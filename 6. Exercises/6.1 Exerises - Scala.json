{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556204978308_980131188","id":"20190425-170938_1092269157","dateCreated":"2019-04-25T17:09:38+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:486","text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","dateUpdated":"2019-04-25T17:09:47+0200","dateFinished":"2019-04-25T17:09:50+0200","dateStarted":"2019-04-25T17:09:47+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]}},{"text":"%md\n# Exercise 1 - Introduction\n\nWe start with the typical hello world application in Spark.","user":"anonymous","dateUpdated":"2019-04-25T17:10:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556204987923_1065540809","id":"20190425-170947_1997023606","dateCreated":"2019-04-25T17:09:47+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:562","dateFinished":"2019-04-25T17:09:59+0200","dateStarted":"2019-04-25T17:09:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Exercise 1 - Introduction</h1>\n<p>We start with the typical hello world application in Spark.</p>\n</div>"}]}},{"text":"%md\n***Task 1.1***\nLoad the following sentences into a RDD: `Spark I am your father`, `May the Spark be with you`, `May Spark live long and prosper`. Split the sentences into words. Use `map` and `flatMap`. What is the difference?\n\n***Task 1.2***\nCount the number of occurences of each word over all sentences using a RDD.","user":"anonymous","dateUpdated":"2019-04-25T17:10:07+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556204999088_-1708334875","id":"20190425-170959_1419221871","dateCreated":"2019-04-25T17:09:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:661","dateFinished":"2019-04-25T17:10:07+0200","dateStarted":"2019-04-25T17:10:07+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 1.1</em></strong><br/>Load the following sentences into a RDD: <code>Spark I am your father</code>, <code>May the Spark be with you</code>, <code>May Spark live long and prosper</code>. Split the sentences into words. Use <code>map</code> and <code>flatMap</code>. What is the difference?</p>\n<p><strong><em>Task 1.2</em></strong><br/>Count the number of occurences of each word over all sentences using a RDD.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:10:15+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205007950_-534863609","id":"20190425-171007_696229478","dateCreated":"2019-04-25T17:10:07+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:750","dateFinished":"2019-04-25T17:10:26+0200","dateStarted":"2019-04-25T17:10:15+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205049615_-854322253","id":"20190425-171049_833094045","dateCreated":"2019-04-25T17:10:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1049","text":"%md\n### Solution 1.1 a","dateUpdated":"2019-04-25T17:11:39+0200","dateFinished":"2019-04-25T17:11:21+0200","dateStarted":"2019-04-25T17:11:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 1.1 a</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205015670_700580976","id":"20190425-171015_1071381145","dateCreated":"2019-04-25T17:10:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:839","text":"%spark\nval sentencesRDD = sc.parallelize(Seq(\"Spark I am your father\", \"May the spark be with you\", \"Spark I am your father\"))\nval wordsMapRDD = sentencesRDD.map(_.split(\" \"))\nwordsMapRDD.collect","dateUpdated":"2019-04-25T17:10:58+0200","dateFinished":"2019-04-25T17:10:58+0200","dateStarted":"2019-04-25T17:10:58+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sentencesRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[2] at parallelize at <console>:28\nwordsMapRDD: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at map at <console>:29\nres4: Array[Array[String]] = Array(Array(Spark, I, am, your, father), Array(May, the, spark, be, with, you), Array(Spark, I, am, your, father))\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=1"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Solution 1.1 b","user":"anonymous","dateUpdated":"2019-04-25T17:12:19+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205097327_-711114024","id":"20190425-171137_2031837218","dateCreated":"2019-04-25T17:11:37+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1177","dateFinished":"2019-04-25T17:11:46+0200","dateStarted":"2019-04-25T17:11:46+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 1.1 b</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205038947_1358600300","id":"20190425-171038_1663880757","dateCreated":"2019-04-25T17:10:38+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:936","text":"val wordsFlatMapRDD = sentencesRDD.flatMap(_.split(\" \"))\nwordsFlatMapRDD.collect","dateUpdated":"2019-04-25T17:11:49+0200","dateFinished":"2019-04-25T17:11:49+0200","dateStarted":"2019-04-25T17:11:49+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"wordsFlatMapRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at flatMap at <console>:27\nres5: Array[String] = Array(Spark, I, am, your, father, May, the, spark, be, with, you, Spark, I, am, your, father)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=2"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205109495_-67382767","id":"20190425-171149_352932491","dateCreated":"2019-04-25T17:11:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1273","text":"//Please add you solution in here\n","dateUpdated":"2019-04-25T17:12:02+0200","dateFinished":"2019-04-25T17:12:03+0200","dateStarted":"2019-04-25T17:12:02+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205137829_228353081","id":"20190425-171217_1082615297","dateCreated":"2019-04-25T17:12:17+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1580","text":"%md\n### Solution 1.2","dateUpdated":"2019-04-25T17:12:27+0200","dateFinished":"2019-04-25T17:12:27+0200","dateStarted":"2019-04-25T17:12:27+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 1.2</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205122898_-1987845446","id":"20190425-171202_1549898437","dateCreated":"2019-04-25T17:12:02+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1386","text":"%spark\nwordsFlatMapRDD.map(word => (word, 1))\n        .reduceByKey(_ + _)\n        .collect()","dateUpdated":"2019-04-25T17:12:35+0200","dateFinished":"2019-04-25T17:12:35+0200","dateStarted":"2019-04-25T17:12:35+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res9: Array[(String, Int)] = Array((Spark,2), (spark,1), (you,1), (am,2), (be,1), (with,1), (I,2), (May,1), (father,2), (your,2), (the,1))\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=4"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205135185_-2111260418","id":"20190425-171215_1026380510","dateCreated":"2019-04-25T17:12:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1467","text":"%md\n# Exercise 2 - Operations and actions\n\nThis exercise we will focus on transformations and actions using different APIs.","dateUpdated":"2019-04-25T17:12:44+0200","dateFinished":"2019-04-25T17:12:44+0200","dateStarted":"2019-04-25T17:12:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Exercise 2 - Operations and actions</h1>\n<p>This exercise we will focus on transformations and actions using different APIs.</p>\n</div>"}]}},{"text":"%md\n***Task 2.0 a***\nUse `mapPartitions` to split the `sentencesRDD` out of exercise 1 without flattening it.\n\n***Task 2.0 b***\nUse `mapPartitionsWithIndex` to split the `sentencesRDD` out of exercise 1 without flattening it.","user":"anonymous","dateUpdated":"2019-04-25T17:12:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205164696_-1756594746","id":"20190425-171244_1701153430","dateCreated":"2019-04-25T17:12:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1715","dateFinished":"2019-04-25T17:12:51+0200","dateStarted":"2019-04-25T17:12:51+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 2.0 a</em></strong><br/>Use <code>mapPartitions</code> to split the <code>sentencesRDD</code> out of exercise 1 without flattening it.</p>\n<p><strong><em>Task 2.0 b</em></strong><br/>Use <code>mapPartitionsWithIndex</code> to split the <code>sentencesRDD</code> out of exercise 1 without flattening it.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:12:59+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205171042_1183010100","id":"20190425-171251_7045072","dateCreated":"2019-04-25T17:12:51+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1805","dateFinished":"2019-04-25T17:12:59+0200","dateStarted":"2019-04-25T17:12:59+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205179317_1984534167","id":"20190425-171259_143134880","dateCreated":"2019-04-25T17:12:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1894","text":"%md\n### Solution 2.0 a","dateUpdated":"2019-04-25T17:13:19+0200","dateFinished":"2019-04-25T17:13:19+0200","dateStarted":"2019-04-25T17:13:19+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.0 a</h3>\n</div>"}]}},{"text":"%spark\nsentencesRDD.mapPartitions(ws => ws.map(_.split(\" \")))\n            .collect","user":"anonymous","dateUpdated":"2019-04-25T17:13:29+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205199160_-1357568329","id":"20190425-171319_381077825","dateCreated":"2019-04-25T17:13:19+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1976","dateFinished":"2019-04-25T17:13:29+0200","dateStarted":"2019-04-25T17:13:29+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res12: Array[Array[String]] = Array(Array(Spark, I, am, your, father), Array(May, the, spark, be, with, you), Array(Spark, I, am, your, father))\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=5"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Solution 2.0 b","user":"anonymous","dateUpdated":"2019-04-25T17:13:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205209728_1411066431","id":"20190425-171329_287966069","dateCreated":"2019-04-25T17:13:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2065","dateFinished":"2019-04-25T17:13:46+0200","dateStarted":"2019-04-25T17:13:46+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.0 b</h3>\n</div>"}]}},{"text":"%spark\nsentencesRDD.mapPartitionsWithIndex((idx, ws) => ws.map(x => (x.split(\" \"), idx)))\n            .collect","user":"anonymous","dateUpdated":"2019-04-25T17:14:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205226880_-249205022","id":"20190425-171346_1018985126","dateCreated":"2019-04-25T17:13:46+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2179","dateFinished":"2019-04-25T17:14:02+0200","dateStarted":"2019-04-25T17:14:01+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res13: Array[(Array[String], Int)] = Array((Array(Spark, I, am, your, father),0), (Array(May, the, spark, be, with, you),0), (Array(Spark, I, am, your, father),0))\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=6"],"interpreterSettingId":"spark"}}},{"text":"%md\n***Task 2.1***\nWe will deal with a snapshot of the million songs dataset containing only 1000 rows. Explore the data using appropriate actions like `count`, `show`, `printSchema`, `first` or `take` of the RDD API and the DataFrame API.","user":"anonymous","dateUpdated":"2019-04-25T17:14:22+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205241883_-21636413","id":"20190425-171401_607460285","dateCreated":"2019-04-25T17:14:01+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2268","dateFinished":"2019-04-25T17:14:22+0200","dateStarted":"2019-04-25T17:14:22+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 2.1</em></strong><br/>We will deal with a snapshot of the million songs dataset containing only 1000 rows. Explore the data using appropriate actions like <code>count</code>, <code>show</code>, <code>printSchema</code>, <code>first</code> or <code>take</code> of the RDD API and the DataFrame API.</p>\n</div>"}]}},{"text":"%spark\ncase class Song(artist: String, year: Int, loudness: Double)\n\nval millionSongsDF = spark.read\n                          .format(\"com.databricks.spark.csv\")\n                          .option(\"header\", true)\n                          .option(\"inferSchema\", true)\n                          .load(\"dbfs:/cs-spark-training/millionSongs1000/millionSongs1000.csv\")\n\nval millionSongsRDD = millionSongsDF.rdd.map(x => Song(x(0).toString, x(1).asInstanceOf[Int], x(2).asInstanceOf[Double]))","user":"anonymous","dateUpdated":"2019-04-25T17:14:33+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205262607_-1159578625","id":"20190425-171422_370249278","dateCreated":"2019-04-25T17:14:22+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2382","dateFinished":"2019-04-25T17:14:34+0200","dateStarted":"2019-04-25T17:14:33+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 41 elided\n"}]}},{"text":"//Please add your solution in here\nprintln(\"Number of Rows: \" + )\nprintln(\"Sneak Preview:\\n\"+ )\n\n// print first 5 lines\n","user":"anonymous","dateUpdated":"2019-04-25T17:14:40+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205273110_-954036154","id":"20190425-171433_1522108568","dateCreated":"2019-04-25T17:14:33+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2471","dateFinished":"2019-04-25T17:14:40+0200","dateStarted":"2019-04-25T17:14:40+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:27: error: missing argument list for method + in class String\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `$plus _` or `$plus(_)` instead of `$plus`.\n       println(\"Sneak Preview:\\n\"+ )\n                                 ^\n<console>:24: error: missing argument list for method + in class String\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `$plus _` or `$plus(_)` instead of `$plus`.\n       println(\"Number of Rows: \" + )\n                                  ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205280526_-48429520","id":"20190425-171440_1020740848","dateCreated":"2019-04-25T17:14:40+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2568","text":"%md\n### Solution 2.1 RDD API","dateUpdated":"2019-04-25T17:14:59+0200","dateFinished":"2019-04-25T17:14:59+0200","dateStarted":"2019-04-25T17:14:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.1 RDD API</h3>\n</div>"}]}},{"text":"%spark\nprintln(\"Number of Rows: \" + millionSongsRDD.count())\nprintln(\"Sneak Preview:\\n\"+millionSongsRDD.first)\n\n// print first 5 lines\nmillionSongsRDD.take(5).foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:15:12+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205299590_-1918537927","id":"20190425-171459_1951850228","dateCreated":"2019-04-25T17:14:59+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2657","dateFinished":"2019-04-25T17:15:12+0200","dateStarted":"2019-04-25T17:15:12+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value millionSongsRDD\n       millionSongsRDD.take(5).foreach(println)\n       ^\n<console>:23: error: not found: value millionSongsRDD\n       println(\"Number of Rows: \" + millionSongsRDD.count())\n                                    ^\n<console>:24: error: not found: value millionSongsRDD\n       println(\"Sneak Preview:\\n\"+millionSongsRDD.first)\n                                  ^\n"}]}},{"text":"//Please add your solution in here\nprintln(\"Schema: \" +)\n\nprintln(\"Number of Rows: \" + )\n\nprintln(\"Show: \" +)\n\nprintln(\"Describe: \" +)\n","user":"anonymous","dateUpdated":"2019-04-25T17:15:20+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205312187_-843917324","id":"20190425-171512_241642918","dateCreated":"2019-04-25T17:15:12+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2746","dateFinished":"2019-04-25T17:15:20+0200","dateStarted":"2019-04-25T17:15:20+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:32: error: missing argument list for method + in class String\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `$plus _` or `$plus(_)` instead of `$plus`.\n       println(\"Describe: \" +)\n                            ^\n<console>:24: error: missing argument list for method + in class String\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `$plus _` or `$plus(_)` instead of `$plus`.\n       println(\"Schema: \" +)\n                          ^\n<console>:26: error: missing argument list for method + in class String\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `$plus _` or `$plus(_)` instead of `$plus`.\n       println(\"Number of Rows: \" + )\n                                  ^\n<console>:28: error: missing argument list for method + in class String\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `$plus _` or `$plus(_)` instead of `$plus`.\n       println(\"Show: \" +)\n                        ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205320914_2015467628","id":"20190425-171520_2088645263","dateCreated":"2019-04-25T17:15:20+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2834","text":"%md\n### Solution 2.1 DataFrame API","dateUpdated":"2019-04-25T17:15:59+0200","dateFinished":"2019-04-25T17:15:59+0200","dateStarted":"2019-04-25T17:15:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.1 DataFrame API</h3>\n</div>"}]}},{"text":"%spark\nprintln(\"Schema:\")\nmillionSongsDF.printSchema\nprintln(\"Number of Rows: \"+millionSongsDF.count)\nprintln(\"Sneak Peak:\")\nmillionSongsDF.show(5)\nmillionSongsDF.describe().show()","user":"anonymous","dateUpdated":"2019-04-25T17:16:10+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205359221_132314406","id":"20190425-171559_1544442587","dateCreated":"2019-04-25T17:15:59+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2923","dateFinished":"2019-04-25T17:16:10+0200","dateStarted":"2019-04-25T17:16:10+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value millionSongsDF\n       millionSongsDF.describe().show()\n       ^\n<console>:24: error: not found: value millionSongsDF\n       millionSongsDF.printSchema\n       ^\n<console>:25: error: not found: value millionSongsDF\n       println(\"Number of Rows: \"+millionSongsDF.count)\n                                  ^\n<console>:27: error: not found: value millionSongsDF\n       millionSongsDF.show(5)\n       ^\n"}]}},{"text":"%md\n***Task 2.2***\nFind out which artist has the most songs in the millionSongs dataset. Use the RDD API on `millionSongsRDD` and the DataFrame API on `millionSongsDF`.","user":"anonymous","dateUpdated":"2019-04-25T17:16:25+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205370555_-235055102","id":"20190425-171610_507245218","dateCreated":"2019-04-25T17:16:10+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3012","dateFinished":"2019-04-25T17:16:25+0200","dateStarted":"2019-04-25T17:16:25+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 2.2</em></strong><br/>Find out which artist has the most songs in the millionSongs dataset. Use the RDD API on <code>millionSongsRDD</code> and the DataFrame API on <code>millionSongsDF</code>.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:16:31+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205385382_1287318558","id":"20190425-171625_842586361","dateCreated":"2019-04-25T17:16:25+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3101","dateFinished":"2019-04-25T17:16:31+0200","dateStarted":"2019-04-25T17:16:31+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205391343_1595938877","id":"20190425-171631_110994899","dateCreated":"2019-04-25T17:16:31+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3190","text":"%md\n### Solution 2.2 DataFrame API","dateUpdated":"2019-04-25T17:16:44+0200","dateFinished":"2019-04-25T17:16:44+0200","dateStarted":"2019-04-25T17:16:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.2 DataFrame API</h3>\n</div>"}]}},{"text":"%spark\nval songsByArtistDF = millionSongsDF.groupBy(\"artist\")\n                                    .count()\n                                    .orderBy($\"count\".desc)\n\nsongsByArtistDF.show(10)","user":"anonymous","dateUpdated":"2019-04-25T17:17:00+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205404343_-1847701496","id":"20190425-171644_1085882039","dateCreated":"2019-04-25T17:16:44+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3272","dateFinished":"2019-04-25T17:17:00+0200","dateStarted":"2019-04-25T17:17:00+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:23: error: not found: value millionSongsDF\n       val songsByArtistDF = millionSongsDF.groupBy(\"artist\")\n                             ^\n"}]}},{"text":"%md\n***Task 2.3***\nCompute the average loudness for each artist and each year with the RDD API as well as the DataFrame API. Ignore years with value = 0.","user":"anonymous","dateUpdated":"2019-04-25T17:17:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205420224_-1572406744","id":"20190425-171700_1760269157","dateCreated":"2019-04-25T17:17:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3361","dateFinished":"2019-04-25T17:17:09+0200","dateStarted":"2019-04-25T17:17:09+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 2.3</em></strong><br/>Compute the average loudness for each artist and each year with the RDD API as well as the DataFrame API. Ignore years with value = 0.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:17:15+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205429241_-20127851","id":"20190425-171709_1821503086","dateCreated":"2019-04-25T17:17:09+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3450","dateFinished":"2019-04-25T17:17:15+0200","dateStarted":"2019-04-25T17:17:15+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205435676_1033209109","id":"20190425-171715_2098699643","dateCreated":"2019-04-25T17:17:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3539","text":"%md\n### Solution 2.3 DataFrame API","dateUpdated":"2019-04-25T17:17:35+0200","dateFinished":"2019-04-25T17:17:35+0200","dateStarted":"2019-04-25T17:17:35+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.3 DataFrame API</h3>\n</div>"}]}},{"text":"%spark\nval loudnessByArtistYearDF = millionSongsDF.filter(\"year > 0\")\n                                           .groupBy(\"artist\", \"year\")\n                                           .mean(\"loudness\")\n                                           .orderBy(\"avg(loudness)\")\n\ndisplay(loudnessByArtistYearDF)","user":"anonymous","dateUpdated":"2019-04-25T17:17:49+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205455673_379547450","id":"20190425-171735_1076066518","dateCreated":"2019-04-25T17:17:35+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3612","dateFinished":"2019-04-25T17:17:49+0200","dateStarted":"2019-04-25T17:17:49+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:23: error: not found: value millionSongsDF\n       val loudnessByArtistYearDF = millionSongsDF.filter(\"year > 0\")\n                                    ^\n<console>:30: error: not found: value display\n       display(loudnessByArtistYearDF)\n       ^\n"}]}},{"text":"%md\n### Solution 2.3 RDD API","user":"anonymous","dateUpdated":"2019-04-25T17:18:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205469234_615109065","id":"20190425-171749_224215999","dateCreated":"2019-04-25T17:17:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3701","dateFinished":"2019-04-25T17:18:03+0200","dateStarted":"2019-04-25T17:18:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.3 RDD API</h3>\n</div>"}]}},{"text":"%spark\nval loudnessByArtistYearRDD = millionSongsRDD.filter(_.year > 0)\n                                             .groupBy(song => (song.artist, song.year))\n                                             .map(tuple => {\n                                                    var loudness = 0.0\n                                                    tuple._2.foreach(song => loudness = loudness + song.loudness)\n                                                    (tuple._1, loudness / tuple._2.size)\n                                                })\n\ndisplay(loudnessByArtistYearRDD.toDF().orderBy(\"_2\"))","user":"anonymous","dateUpdated":"2019-04-25T17:18:14+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205483402_-2145618129","id":"20190425-171803_196249799","dateCreated":"2019-04-25T17:18:03+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3790","dateFinished":"2019-04-25T17:18:14+0200","dateStarted":"2019-04-25T17:18:14+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:23: error: not found: value millionSongsRDD\n       val loudnessByArtistYearRDD = millionSongsRDD.filter(_.year > 0)\n                                     ^\n<console>:33: error: not found: value display\n       display(loudnessByArtistYearRDD.toDF().orderBy(\"_2\"))\n       ^\n"}]}},{"text":"%md\n***Task 2.4***\nTry to solve the previous RDD task by using `reduceByKey`.","user":"anonymous","dateUpdated":"2019-04-25T17:18:24+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205494471_350429670","id":"20190425-171814_547932835","dateCreated":"2019-04-25T17:18:14+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3879","dateFinished":"2019-04-25T17:18:24+0200","dateStarted":"2019-04-25T17:18:24+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 2.4</em></strong><br/>Try to solve the previous RDD task by using <code>reduceByKey</code>.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:18:30+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205504612_-1253066855","id":"20190425-171824_2000386316","dateCreated":"2019-04-25T17:18:24+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3968","dateFinished":"2019-04-25T17:18:30+0200","dateStarted":"2019-04-25T17:18:30+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205510731_1308069037","id":"20190425-171830_878584468","dateCreated":"2019-04-25T17:18:30+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4057","text":"%md\n### Solution 2.4","dateUpdated":"2019-04-25T17:18:44+0200","dateFinished":"2019-04-25T17:18:44+0200","dateStarted":"2019-04-25T17:18:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 2.4</h3>\n</div>"}]}},{"text":"%spark\nval loudnessByArtistYearRBK = millionSongsRDD.filter(_.year > 0)\n                                             .map(song => ((song.artist, song.year), (song.loudness, 1)))\n                                             .reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2))\n                                             .map(tuple => (tuple._1, tuple._2._1 / tuple._2._2))\n\ndisplay(loudnessByArtistYearRBK.sortByKey().toDF.orderBy(\"_2\"))","user":"anonymous","dateUpdated":"2019-04-25T17:18:52+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205524369_-1775394116","id":"20190425-171844_1670294857","dateCreated":"2019-04-25T17:18:44+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4139","dateFinished":"2019-04-25T17:18:52+0200","dateStarted":"2019-04-25T17:18:52+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:23: error: not found: value millionSongsRDD\n       val loudnessByArtistYearRBK = millionSongsRDD.filter(_.year > 0)\n                                     ^\n<console>:30: error: not found: value display\n       display(loudnessByArtistYearRBK.sortByKey().toDF.orderBy(\"_2\"))\n       ^\n"}]}},{"text":"%md\n***Task 2.5***\nInvestigate the Web UI by observing the Event timeline and the DAG of the last exercises.","user":"anonymous","dateUpdated":"2019-04-25T17:19:00+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205532684_-380105830","id":"20190425-171852_1983508067","dateCreated":"2019-04-25T17:18:52+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4228","dateFinished":"2019-04-25T17:19:00+0200","dateStarted":"2019-04-25T17:19:00+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 2.5</em></strong><br/>Investigate the Web UI by observing the Event timeline and the DAG of the last exercises.</p>\n</div>"}]}},{"text":"%md\n# Exercise 3 - Ingestion and saving\n\nIn this exercise we will become familiar with general aspects of data ingestion and saving.\n\nWe will deal with a snapshot of the NYC Taxi dataset containing only 100 rows.","user":"anonymous","dateUpdated":"2019-04-25T17:19:07+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205540250_924280667","id":"20190425-171900_589908980","dateCreated":"2019-04-25T17:19:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4317","dateFinished":"2019-04-25T17:19:07+0200","dateStarted":"2019-04-25T17:19:07+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Exercise 3 - Ingestion and saving</h1>\n<p>In this exercise we will become familiar with general aspects of data ingestion and saving.</p>\n<p>We will deal with a snapshot of the NYC Taxi dataset containing only 100 rows.</p>\n</div>"}]}},{"text":"%md\n***Task 3.1***\nLoad a DataFrame from a blank-delimited CSV file (***dbfs:/cs-spark-training/exercises/chapter3/***) containing a snapshot of the NYC Taxi dataset. Compare the infered data types of the snapshot with the corresponding columns of the complete dataset. Are there differences?","user":"anonymous","dateUpdated":"2019-04-25T17:19:15+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205547258_-1451239503","id":"20190425-171907_1888375131","dateCreated":"2019-04-25T17:19:07+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4407","dateFinished":"2019-04-25T17:19:15+0200","dateStarted":"2019-04-25T17:19:15+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 3.1</em></strong><br/>Load a DataFrame from a blank-delimited CSV file (***dbfs:/cs-spark-training/exercises/chapter3/***) containing a snapshot of the NYC Taxi dataset. Compare the infered data types of the snapshot with the corresponding columns of the complete dataset. Are there differences?</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:19:24+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205555234_-663221481","id":"20190425-171915_1062291228","dateCreated":"2019-04-25T17:19:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4497","dateFinished":"2019-04-25T17:19:24+0200","dateStarted":"2019-04-25T17:19:24+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205564495_-1763749608","id":"20190425-171924_802130634","dateCreated":"2019-04-25T17:19:24+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4586","text":"%md\n### Solution 3.1","dateUpdated":"2019-04-25T17:19:35+0200","dateFinished":"2019-04-25T17:19:35+0200","dateStarted":"2019-04-25T17:19:35+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 3.1</h3>\n</div>"}]}},{"text":"%spark\nval taxiSnap = spark.read.option(\"header\", true).option(\"inferSchema\", true).option(\"delimiter\", \" \").csv(\"dbfs:/cs-spark-training/exercises/chapter3/\")\ntaxiSnap.printSchema()  //with schema inferring only 'pickup_datetime' has a wrong data type\ntaxiSnap.show(false)","user":"anonymous","dateUpdated":"2019-04-25T17:19:43+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205574981_992038928","id":"20190425-171934_400781306","dateCreated":"2019-04-25T17:19:34+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4659","dateFinished":"2019-04-25T17:19:44+0200","dateStarted":"2019-04-25T17:19:43+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:412)\n  ... 47 elided\n"}]}},{"text":"%md\n***Task 3.2***\nIn case of wrong inferred data types correct them manually and load the file again with corrected data types.","user":"anonymous","dateUpdated":"2019-04-25T17:19:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205583747_-1060395967","id":"20190425-171943_771708666","dateCreated":"2019-04-25T17:19:43+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4748","dateFinished":"2019-04-25T17:19:51+0200","dateStarted":"2019-04-25T17:19:51+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 3.2</em></strong><br/>In case of wrong inferred data types correct them manually and load the file again with corrected data types.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:19:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205591671_-185425732","id":"20190425-171951_1951092001","dateCreated":"2019-04-25T17:19:51+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4846","dateFinished":"2019-04-25T17:19:58+0200","dateStarted":"2019-04-25T17:19:58+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205598187_1250598579","id":"20190425-171958_102076003","dateCreated":"2019-04-25T17:19:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4935","text":"%md\n### Solution 3.2","dateUpdated":"2019-04-25T17:20:12+0200","dateFinished":"2019-04-25T17:20:12+0200","dateStarted":"2019-04-25T17:20:12+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 3.2</h3>\n</div>"}]}},{"text":"%spark\n//Import the types you need\nimport org.apache.spark.sql.types.{StructType,StructField,StringType,IntegerType,TimestampType,DoubleType}\n\n//Manually define the schema\nval taxiSchema = StructType(List(StructField(\"medallion\", StringType),\n                                 StructField(\"rate_code\", IntegerType),\n                                 StructField(\"pickup_datetime\", TimestampType),\n                                 StructField(\"trip_distance\", DoubleType),\n                                 StructField(\"store_and_fwd_flag\", StringType)))\n\nval taxiSnapshot = spark.read.option(\"header\", true)\n                             .option(\"delimiter\", \" \")\n                             .option(\"timestampFormat\", \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\")\n                             .schema(taxiSchema)\n                             .csv(\"dbfs:/cs-spark-training/exercises/chapter3/\")\n\ntaxiSnapshot.printSchema()\ntaxiSnapshot.show(50, false)","user":"anonymous","dateUpdated":"2019-04-25T17:20:21+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205611994_-1343543649","id":"20190425-172011_1122791299","dateCreated":"2019-04-25T17:20:11+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5017","dateFinished":"2019-04-25T17:20:22+0200","dateStarted":"2019-04-25T17:20:21+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:412)\n  ... 47 elided\n"}]}},{"text":"%md\n***Task 3.3***\nSave the corrected DataFrame to your directory as a Parquet file and partition it by ***rate_code***. Additionally make sure you can save your file no matter if there already exists one. Afterwards have a look into the directory you saved the file to. What can you see?","user":"anonymous","dateUpdated":"2019-04-25T17:20:30+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205621555_660477614","id":"20190425-172021_2032744498","dateCreated":"2019-04-25T17:20:21+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5106","dateFinished":"2019-04-25T17:20:30+0200","dateStarted":"2019-04-25T17:20:30+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 3.3</em></strong><br/>Save the corrected DataFrame to your directory as a Parquet file and partition it by <strong><em>rate_code</em></strong>. Additionally make sure you can save your file no matter if there already exists one. Afterwards have a look into the directory you saved the file to. What can you see?</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:20:36+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205630533_700601415","id":"20190425-172030_900054456","dateCreated":"2019-04-25T17:20:30+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5204","dateFinished":"2019-04-25T17:20:36+0200","dateStarted":"2019-04-25T17:20:36+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205636799_1152906271","id":"20190425-172036_380820490","dateCreated":"2019-04-25T17:20:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5293","text":"%md\n### Solution 3.3","dateUpdated":"2019-04-25T17:20:47+0200","dateFinished":"2019-04-25T17:20:47+0200","dateStarted":"2019-04-25T17:20:47+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 3.3</h3>\n</div>"}]}},{"text":"%spark\ntaxiSnapshot.write.partitionBy(\"store_and_fwd_flag\", \"rate_code\").mode(\"overwrite\").save(\"dbfs:/cs-spark-training/test2/\")","user":"anonymous","dateUpdated":"2019-04-25T17:20:56+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205647040_665547550","id":"20190425-172047_183527554","dateCreated":"2019-04-25T17:20:47+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5366","dateFinished":"2019-04-25T17:20:56+0200","dateStarted":"2019-04-25T17:20:56+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:24: error: not found: value taxiSnapshot\n       taxiSnapshot.write.partitionBy(\"store_and_fwd_flag\", \"rate_code\").mode(\"overwrite\").save(\"dbfs:/cs-spark-training/test2/\")\n       ^\n"}]}},{"text":"%md\n***Task 3.4***\nMake yourself familiar with the `.basePath` option. For more information about this option please have a look [here](https://spark.apache.org/docs/latest/sql-programming-guide.html#partition-discovery).\nAfter your familiar with the `.basePath` option please read in your previously saved snapshot of the NYC Taxi dataset in two different ways:\n1. Read in the files as DataFrame again by using the `.basePath` option which ***excludes*** the subdirectory *store_and_fwd_flag* and subsequent subdirectories.\n2. Read in the files as DataFrame again by using the `.basePath` option which ***includes*** the subdirectory *store_and_fwd_flag*.","user":"anonymous","dateUpdated":"2019-04-25T17:21:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205656485_34924810","id":"20190425-172056_1118403000","dateCreated":"2019-04-25T17:20:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5455","dateFinished":"2019-04-25T17:21:03+0200","dateStarted":"2019-04-25T17:21:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 3.4</em></strong><br/>Make yourself familiar with the <code>.basePath</code> option. For more information about this option please have a look <a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html#partition-discovery\">here</a>.<br/>After your familiar with the <code>.basePath</code> option please read in your previously saved snapshot of the NYC Taxi dataset in two different ways:<br/>1. Read in the files as DataFrame again by using the <code>.basePath</code> option which <strong><em>excludes</em></strong> the subdirectory <em>store_and_fwd_flag</em> and subsequent subdirectories.<br/>2. Read in the files as DataFrame again by using the <code>.basePath</code> option which <strong><em>includes</em></strong> the subdirectory <em>store_and_fwd_flag</em>.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:21:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205663629_375734932","id":"20190425-172103_1437382870","dateCreated":"2019-04-25T17:21:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5544","dateFinished":"2019-04-25T17:21:13+0200","dateStarted":"2019-04-25T17:21:13+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205673091_1790736015","id":"20190425-172113_1158307606","dateCreated":"2019-04-25T17:21:13+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5633","text":"%md\n### Solution 3.4","dateUpdated":"2019-04-25T17:21:41+0200","dateFinished":"2019-04-25T17:21:41+0200","dateStarted":"2019-04-25T17:21:41+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 3.4</h3>\n</div>"}]}},{"text":"%spark\nval firstBasePath = \"dbfs:/cs-spark-training/test2/\"\nval first = spark.read.option(\"basePath\", firstBasePath)\n                      .load(\"dbfs:/cs-spark-training/test2/store_and_fwd_flag=B/\")\nfirst.printSchema()\n\n\nval secondBasePath = \"dbfs:/cs-spark-training/test2/store_and_fwd_flag=B\"\nval second = spark.read.option(\"basePath\", secondBasePath)\n                       .load(\"dbfs:/cs-spark-training/test2/store_and_fwd_flag=B/\")\nsecond.printSchema()","user":"anonymous","dateUpdated":"2019-04-25T17:21:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205701400_-1642599164","id":"20190425-172141_1193636657","dateCreated":"2019-04-25T17:21:41+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5706","dateFinished":"2019-04-25T17:21:52+0200","dateStarted":"2019-04-25T17:21:51+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 47 elided\n"}]}},{"text":"%md\n***Task 3.5***\nTry to ingest in-memory data as Datasets and RDDs","user":"anonymous","dateUpdated":"2019-04-25T17:22:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205711738_-1407414288","id":"20190425-172151_538974358","dateCreated":"2019-04-25T17:21:51+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5795","dateFinished":"2019-04-25T17:22:03+0200","dateStarted":"2019-04-25T17:22:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 3.5</em></strong><br/>Try to ingest in-memory data as Datasets and RDDs</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:22:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205723869_2026225952","id":"20190425-172203_295514339","dateCreated":"2019-04-25T17:22:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5893","dateFinished":"2019-04-25T17:22:10+0200","dateStarted":"2019-04-25T17:22:09+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205729918_54736224","id":"20190425-172209_945144773","dateCreated":"2019-04-25T17:22:09+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5982","text":"%md\n### Solution 3.5","dateUpdated":"2019-04-25T17:22:24+0200","dateFinished":"2019-04-25T17:22:24+0200","dateStarted":"2019-04-25T17:22:24+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 3.5</h3>\n</div>"}]}},{"text":"%spark\n//Dataset\ncase class Vehicle(brand: String, model: String, fourWheeler: Boolean)\n\nval sampleVehicles = List(Vehicle(\"Dacia\", \"Duster\", true), Vehicle(\"BMW\", \"Isetta\", false), Vehicle(\"Yamaha\", \"YZF-R1M\", false))\n\nval fleetDS = spark.createDataset(sampleVehicles)\nfleetDS.show(false)\n\n//RDD\nval fleetRDD = sc.parallelize(sampleVehicles)\nfleetRDD.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:22:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205744906_-917553903","id":"20190425-172224_745071512","dateCreated":"2019-04-25T17:22:24+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6055","dateFinished":"2019-04-25T17:22:35+0200","dateStarted":"2019-04-25T17:22:35+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:20: error: Unable to find encoder for type stored in a Dataset.  Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._  Support for serializing other types will be added in future releases.\n       val fleetDS = spark.createDataset(sampleVehicles)\n                                        ^\n"}]}},{"text":"%md\n# Exercise 4 - Spark SQL\n\nIn this exercise we will become familiar with Spark SQL structured data processing.\n\nSee also the offical [Spark SQL programming guide](https://spark.apache.org/docs/latest/sql-programming-guide.html).\n\nData: *New York City Taxi Dataset*, 22 MB zipped Parquets with overall 999,999 rows","user":"anonymous","dateUpdated":"2019-04-25T17:22:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205755408_-677175634","id":"20190425-172235_1970533225","dateCreated":"2019-04-25T17:22:35+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6144","dateFinished":"2019-04-25T17:22:45+0200","dateStarted":"2019-04-25T17:22:45+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Exercise 4 - Spark SQL</h1>\n<p>In this exercise we will become familiar with Spark SQL structured data processing.</p>\n<p>See also the offical <a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html\">Spark SQL programming guide</a>.</p>\n<p>Data: <em>New York City Taxi Dataset</em>, 22 MB zipped Parquets with overall 999,999 rows</p>\n</div>"}]}},{"text":"%md\n##### Setup basics\nPlease run the subsequent paragraph to setup the basics before you proceed with the tasks.","user":"anonymous","dateUpdated":"2019-04-25T17:23:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205765828_-1285416285","id":"20190425-172245_919053981","dateCreated":"2019-04-25T17:22:45+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6242","dateFinished":"2019-04-25T17:23:01+0200","dateStarted":"2019-04-25T17:23:01+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>Setup basics</h5>\n<p>Please run the subsequent paragraph to setup the basics before you proceed with the tasks.</p>\n</div>"}]}},{"text":"%run \"/cs-spark-training/connect_s3\"","user":"anonymous","dateUpdated":"2019-04-25T17:23:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205774040_-1759088967","id":"20190425-172254_1891063102","dateCreated":"2019-04-25T17:22:54+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6332","errorMessage":"org.apache.zeppelin.interpreter.InterpreterNotFoundException: Either no interpreter named run or it is not binded to this note\n\tat org.apache.zeppelin.interpreter.InterpreterFactory.getInterpreter(InterpreterFactory.java:101)\n\tat org.apache.zeppelin.notebook.Paragraph.getBindedInterpreter(Paragraph.java:242)\n\tat org.apache.zeppelin.notebook.Paragraph.execute(Paragraph.java:350)\n\tat org.apache.zeppelin.notebook.Note.run(Note.java:683)\n\tat org.apache.zeppelin.socket.NotebookServer.persistAndExecuteSingleParagraph(NotebookServer.java:1881)\n\tat org.apache.zeppelin.socket.NotebookServer.runParagraph(NotebookServer.java:1840)\n\tat org.apache.zeppelin.socket.NotebookServer.onMessage(NotebookServer.java:262)\n\tat org.apache.zeppelin.socket.NotebookSocket.onWebSocketText(NotebookSocket.java:59)\n\tat org.eclipse.jetty.websocket.common.events.JettyListenerEventDriver.onTextMessage(JettyListenerEventDriver.java:189)\n\tat org.eclipse.jetty.websocket.common.message.SimpleTextMessage.messageComplete(SimpleTextMessage.java:69)\n\tat org.eclipse.jetty.websocket.common.events.AbstractEventDriver.appendMessage(AbstractEventDriver.java:66)\n\tat org.eclipse.jetty.websocket.common.events.JettyListenerEventDriver.onTextFrame(JettyListenerEventDriver.java:158)\n\tat org.eclipse.jetty.websocket.common.events.AbstractEventDriver.incomingFrame(AbstractEventDriver.java:162)\n\tat org.eclipse.jetty.websocket.common.WebSocketSession.incomingFrame(WebSocketSession.java:459)\n\tat org.eclipse.jetty.websocket.common.extensions.AbstractExtension.nextIncomingFrame(AbstractExtension.java:182)\n\tat org.eclipse.jetty.websocket.common.extensions.compress.PerMessageDeflateExtension.nextIncomingFrame(PerMessageDeflateExtension.java:105)\n\tat org.eclipse.jetty.websocket.common.extensions.compress.CompressExtension.forwardIncoming(CompressExtension.java:142)\n\tat org.eclipse.jetty.websocket.common.extensions.compress.PerMessageDeflateExtension.incomingFrame(PerMessageDeflateExtension.java:85)\n\tat org.eclipse.jetty.websocket.common.extensions.ExtensionStack.incomingFrame(ExtensionStack.java:220)\n\tat org.eclipse.jetty.websocket.common.Parser.notifyFrame(Parser.java:219)\n\tat org.eclipse.jetty.websocket.common.Parser.parse(Parser.java:244)\n\tat org.eclipse.jetty.websocket.common.io.AbstractWebSocketConnection.readParse(AbstractWebSocketConnection.java:559)\n\tat org.eclipse.jetty.websocket.common.io.AbstractWebSocketConnection.onFillable(AbstractWebSocketConnection.java:390)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\n\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\n\tat java.lang.Thread.run(Thread.java:748)\n","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.zeppelin.interpreter.InterpreterNotFoundException: Either no interpreter named run or it is not binded to this note"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205793194_-176567504","id":"20190425-172313_1584284750","dateCreated":"2019-04-25T17:23:13+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6445","text":"%md \n***Task 4.1***\nLoad the data in a DataFrame and infer the schema automatically.\nUse the databricks command `display()` to visualize the DataFrame.","dateUpdated":"2019-04-25T17:23:21+0200","dateFinished":"2019-04-25T17:23:21+0200","dateStarted":"2019-04-25T17:23:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.1</em></strong><br/>Load the data in a DataFrame and infer the schema automatically.<br/>Use the databricks command <code>display()</code> to visualize the DataFrame.</p>\n</div>"}]}},{"text":"//Path of NYC Taxi dataset\nval taxiDataPath = \"s3a://bigpicture-guild/nyctaxi/sample_1_month/parquet/\"","user":"anonymous","dateUpdated":"2019-04-25T17:23:31+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205801379_102376295","id":"20190425-172321_211442554","dateCreated":"2019-04-25T17:23:21+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6539","dateFinished":"2019-04-25T17:23:28+0200","dateStarted":"2019-04-25T17:23:28+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"taxiDataPath: String = s3a://bigpicture-guild/nyctaxi/sample_1_month/parquet/\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205808249_968360734","id":"20190425-172328_1123513947","dateCreated":"2019-04-25T17:23:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6629","text":"//Please add your solution in here\n","dateUpdated":"2019-04-25T17:23:42+0200","dateFinished":"2019-04-25T17:23:42+0200","dateStarted":"2019-04-25T17:23:42+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205822316_382484759","id":"20190425-172342_1187826326","dateCreated":"2019-04-25T17:23:42+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6742","text":"%md\n### Solution 4.1","dateUpdated":"2019-04-25T17:23:53+0200","dateFinished":"2019-04-25T17:23:53+0200","dateStarted":"2019-04-25T17:23:53+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.1</h3>\n</div>"}]}},{"text":"%spark\nval taxiDfEmptyCol = spark.read.parquet(taxiDataPath)\ndisplay(taxiDfEmptyCol)","user":"anonymous","dateUpdated":"2019-04-25T17:24:11+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205833749_-868107969","id":"20190425-172353_1993891322","dateCreated":"2019-04-25T17:23:53+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6815","dateFinished":"2019-04-25T17:24:11+0200","dateStarted":"2019-04-25T17:24:11+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:28: error: not found: value display\n       display(taxiDfEmptyCol)\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205840336_-2123231424","id":"20190425-172400_1753480426","dateCreated":"2019-04-25T17:24:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6905","text":"%md\n***Task 4.2***\nAfter observing the DataFrame you should see that there is a column without any name. Provide this column with the name *payment_type* by using `.withColumnRenamed`. Additionally check the schema of the DataFrame and count the rows.","dateUpdated":"2019-04-25T17:24:33+0200","dateFinished":"2019-04-25T17:24:33+0200","dateStarted":"2019-04-25T17:24:33+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.2</em></strong><br/>After observing the DataFrame you should see that there is a column without any name. Provide this column with the name <em>payment_type</em> by using <code>.withColumnRenamed</code>. Additionally check the schema of the DataFrame and count the rows.</p>\n</div>"}]}},{"text":"//Please add you solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:24:39+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205873147_-1768298702","id":"20190425-172433_1951832160","dateCreated":"2019-04-25T17:24:33+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7026","dateFinished":"2019-04-25T17:24:39+0200","dateStarted":"2019-04-25T17:24:39+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205879724_1488367602","id":"20190425-172439_150610525","dateCreated":"2019-04-25T17:24:39+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7115","text":"%md\n### Solution 4.2","dateUpdated":"2019-04-25T17:24:54+0200","dateFinished":"2019-04-25T17:24:54+0200","dateStarted":"2019-04-25T17:24:54+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.2</h3>\n</div>"}]}},{"text":"%spark\nval taxiDataDF = taxiDfEmptyCol.withColumnRenamed(\"\",\"payment_type\")\n\n// check if we need to change data types\ntaxiDataDF.printSchema()\n\n// number of rows 999,999\ntaxiDataDF.count()","user":"anonymous","dateUpdated":"2019-04-25T17:25:08+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205894335_-914826182","id":"20190425-172454_505087363","dateCreated":"2019-04-25T17:24:54+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7197","dateFinished":"2019-04-25T17:25:08+0200","dateStarted":"2019-04-25T17:25:08+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:23: error: not found: value taxiDfEmptyCol\n       val taxiDataDF = taxiDfEmptyCol.withColumnRenamed(\"\",\"payment_type\")\n                        ^\n"}]}},{"text":"%md \n***Task 4.3***\nEven though the schema is correct, let's try to change \"pickup_datetime\" to a unix timestamp temporarily. `cast` might be a useful operation here.","user":"anonymous","dateUpdated":"2019-04-25T17:25:19+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205907972_1046905773","id":"20190425-172507_445469342","dateCreated":"2019-04-25T17:25:07+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7286","dateFinished":"2019-04-25T17:25:19+0200","dateStarted":"2019-04-25T17:25:19+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.3</em></strong><br/>Even though the schema is correct, let&rsquo;s try to change &ldquo;pickup_datetime&rdquo; to a unix timestamp temporarily. <code>cast</code> might be a useful operation here.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:25:26+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205919720_-1866599893","id":"20190425-172519_662946172","dateCreated":"2019-04-25T17:25:19+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7375","dateFinished":"2019-04-25T17:25:26+0200","dateStarted":"2019-04-25T17:25:26+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205926168_-1555698359","id":"20190425-172526_1868644603","dateCreated":"2019-04-25T17:25:26+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7464","text":"%md\n### Solution 4.3","dateUpdated":"2019-04-25T17:25:37+0200","dateFinished":"2019-04-25T17:25:37+0200","dateStarted":"2019-04-25T17:25:37+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.3</h3>\n</div>"}]}},{"text":"%spark\ntaxiDataDF.withColumn(\"pickup_datetime\", taxiDataDF(\"pickup_datetime\").cast(\"integer\")).printSchema","user":"anonymous","dateUpdated":"2019-04-25T17:26:18+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205937800_1952218168","id":"20190425-172537_762337805","dateCreated":"2019-04-25T17:25:37+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7537","dateFinished":"2019-04-25T17:26:18+0200","dateStarted":"2019-04-25T17:26:18+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:24: error: not found: value taxiDataDF\n       taxiDataDF.withColumn(\"pickup_datetime\", taxiDataDF(\"pickup_datetime\").cast(\"integer\")).printSchema\n       ^\n<console>:24: error: not found: value taxiDataDF\n       taxiDataDF.withColumn(\"pickup_datetime\", taxiDataDF(\"pickup_datetime\").cast(\"integer\")).printSchema\n                                                ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205970103_132187639","id":"20190425-172610_728397964","dateCreated":"2019-04-25T17:26:10+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7627","text":"%md\n***Task 4.4***\nCreate a temporary view of the taxi DataFrame.","dateUpdated":"2019-04-25T17:26:31+0200","dateFinished":"2019-04-25T17:26:31+0200","dateStarted":"2019-04-25T17:26:31+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.4</em></strong><br/>Create a temporary view of the taxi DataFrame.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:26:37+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205991751_1891733335","id":"20190425-172631_1249439984","dateCreated":"2019-04-25T17:26:31+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7748","dateFinished":"2019-04-25T17:26:38+0200","dateStarted":"2019-04-25T17:26:38+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556205997968_-1532207878","id":"20190425-172637_447005151","dateCreated":"2019-04-25T17:26:37+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7837","text":"%md\n### Solution 4.4","dateUpdated":"2019-04-25T17:26:47+0200","dateFinished":"2019-04-25T17:26:47+0200","dateStarted":"2019-04-25T17:26:47+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.4</h3>\n</div>"}]}},{"text":"%spark\ntaxiDataDF.createOrReplaceTempView(\"taxidata\")","user":"anonymous","dateUpdated":"2019-04-25T17:26:56+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206007262_1110816188","id":"20190425-172647_693726556","dateCreated":"2019-04-25T17:26:47+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7910","dateFinished":"2019-04-25T17:26:56+0200","dateStarted":"2019-04-25T17:26:56+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:24: error: not found: value taxiDataDF\n       taxiDataDF.createOrReplaceTempView(\"taxidata\")\n       ^\n"}]}},{"text":"%md\n***Task 4.5***\nSelect all tips smaller 14 and greater 0.01 and fares smaller 60 by using SQL and visualize the outcome with a scatter plot.","user":"anonymous","dateUpdated":"2019-04-25T17:27:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206016033_-1806308620","id":"20190425-172656_576915824","dateCreated":"2019-04-25T17:26:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7999","dateFinished":"2019-04-25T17:27:03+0200","dateStarted":"2019-04-25T17:27:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.5</em></strong><br/>Select all tips smaller 14 and greater 0.01 and fares smaller 60 by using SQL and visualize the outcome with a scatter plot.</p>\n</div>"}]}},{"text":"// Please add your solution in here\n// state '%sql' in the first line to use SQL syntax\n","user":"anonymous","dateUpdated":"2019-04-25T17:27:12+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206023006_-1714024546","id":"20190425-172703_1782622114","dateCreated":"2019-04-25T17:27:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8088","dateFinished":"2019-04-25T17:27:09+0200","dateStarted":"2019-04-25T17:27:09+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206029491_249864241","id":"20190425-172709_445977379","dateCreated":"2019-04-25T17:27:09+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8178","text":"%md\n### Solution 4.5","dateUpdated":"2019-04-25T17:27:27+0200","dateFinished":"2019-04-25T17:27:27+0200","dateStarted":"2019-04-25T17:27:27+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.5</h3>\n</div>"}]}},{"text":"%sql\nSELECT tip_amount, fare_amount FROM taxidata WHERE tip_amount < 14.0 AND tip_amount > 0.01 AND fare_amount < 60.0","user":"anonymous","dateUpdated":"2019-04-25T17:27:34+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206047710_111499254","id":"20190425-172727_888193125","dateCreated":"2019-04-25T17:27:27+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8267","dateFinished":"2019-04-25T17:27:35+0200","dateStarted":"2019-04-25T17:27:34+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: taxidata; line 1 pos 36\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n***Task 4.6***\nCalculate the correlation between tips greater 0.01 and smaller 14 as well as the fare smaller 60. ","user":"anonymous","dateUpdated":"2019-04-25T17:27:48+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206054863_-1402801926","id":"20190425-172734_570788527","dateCreated":"2019-04-25T17:27:34+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8356","dateFinished":"2019-04-25T17:27:48+0200","dateStarted":"2019-04-25T17:27:48+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.6</em></strong><br/>Calculate the correlation between tips greater 0.01 and smaller 14 as well as the fare smaller 60.</p>\n</div>"}]}},{"text":"// Please add your solution in here\n// state '%sql' in the first line to use SQL syntax\n","user":"anonymous","dateUpdated":"2019-04-25T17:27:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206067999_-1887828342","id":"20190425-172747_2082717626","dateCreated":"2019-04-25T17:27:47+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8454","dateFinished":"2019-04-25T17:27:56+0200","dateStarted":"2019-04-25T17:27:56+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206075981_265868625","id":"20190425-172755_1151657450","dateCreated":"2019-04-25T17:27:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8544","text":"%md\n### Solution 4.6","dateUpdated":"2019-04-25T17:28:24+0200","dateFinished":"2019-04-25T17:28:24+0200","dateStarted":"2019-04-25T17:28:24+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.6</h3>\n</div>"}]}},{"text":"%sql\nSELECT CORR(tip_amount, fare_amount) FROM taxidata WHERE tip_amount BETWEEN 0.01 AND 14.0 AND fare_amount < 60.0","user":"anonymous","dateUpdated":"2019-04-25T17:28:32+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206104527_647763379","id":"20190425-172824_1923069258","dateCreated":"2019-04-25T17:28:24+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8630","dateFinished":"2019-04-25T17:28:32+0200","dateStarted":"2019-04-25T17:28:32+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: taxidata; line 1 pos 42\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n***Task 4.7***\nQuery the average tip amount by passenger count for tips greater than 0 and sort it by average tip amount.","user":"anonymous","dateUpdated":"2019-04-25T17:28:39+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206112174_1808356787","id":"20190425-172832_595350554","dateCreated":"2019-04-25T17:28:32+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8719","dateFinished":"2019-04-25T17:28:39+0200","dateStarted":"2019-04-25T17:28:39+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.7</em></strong><br/>Query the average tip amount by passenger count for tips greater than 0 and sort it by average tip amount.</p>\n</div>"}]}},{"text":"%sql\n","user":"anonymous","dateUpdated":"2019-04-25T17:28:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206119477_2033419686","id":"20190425-172839_121714281","dateCreated":"2019-04-25T17:28:39+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8808"},{"text":"%md\n### Solution 4.7","user":"anonymous","dateUpdated":"2019-04-25T17:29:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206135813_-1865410402","id":"20190425-172855_1659774292","dateCreated":"2019-04-25T17:28:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8897","dateFinished":"2019-04-25T17:29:09+0200","dateStarted":"2019-04-25T17:29:09+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.7</h3>\n</div>"}]}},{"text":"%sql\nSELECT passenger_count, AVG(tip_amount) AS average_tip FROM taxidata WHERE tip_amount > 0.0 GROUP BY passenger_count ORDER BY average_tip DESC","user":"anonymous","dateUpdated":"2019-04-25T17:29:17+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206149345_398494617","id":"20190425-172909_52164952","dateCreated":"2019-04-25T17:29:09+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8970","dateFinished":"2019-04-25T17:29:17+0200","dateStarted":"2019-04-25T17:29:17+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: taxidata; line 1 pos 60\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n***Task 4.8***\nQuery the percentage tips of fares by payment type for tips greater 0 and sort it by percentage.","user":"anonymous","dateUpdated":"2019-04-25T17:29:26+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206157202_1198989357","id":"20190425-172917_1358031847","dateCreated":"2019-04-25T17:29:17+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9059","dateFinished":"2019-04-25T17:29:26+0200","dateStarted":"2019-04-25T17:29:26+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.8</em></strong><br/>Query the percentage tips of fares by payment type for tips greater 0 and sort it by percentage.</p>\n</div>"}]}},{"text":"%sql\n","user":"anonymous","dateUpdated":"2019-04-25T17:29:32+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206166228_1070362989","id":"20190425-172926_1140946882","dateCreated":"2019-04-25T17:29:26+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9148"},{"text":"%md\n### Solution 4.8","user":"anonymous","dateUpdated":"2019-04-25T17:29:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206176484_1445434721","id":"20190425-172936_1480726196","dateCreated":"2019-04-25T17:29:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9237","dateFinished":"2019-04-25T17:29:44+0200","dateStarted":"2019-04-25T17:29:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.8</h3>\n</div>"}]}},{"text":"%sql\nSELECT payment_type, AVG(tip_amount), AVG(fare_amount), (AVG(tip_amount / fare_amount))*100 AS tip_percent FROM taxidata WHERE tip_amount > 0.0 GROUP BY payment_type ORDER BY tip_percent DESC ","user":"anonymous","dateUpdated":"2019-04-25T17:29:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206184920_-803668493","id":"20190425-172944_794771931","dateCreated":"2019-04-25T17:29:44+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9310","dateFinished":"2019-04-25T17:29:51+0200","dateStarted":"2019-04-25T17:29:51+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: taxidata; line 1 pos 112\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n***Task 4.9***\nQuery the total amount of trips and the average distance per hour (0 until 23) on basis of the pickup time.","user":"anonymous","dateUpdated":"2019-04-25T17:29:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206191096_-1947482999","id":"20190425-172951_778696325","dateCreated":"2019-04-25T17:29:51+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9399","dateFinished":"2019-04-25T17:29:58+0200","dateStarted":"2019-04-25T17:29:58+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 4.9</em></strong><br/>Query the total amount of trips and the average distance per hour (0 until 23) on basis of the pickup time.</p>\n</div>"}]}},{"text":"%sql\n","user":"anonymous","dateUpdated":"2019-04-25T17:30:04+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206198628_-1886597514","id":"20190425-172958_725240347","dateCreated":"2019-04-25T17:29:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9488"},{"text":"%md\n### Solution 4.9","user":"anonymous","dateUpdated":"2019-04-25T17:30:21+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206209469_-1938467324","id":"20190425-173009_2017343162","dateCreated":"2019-04-25T17:30:09+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9577","dateFinished":"2019-04-25T17:30:21+0200","dateStarted":"2019-04-25T17:30:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 4.9</h3>\n</div>"}]}},{"text":"%sql\nSELECT HOUR(pickup_datetime) AS hour, AVG(trip_distance) AS avg_dist, COUNT(*) AS count FROM taxidata GROUP BY HOUR(pickup_datetime) ORDER BY avg_dist DESC","user":"anonymous","dateUpdated":"2019-04-25T17:30:27+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206221296_-620147448","id":"20190425-173021_1715116368","dateCreated":"2019-04-25T17:30:21+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9650","dateFinished":"2019-04-25T17:30:27+0200","dateStarted":"2019-04-25T17:30:27+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: taxidata; line 1 pos 93\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n# Exercise 5 - Performance tuning\n\nIn this exercise we will become familiar with the most common optimization techniques in Spark.\n\nOnce again we will use the *New York City Taxi Dataset* (22 MB zipped parquet files with 999,999 rows)","user":"anonymous","dateUpdated":"2019-04-25T17:30:34+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206227042_-965001008","id":"20190425-173027_612328701","dateCreated":"2019-04-25T17:30:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9739","dateFinished":"2019-04-25T17:30:34+0200","dateStarted":"2019-04-25T17:30:34+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Exercise 5 - Performance tuning</h1>\n<p>In this exercise we will become familiar with the most common optimization techniques in Spark.</p>\n<p>Once again we will use the <em>New York City Taxi Dataset</em> (22 MB zipped parquet files with 999,999 rows)</p>\n</div>"}]}},{"text":"%md\n***Task 5.1***\nLoad NYC Taxi dataset again into a DataFrame and count the amount of rows the dataset is containing. Afterwards repeat this task but this time with caching the DataFrame.","user":"anonymous","dateUpdated":"2019-04-25T17:30:41+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206234639_-1421989886","id":"20190425-173034_538548853","dateCreated":"2019-04-25T17:30:34+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9828","dateFinished":"2019-04-25T17:30:41+0200","dateStarted":"2019-04-25T17:30:41+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.1</em></strong><br/>Load NYC Taxi dataset again into a DataFrame and count the amount of rows the dataset is containing. Afterwards repeat this task but this time with caching the DataFrame.</p>\n</div>"}]}},{"text":"%md\n***Task 5.1.1***\nLoad NYC Taxi dataset into DataFrame and count it without caching. Notice the duration the count is taking.","user":"anonymous","dateUpdated":"2019-04-25T17:30:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206240986_-1389846720","id":"20190425-173040_342018485","dateCreated":"2019-04-25T17:30:40+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9918","dateFinished":"2019-04-25T17:30:46+0200","dateStarted":"2019-04-25T17:30:46+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.1.1</em></strong><br/>Load NYC Taxi dataset into DataFrame and count it without caching. Notice the duration the count is taking.</p>\n</div>"}]}},{"text":"//Load the NYC Taxi dataset into a DataFrame\n","user":"anonymous","dateUpdated":"2019-04-25T17:30:53+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206246860_-1626236034","id":"20190425-173046_682973845","dateCreated":"2019-04-25T17:30:46+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10008","dateFinished":"2019-04-25T17:30:53+0200","dateStarted":"2019-04-25T17:30:53+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206253128_935287684","id":"20190425-173053_1565877814","dateCreated":"2019-04-25T17:30:53+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10097","text":"//Count the amount of rows of this DataFrame\n","dateUpdated":"2019-04-25T17:30:59+0200","dateFinished":"2019-04-25T17:30:59+0200","dateStarted":"2019-04-25T17:30:59+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206259197_454443735","id":"20190425-173059_182982376","dateCreated":"2019-04-25T17:30:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10169","text":"%md\n### Solution 5.1.1","dateUpdated":"2019-04-25T17:31:19+0200","dateFinished":"2019-04-25T17:31:19+0200","dateStarted":"2019-04-25T17:31:19+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 5.1.1</h3>\n</div>"}]}},{"text":"%spark\nval taxi = spark.read.load(\"s3a://bigpicture-guild/nyctaxi/sample_1_month/parquet/\")","user":"anonymous","dateUpdated":"2019-04-25T17:31:38+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206279516_-316601093","id":"20190425-173119_1011465276","dateCreated":"2019-04-25T17:31:19+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10242","dateFinished":"2019-04-25T17:31:38+0200","dateStarted":"2019-04-25T17:31:38+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n  at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 47 elided\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n  at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n  at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n  ... 65 more\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206288414_1263999130","id":"20190425-173128_1457592183","dateCreated":"2019-04-25T17:31:28+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10332","text":"taxi.count()","dateUpdated":"2019-04-25T17:31:45+0200","dateFinished":"2019-04-25T17:31:45+0200","dateStarted":"2019-04-25T17:31:45+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:24: error: not found: value taxi\n       taxi.count()\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206305744_-876404445","id":"20190425-173145_821309631","dateCreated":"2019-04-25T17:31:45+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10469","text":"%md\n***Task 5.1.2***\nNow load the same dataset into a second DataFrame and count it again. Notice the duration of the second count and compare it with the first count.","dateUpdated":"2019-04-25T17:31:55+0200","dateFinished":"2019-04-25T17:31:55+0200","dateStarted":"2019-04-25T17:31:55+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.1.2</em></strong><br/>Now load the same dataset into a second DataFrame and count it again. Notice the duration of the second count and compare it with the first count.</p>\n</div>"}]}},{"text":"//Load the same dataset into a second DataFrame\n","user":"anonymous","dateUpdated":"2019-04-25T17:32:04+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206315176_-1904533008","id":"20190425-173155_352422840","dateCreated":"2019-04-25T17:31:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10558","dateFinished":"2019-04-25T17:32:04+0200","dateStarted":"2019-04-25T17:32:04+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206324089_-324498635","id":"20190425-173204_327561529","dateCreated":"2019-04-25T17:32:04+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10647","text":"//Count the amount of rows of the second DataFrame\n","dateUpdated":"2019-04-25T17:32:10+0200","dateFinished":"2019-04-25T17:32:10+0200","dateStarted":"2019-04-25T17:32:10+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206330334_1091815835","id":"20190425-173210_946666382","dateCreated":"2019-04-25T17:32:10+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10719","text":"%md\n### Solution 5.1.2","dateUpdated":"2019-04-25T17:32:22+0200","dateFinished":"2019-04-25T17:32:22+0200","dateStarted":"2019-04-25T17:32:22+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 5.1.2</h3>\n</div>"}]}},{"text":"%spark\nval taxi2 = spark.read.load(\"s3a://bigpicture-guild/nyctaxi/sample_1_month/parquet/\")\ntaxi2.cache()","user":"anonymous","dateUpdated":"2019-04-25T17:32:36+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206342641_98388289","id":"20190425-173222_1068985250","dateCreated":"2019-04-25T17:32:22+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10792","dateFinished":"2019-04-25T17:32:36+0200","dateStarted":"2019-04-25T17:32:36+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n  at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 47 elided\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n  at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n  at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n  ... 65 more\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206348041_-1716985236","id":"20190425-173228_1162429317","dateCreated":"2019-04-25T17:32:28+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10882","text":"taxi2.count()","dateUpdated":"2019-04-25T17:32:48+0200","dateFinished":"2019-04-25T17:32:48+0200","dateStarted":"2019-04-25T17:32:48+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:24: error: not found: value taxi2\n       taxi2.count()\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206368305_-407873670","id":"20190425-173248_148165462","dateCreated":"2019-04-25T17:32:48+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11016","text":"%md\n***Task 5.1.3*** Have a look into the Spark web UI and become familiar with its tabs. Can you see differences by comparing `5.1.1` and `5.1.2` in the Spark web UI (DAG, Event timeline, stages, durations, shufflings, etc.)?","dateUpdated":"2019-04-25T17:32:55+0200","dateFinished":"2019-04-25T17:32:55+0200","dateStarted":"2019-04-25T17:32:55+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.1.3</em></strong> Have a look into the Spark web UI and become familiar with its tabs. Can you see differences by comparing <code>5.1.1</code> and <code>5.1.2</code> in the Spark web UI (DAG, Event timeline, stages, durations, shufflings, etc.)?</p>\n</div>"}]}},{"text":"%md\n***Task 5.2***\nConvert the DataFrame of ***Task 5.1.1*** into a RDD and output every single row of the DataFrame. Afterwards only output the first 100 rows. Compare the duration these commands took.","user":"anonymous","dateUpdated":"2019-04-25T17:33:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206375508_635315857","id":"20190425-173255_1225477194","dateCreated":"2019-04-25T17:32:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11105","dateFinished":"2019-04-25T17:33:01+0200","dateStarted":"2019-04-25T17:33:01+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.2</em></strong><br/>Convert the DataFrame of <strong><em>Task 5.1.1</em></strong> into a RDD and output every single row of the DataFrame. Afterwards only output the first 100 rows. Compare the duration these commands took.</p>\n</div>"}]}},{"text":"%md\n***Task 5.2.1*** Convert the DataFrame of ***Task 5.1.1*** into a RDD and output every single row.","user":"anonymous","dateUpdated":"2019-04-25T17:33:07+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206381341_-149682956","id":"20190425-173301_908674369","dateCreated":"2019-04-25T17:33:01+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11195","dateFinished":"2019-04-25T17:33:07+0200","dateStarted":"2019-04-25T17:33:07+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.2.1</em></strong> Convert the DataFrame of <strong><em>Task 5.1.1</em></strong> into a RDD and output every single row.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:33:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206387348_-1197798357","id":"20190425-173307_1907504051","dateCreated":"2019-04-25T17:33:07+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11285","dateFinished":"2019-04-25T17:33:13+0200","dateStarted":"2019-04-25T17:33:13+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206393656_2138056363","id":"20190425-173313_1169709003","dateCreated":"2019-04-25T17:33:13+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11374","text":"%md\n### Solution 5.2.1","dateUpdated":"2019-04-25T17:33:25+0200","dateFinished":"2019-04-25T17:33:25+0200","dateStarted":"2019-04-25T17:33:25+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 5.2.1</h3>\n</div>"}]}},{"text":"%spark\nval taxiRDD = taxi.rdd\ntaxiRDD.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:33:37+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206405126_2122389225","id":"20190425-173325_81990863","dateCreated":"2019-04-25T17:33:25+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11447","dateFinished":"2019-04-25T17:33:37+0200","dateStarted":"2019-04-25T17:33:37+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:23: error: not found: value taxi\n       val taxiRDD = taxi.rdd\n                     ^\n"}]}},{"text":"%md\n***Task 5.2.2*** Now let´s output only the first 100 rows and compare the durations.","user":"anonymous","dateUpdated":"2019-04-25T17:33:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206417510_-992897370","id":"20190425-173337_1143355018","dateCreated":"2019-04-25T17:33:37+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11536","dateFinished":"2019-04-25T17:33:44+0200","dateStarted":"2019-04-25T17:33:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.2.2</em></strong> Now let´s output only the first 100 rows and compare the durations.</p>\n</div>"}]}},{"text":"//Please add your solution in here\n","user":"anonymous","dateUpdated":"2019-04-25T17:33:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206424724_390189473","id":"20190425-173344_1300592355","dateCreated":"2019-04-25T17:33:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11625","dateFinished":"2019-04-25T17:33:51+0200","dateStarted":"2019-04-25T17:33:51+0200","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206431099_-1528891904","id":"20190425-173351_772082722","dateCreated":"2019-04-25T17:33:51+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11714","text":"%md\n### Solution 5.2.2","dateUpdated":"2019-04-25T17:34:01+0200","dateFinished":"2019-04-25T17:34:01+0200","dateStarted":"2019-04-25T17:34:01+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 5.2.2</h3>\n</div>"}]}},{"text":"%spark\ntaxiRDD.take(100).foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:34:17+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206441215_-912015306","id":"20190425-173401_932726077","dateCreated":"2019-04-25T17:34:01+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11787","dateFinished":"2019-04-25T17:34:17+0200","dateStarted":"2019-04-25T17:34:17+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:24: error: not found: value taxiRDD\n       taxiRDD.take(100).foreach(println)\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206450248_-2121821662","id":"20190425-173410_1444104119","dateCreated":"2019-04-25T17:34:10+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11877","text":"%md\n***Task 5.3.1*** The subsequent code snippet finds all prime numbers between 2 and 2 million and displays 10 primes. Find out how to determine the number of partitions after each operation. Notice the duration the whole code snippet took.","dateUpdated":"2019-04-25T17:34:29+0200","dateFinished":"2019-04-25T17:34:29+0200","dateStarted":"2019-04-25T17:34:29+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.3.1</em></strong> The subsequent code snippet finds all prime numbers between 2 and 2 million and displays 10 primes. Find out how to determine the number of partitions after each operation. Notice the duration the whole code snippet took.</p>\n</div>"}]}},{"text":"%spark\n//Please add your completions in here\n\n//Construct all non-primes from 2 to 2 million (duplicates are tolerated)\nval nonPrimes = sc.parallelize(2 to 2000000)\n                  .map(x => (x, (2 to (2000000 / x))))\n\nval nonPrimesFlat = nonPrimes.flatMap(kv => kv._2.map(_ * kv._1))\n\n//Get all primes by excluding all non-primes from 2 to 2 million\nval prime = sc.parallelize(2 to 2000000).subtract(nonPrimesFlat)\n\n//Display 10 primes\nprintln(\"*************** RESULT ***************\")\nprime.take(10).foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:34:42+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206469274_-1837673820","id":"20190425-173429_1188232389","dateCreated":"2019-04-25T17:34:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11995","dateFinished":"2019-04-25T17:35:06+0200","dateStarted":"2019-04-25T17:34:42+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"*************** RESULT ***************\n2\n3\n5\n7\n11\n13\n17\n19\n23\n29\nnonPrimes: org.apache.spark.rdd.RDD[(Int, scala.collection.immutable.Range.Inclusive)] = MapPartitionsRDD[12] at map at <console>:29\nnonPrimesFlat: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[13] at flatMap at <console>:31\nprime: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[18] at subtract at <console>:34\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=7"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Solution 5.3.1","user":"anonymous","dateUpdated":"2019-04-25T17:34:59+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206482560_1851101034","id":"20190425-173442_1066781276","dateCreated":"2019-04-25T17:34:42+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12084","dateFinished":"2019-04-25T17:34:59+0200","dateStarted":"2019-04-25T17:34:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 5.3.1</h3>\n</div>"}]}},{"text":"%spark\n//Construct all non-primes from 2 to 2 million (duplicates are tolerated)\nval nonPrimes = sc.parallelize(2 to 2000000)\n                  .map(x => (x, (2 to (2000000 / x))))\nprintln(\"nonPrimes is distributed across \" + nonPrimes.getNumPartitions.toString + \" partitions\")\n\nval nonPrimesFlat = nonPrimes.flatMap(kv => kv._2.map(_ * kv._1))\nprintln(\"nonPrimesFlat is distributed across \" + nonPrimesFlat.getNumPartitions.toString + \" partitions\")\n\n//Get all primes by excluding all non-primes from 2 to 2 million\nval prime = sc.parallelize(2 to 2000000).subtract(nonPrimesFlat)\nprintln(\"prime is distributed across \" + prime.getNumPartitions.toString + \" partitions\")\n\n//Display 10 primes\nprintln(\"*************** RESULT ***************\")\nprime.take(10).foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:35:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206499680_-353982856","id":"20190425-173459_1611859691","dateCreated":"2019-04-25T17:34:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12200","dateFinished":"2019-04-25T17:35:37+0200","dateStarted":"2019-04-25T17:35:13+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"nonPrimes is distributed across 1 partitions\nnonPrimesFlat is distributed across 1 partitions\nprime is distributed across 1 partitions\n*************** RESULT ***************\n2\n3\n5\n7\n11\n13\n17\n19\n23\n29\nnonPrimes: org.apache.spark.rdd.RDD[(Int, scala.collection.immutable.Range.Inclusive)] = MapPartitionsRDD[20] at map at <console>:31\nnonPrimesFlat: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[21] at flatMap at <console>:34\nprime: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[26] at subtract at <console>:38\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.178.115:4040/jobs/job?id=8"],"interpreterSettingId":"spark"}}},{"text":"%md\n***Task 5.3.2*** Now try to optimize the code of Task 5.3.1 by using `repartition`. Remember the rule of thumb for repartitioning and figure out the necessary information for applying it. Notice the duration the whole code snippet is taking now.","user":"anonymous","dateUpdated":"2019-04-25T17:35:26+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206513693_184658561","id":"20190425-173513_370475906","dateCreated":"2019-04-25T17:35:13+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12289","dateFinished":"2019-04-25T17:35:26+0200","dateStarted":"2019-04-25T17:35:26+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Task 5.3.2</em></strong> Now try to optimize the code of Task 5.3.1 by using <code>repartition</code>. Remember the rule of thumb for repartitioning and figure out the necessary information for applying it. Notice the duration the whole code snippet is taking now.</p>\n</div>"}]}},{"text":"%spark\n//Please add your completions in here\n\n//Construct all non-primes from 2 to 2 million (duplicates are tolerated)\nval nonPrimes = sc.parallelize(2 to 2000000)\n                  .map(x => (x, (2 to (2000000 / x))))\n\nval nonPrimesFlat = nonPrimes.flatMap(kv => kv._2.map(_ * kv._1))\n\n//Get all primes by excluding all non-primes from 2 to 2 million\nval prime = sc.parallelize(2 to 2000000).subtract(nonPrimesFlat)\n\n//Display 10 primes\nprintln(\"*************** RESULT ***************\")\nprime.take(10).foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:35:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206526229_10870387","id":"20190425-173526_1073068552","dateCreated":"2019-04-25T17:35:26+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12405"},{"text":"%md\n### Solution 5.3.2","user":"anonymous","dateUpdated":"2019-04-25T17:36:00+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206549684_-816262513","id":"20190425-173549_162373151","dateCreated":"2019-04-25T17:35:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12494","dateFinished":"2019-04-25T17:36:00+0200","dateStarted":"2019-04-25T17:36:00+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution 5.3.2</h3>\n</div>"}]}},{"text":"%spark\n//Construct all non-primes from 2 to 2 million (duplicates are tolerated)\nval nonPrimes = sc.parallelize(2 to 2000000)\n                  .map(x => (x, (2 to (2000000 / x))))\nprintln(nonPrimes.getNumPartitions)                  \n\n//Rule of thumb: number of partitions = cores per CPU * CPU per cluster * 2 or 3\nval nonPrimesRep = nonPrimes.repartition(36)\nprintln(nonPrimesRep.getNumPartitions)\n\nval nonPrimesRepFlat = nonPrimesRep.flatMap(kv => kv._2.map(_ * kv._1))                \nprintln(nonPrimesRepFlat.getNumPartitions)\n\n//Get all primes by excluding all non-primes from 2 to 2 million\nval prime = sc.parallelize(2 to 2000000).subtract(nonPrimesRepFlat)\nprintln(prime.getNumPartitions)\n\n//Dispaly 10 primes\nprime.take(10).foreach(println)","user":"anonymous","dateUpdated":"2019-04-25T17:36:18+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556206560025_-2082011657","id":"20190425-173600_877570879","dateCreated":"2019-04-25T17:36:00+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12567"}],"name":"/6. Exercises/6.1 Exerises - Scala","id":"2EAGTVBPJ","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}