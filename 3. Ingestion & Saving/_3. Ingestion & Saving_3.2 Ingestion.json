{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969038_1738930823","id":"20190424-172718_1736239905","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18304"},{"text":"%md\n# 3.2 Ingestion","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>3.2 Ingestion</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969042_-491943993","id":"20190424-172735_1365411266","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18305"},{"text":"%md\n***3.2.1 DataFrame ingestion***\n\n* Common `.DataFrameReader` settings\n\n* Providing data source path\n\n* Examples for DataFrame ingestion out of a data source\n\n* Example for creating DataFrames out of in-memory data\n\n***3.2.2 Dataset ingestion***\n\n* Ingestion of text files with `.textFile`\n\n* Example for Dataset ingestion out of text files\n\n* Example for Dataset ingestion out of in-memory data\n\n***3.2.3 RDD ingestion***\n\n* Ingestion of a single text file with `.textFile`\n\n* Ingestion of multiple text files with `.wholeTextFile`\n\n* Example for RDD ingestion out of a single text file\n\n* Example for RDD ingestion of multiple text files\n\n* Example for RDD ingestion out of in-memory data","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>3.2.1 DataFrame ingestion</em></strong></p>\n<ul>\n  <li>\n  <p>Common <code>.DataFrameReader</code> settings</p></li>\n  <li>\n  <p>Providing data source path</p></li>\n  <li>\n  <p>Examples for DataFrame ingestion out of a data source</p></li>\n  <li>\n  <p>Example for creating DataFrames out of in-memory data</p></li>\n</ul>\n<p><strong><em>3.2.2 Dataset ingestion</em></strong></p>\n<ul>\n  <li>\n  <p>Ingestion of text files with <code>.textFile</code></p></li>\n  <li>\n  <p>Example for Dataset ingestion out of text files</p></li>\n  <li>\n  <p>Example for Dataset ingestion out of in-memory data</p></li>\n</ul>\n<p><strong><em>3.2.3 RDD ingestion</em></strong></p>\n<ul>\n  <li>\n  <p>Ingestion of a single text file with <code>.textFile</code></p></li>\n  <li>\n  <p>Ingestion of multiple text files with <code>.wholeTextFile</code></p></li>\n  <li>\n  <p>Example for RDD ingestion out of a single text file</p></li>\n  <li>\n  <p>Example for RDD ingestion of multiple text files</p></li>\n  <li>\n  <p>Example for RDD ingestion out of in-memory data</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969043_1813145541","id":"20190424-172741_1272823798","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18306"},{"text":"%md\n## 3.2.1 DataFrame ingestion\n\nA DataFrame can be loaded with `spark.read`which creates a `DataFrameReader` object.\nWith the settings of the `DataFrameReader` it´s possbile to influence the process of reading in data.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>3.2.1 DataFrame ingestion</h2>\n<p>A DataFrame can be loaded with <code>spark.read</code>which creates a <code>DataFrameReader</code> object.<br/>With the settings of the <code>DataFrameReader</code> it´s possbile to influence the process of reading in data.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969044_30094715","id":"20190424-172752_1781729318","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18307"},{"text":"%md\n### Common DataFrameReader settings\n\n*   `.format`: Specifies the type of the data source (e.g. CSV, JSON, Parquet, etc.)\n\n*   `.option`: Additional key-value settings (e.g. \"Header\",\"true\")\n\n*   `.schema`: Specifies the schema without inferencing\n\n*   `.load`:   For loading data out of files. `.load` without `.format` reads in Parquet as default.\n\n*   `.table`:  For loading data out of Hive tables\n\n*   `.csv`, `.json` etc: Instead of using `.load` one can use format specific short cuts.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Common DataFrameReader settings</h3>\n<ul>\n  <li>\n  <p><code>.format</code>: Specifies the type of the data source (e.g. CSV, JSON, Parquet, etc.)</p></li>\n  <li>\n  <p><code>.option</code>: Additional key-value settings (e.g. &ldquo;Header&rdquo;,&ldquo;true&rdquo;)</p></li>\n  <li>\n  <p><code>.schema</code>: Specifies the schema without inferencing</p></li>\n  <li>\n  <p><code>.load</code>: For loading data out of files. <code>.load</code> without <code>.format</code> reads in Parquet as default.</p></li>\n  <li>\n  <p><code>.table</code>: For loading data out of Hive tables</p></li>\n  <li>\n  <p><code>.csv</code>, <code>.json</code> etc: Instead of using <code>.load</code> one can use format specific short cuts.</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969046_-30804397","id":"20190424-172801_7208871","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18308"},{"text":"%md\n### Providing data source path\n\nThe data source path has to be provided inside `.load` respectively inside the format specific equivalents.\n\nYou can specify the path for...\n\n* **single files**      ->     spark.read.csv(\"oneFile.csv\")\n\n* **list of files** -> spark.read.csv(\"firstFile.csv\",\"secondFile.csv\")\n\n* **directories** -> spark.read.csv(\"directory/\")\n\n* **wildcard list of files** -> spark.read.csv(\"directory/*.csv\")","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Providing data source path</h3>\n<p>The data source path has to be provided inside <code>.load</code> respectively inside the format specific equivalents.</p>\n<p>You can specify the path for&hellip;</p>\n<ul>\n  <li>\n  <p><strong>single files</strong> -&gt; spark.read.csv(&ldquo;oneFile.csv&rdquo;)</p></li>\n  <li>\n  <p><strong>list of files</strong> -&gt; spark.read.csv(&ldquo;firstFile.csv&rdquo;,&ldquo;secondFile.csv&rdquo;)</p></li>\n  <li>\n  <p><strong>directories</strong> -&gt; spark.read.csv(&ldquo;directory/&rdquo;)</p></li>\n  <li>\n  <p><strong>wildcard list of files</strong> -&gt; spark.read.csv(&ldquo;directory/*.csv&rdquo;)</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969046_473989182","id":"20190424-172811_1821630138","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18309"},{"text":"%md\n### Examples for DataFrame ingestions out of data sources","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Examples for DataFrame ingestions out of data sources</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969047_1830954300","id":"20190424-172831_1396428840","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18310"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T07:50:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969047_-1259499997","id":"20190424-172840_1914333283","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:50:43+0000","dateFinished":"2019-05-21T07:50:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18311"},{"text":"%spark\n// Read in Parquet file...\nval songDF1 = spark.read\n                   .load(\"s3a://cs-spark-basic-training/Songs/\")\nsongDF1.show(false)\n\n// ...is equivalent to\nval songDF2 = spark.read\n                   .format(\"parquet\")\n                   .load(\"s3a://cs-spark-basic-training/Songs/\")\nsongDF2.show(false)\n\n\n\n// Read in CSV file and specifiy some DataFrameReader settings...\nval songDF3 = spark.read\n                   .option(\"header\", true)   // Take first row as header\n                   .csv(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")   // .csv is a format specific shortcut for `.load`\nsongDF3.show(false)\n\n// ...is equivalent to\nval songDF4 = spark.read\n                   .format(\"csv\")\n                   .option(\"header\", true)   // Take first row as header\n                   .load(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")\nsongDF4.show(false)","user":"anonymous","dateUpdated":"2019-05-21T08:17:09+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{"0":{"graph":{"mode":"table","height":414,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|artist       |loudness|\n+-------------+--------+\n|Frank Sinatra|-10.0   |\n|Beastie Boys |-5.0    |\n|Muse         |-7.0    |\n+-------------+--------+\n\n+-------------+--------+\n|artist       |loudness|\n+-------------+--------+\n|Frank Sinatra|-10.0   |\n|Beastie Boys |-5.0    |\n|Muse         |-7.0    |\n+-------------+--------+\n\n+------------+--------+--------------------------+\n|artist      |loudness|songs                     |\n+------------+--------+--------------------------+\n|BeastieBoys |-5.0    |Sabotage,Intergalactic    |\n|FrankSinatra|-10.0   |MyWay                     |\n|Muse        |-7.0    |Uprising,Starlight,Madness|\n+------------+--------+--------------------------+\n\n+------------+--------+--------------------------+\n|artist      |loudness|songs                     |\n+------------+--------+--------------------------+\n|BeastieBoys |-5.0    |Sabotage,Intergalactic    |\n|FrankSinatra|-10.0   |MyWay                     |\n|Muse        |-7.0    |Uprising,Starlight,Madness|\n+------------+--------+--------------------------+\n\nsongDF1: org.apache.spark.sql.DataFrame = [artist: string, loudness: double]\nsongDF2: org.apache.spark.sql.DataFrame = [artist: string, loudness: double]\nsongDF3: org.apache.spark.sql.DataFrame = [artist: string, loudness: string ... 1 more field]\nsongDF4: org.apache.spark.sql.DataFrame = [artist: string, loudness: string ... 1 more field]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=21","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=22","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=23","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=24","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=25","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=26","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=27","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=28","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=29","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=30"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558424969047_-89551794","id":"20190424-172849_1907259567","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T08:17:09+0000","dateFinished":"2019-05-21T08:17:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18312"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T07:51:35+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969047_-1458840038","id":"20190424-172855_1901339109","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:51:35+0000","dateFinished":"2019-05-21T07:51:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18313"},{"text":"%pyspark\n# Read in Parquet file...\nsongDF1 = spark.read.load(\"s3a://cs-spark-basic-training/Songs/\")\nsongDF1.show()\n\n# ...is equivalent to\nsongDF2 = spark.read.format(\"parquet\").load(\"s3a://cs-spark-basic-training/Songs/\")\nsongDF2.show()\n\n\n\n# Read in CSV file and specifiy some DataFrameReader settings...\nsongDF3 = spark.read.option(\"header\", True).csv(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")\nsongDF3.show()\n\n# ...is equivalent to\nsongDF4 = spark.read.format(\"csv\").option(\"header\", True).load(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")\nsongDF4.show()","user":"anonymous","dateUpdated":"2019-05-21T08:25:26+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+------------+--------+--------------------+\n|      artist|loudness|               songs|\n+------------+--------+--------------------+\n| BeastieBoys|    -5.0|Sabotage,Intergal...|\n|FrankSinatra|   -10.0|               MyWay|\n|        Muse|    -7.0|Uprising,Starligh...|\n+------------+--------+--------------------+\n\n+------------+--------+--------------------+\n|      artist|loudness|               songs|\n+------------+--------+--------------------+\n| BeastieBoys|    -5.0|Sabotage,Intergal...|\n|FrankSinatra|   -10.0|               MyWay|\n|        Muse|    -7.0|Uprising,Starligh...|\n+------------+--------+--------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1558424969048_-2026331418","id":"20190424-172920_1325604960","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18314","dateFinished":"2019-05-21T08:25:29+0000","dateStarted":"2019-05-21T08:25:26+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=59","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=60","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=61","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=62","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=63","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=64","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=65","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=66","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=67","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=68"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Example for creating DataFrames out of in-memory data\n\nFor creation of DataFrames out of in-memory data one have to use `.createDataFrame`.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Example for creating DataFrames out of in-memory data</h3>\n<p>For creation of DataFrames out of in-memory data one have to use <code>.createDataFrame</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969048_688808131","id":"20190424-172942_226744149","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18315"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T07:50:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969048_979090627","id":"20190424-172959_1239490018","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:50:54+0000","dateFinished":"2019-05-21T07:50:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18316"},{"text":"%spark\n// Manuel creation of in-memory data\nval songList = List((\"Frank Sinatra\", -10.0),(\"Beastie Boys\", -5.0),(\"Muse\", -7.0))\n\n// Create DataFrame out of 'songList'\nval songListDF = spark.createDataFrame(songList)\nsongListDF.show()","user":"anonymous","dateUpdated":"2019-05-21T08:28:38+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+-----+\n|           _1|   _2|\n+-------------+-----+\n|Frank Sinatra|-10.0|\n| Beastie Boys| -5.0|\n|         Muse| -7.0|\n+-------------+-----+\n\nsongList: List[(String, Double)] = List((Frank Sinatra,-10.0), (Beastie Boys,-5.0), (Muse,-7.0))\nsongListDF: org.apache.spark.sql.DataFrame = [_1: string, _2: double]\n"}]},"apps":[],"jobName":"paragraph_1558424969049_-1815289078","id":"20190424-173009_198178339","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18317","dateFinished":"2019-05-21T08:28:39+0000","dateStarted":"2019-05-21T08:28:38+0000"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T07:51:41+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969049_1517856120","id":"20190424-173020_1507656478","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:51:41+0000","dateFinished":"2019-05-21T07:51:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18318"},{"text":"%pyspark\n# Manuel creation of in-memory data\nsongList = [('Frank Sinatra', -10.0),('Beastie Boys', -5.0),('Muse', -7.0)]\n\n# Create DataFrame out of 'songList'\nsongListDF = spark.createDataFrame(songList)\nsongListDF.show()","user":"anonymous","dateUpdated":"2019-05-21T08:29:27+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+-----+\n|           _1|   _2|\n+-------------+-----+\n|Frank Sinatra|-10.0|\n| Beastie Boys| -5.0|\n|         Muse| -7.0|\n+-------------+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1558424969050_1757742111","id":"20190424-173031_1673304913","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18319","dateFinished":"2019-05-21T08:29:36+0000","dateStarted":"2019-05-21T08:29:27+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=71","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=72"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 3.2.2 Dataset ingestion\n\nTo create a Dataset directly out of a source file is only possible for ***text files***. In this case you have to call `spark.read.textFile(\"filePath\")`.\nThere is only one setting `.option(\"wholetext\", true)` applicable which is enabling to read in the whole text into one single row. ","user":"anonymous","dateUpdated":"2019-05-21T08:30:42+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>3.2.2 Dataset ingestion</h2>\n<p>To create a Dataset directly out of a source file is only possible for <strong><em>text files</em></strong>. In this case you have to call <code>spark.read.textFile(&quot;filePath&quot;)</code>.<br/>There is only one setting <code>.option(&quot;wholetext&quot;, true)</code> applicable which is enabling to read in the whole text into one single row.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969050_-1045727106","id":"20190424-173038_1889761016","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18320","dateFinished":"2019-05-21T08:30:42+0000","dateStarted":"2019-05-21T08:30:42+0000"},{"text":"%md\n### Example for Dataset ingestion out of text files","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Example for Dataset ingestion out of text files</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969051_1617148054","id":"20190424-173053_406144507","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18321"},{"text":"%spark\n// Create Dataset out of text file\nval songDS = spark.read.textFile(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")\nsongDS.show(false)   // '.show' truncates by default (truncate: true) long Strings after 20 characters\nsongDS.count()","user":"anonymous","dateUpdated":"2019-05-21T08:37:31+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------------------------------+\n|value                                    |\n+-----------------------------------------+\n|artist,loudness,songs                    |\n|BeastieBoys,-5.0,\"Sabotage,Intergalactic\"|\n|FrankSinatra,-10.0,MyWay                 |\n|Muse,-7.0,\"Uprising,Starlight,Madness\"   |\n+-----------------------------------------+\n\nsongDS: org.apache.spark.sql.Dataset[String] = [value: string]\nres15: Long = 4\n"}]},"apps":[],"jobName":"paragraph_1558424969051_-1044608532","id":"20190424-173100_1713044707","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18322","dateFinished":"2019-05-21T08:37:43+0000","dateStarted":"2019-05-21T08:37:31+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=87","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=88"],"interpreterSettingId":"spark"}}},{"text":"%spark\n// Create Dataset out of text file and apply option `wholetext`\nval songDS = spark.read.option(\"wholetext\", true).textFile(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")   // option 'wholetext' is 'false' by default\nsongDS.show(false)   // '.show' truncates by default (truncate: true) long Strings after 20 characters\nsongDS.count()","user":"anonymous","dateUpdated":"2019-05-21T08:37:39+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------------------------------------------------------------------------------------------------------------------+\n|value                                                                                                                           |\n+--------------------------------------------------------------------------------------------------------------------------------+\n|artist,loudness,songs\nBeastieBoys,-5.0,\"Sabotage,Intergalactic\"\nFrankSinatra,-10.0,MyWay\nMuse,-7.0,\"Uprising,Starlight,Madness\"\n|\n+--------------------------------------------------------------------------------------------------------------------------------+\n\nsongDS: org.apache.spark.sql.Dataset[String] = [value: string]\nres16: Long = 1\n"}]},"apps":[],"jobName":"paragraph_1558424969051_1722363686","id":"20190424-173110_783984531","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18323","dateFinished":"2019-05-21T08:37:44+0000","dateStarted":"2019-05-21T08:37:40+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=89","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=90"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Example for creating Datasets out of in-memory data\n\nFor creation of Datasets out of in-memory data one have to use `.createDataset`.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Example for creating Datasets out of in-memory data</h3>\n<p>For creation of Datasets out of in-memory data one have to use <code>.createDataset</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969052_1570355299","id":"20190424-173119_1040379897","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18324"},{"text":"%spark\n// Create DataFrame out of in-memory data\nval songListDS = spark.createDataset(songList)\nsongListDS.show()","user":"anonymous","dateUpdated":"2019-05-21T08:38:11+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+-----+\n|           _1|   _2|\n+-------------+-----+\n|Frank Sinatra|-10.0|\n| Beastie Boys| -5.0|\n|         Muse| -7.0|\n+-------------+-----+\n\nsongListDS: org.apache.spark.sql.Dataset[(String, Double)] = [_1: string, _2: double]\n"}]},"apps":[],"jobName":"paragraph_1558424969052_464198442","id":"20190424-173135_1458684622","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18325","dateFinished":"2019-05-21T08:38:12+0000","dateStarted":"2019-05-21T08:38:11+0000"},{"text":"%md\n## 3.2.3 RDD ingestion\n\nText files can be loaded with a sparkConext `sc` followed by `.textFile()`.\n\nMulti-line text file can be loaded with a sparkContext `sc` followed by `.wholeTextFiles()`.\n\nIn addition it is possible to control the number of partitions with the 2nd parameter of both methods. For example `sc.textFile(\"path\", 5)` would distribute the data on 5 nodes. For DataFrames and Datasets you can´t control the number of partitions within ingestion.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>3.2.3 RDD ingestion</h2>\n<p>Text files can be loaded with a sparkConext <code>sc</code> followed by <code>.textFile()</code>.</p>\n<p>Multi-line text file can be loaded with a sparkContext <code>sc</code> followed by <code>.wholeTextFiles()</code>.</p>\n<p>In addition it is possible to control the number of partitions with the 2nd parameter of both methods. For example <code>sc.textFile(&quot;path&quot;, 5)</code> would distribute the data on 5 nodes. For DataFrames and Datasets you can´t control the number of partitions within ingestion.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969053_-543296736","id":"20190424-173145_1404496796","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18326"},{"text":"%md\n### Ingestion of a single text file with `.textFile`\n\nMaps each row of the file into a individual RDD.\n\nApplicable for...\n\n* ***Single text files*** -> sc.textFile(\"oneFile.txt\")\n\n* ***Directory of text files*** -> sc.textFile(\"directory/\")\n\n* ***Wildcard list of text files*** -> sc.textFile(\"directory/*.txt\")\n\n* ***List of text files*** -> sc.textFile(\"firstTextFile.txt\",\"secondTextFile.txt\")\n\nApplicable only to newline-delimited text files.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Ingestion of a single text file with <code>.textFile</code></h3>\n<p>Maps each row of the file into a individual RDD.</p>\n<p>Applicable for&hellip;</p>\n<ul>\n  <li>\n  <p><strong><em>Single text files</em></strong> -&gt; sc.textFile(&ldquo;oneFile.txt&rdquo;)</p></li>\n  <li>\n  <p><strong><em>Directory of text files</em></strong> -&gt; sc.textFile(&ldquo;directory/&rdquo;)</p></li>\n  <li>\n  <p><strong><em>Wildcard list of text files</em></strong> -&gt; sc.textFile(&ldquo;directory/*.txt&rdquo;)</p></li>\n  <li>\n  <p><strong><em>List of text files</em></strong> -&gt; sc.textFile(&ldquo;firstTextFile.txt&rdquo;,&ldquo;secondTextFile.txt&rdquo;)</p></li>\n</ul>\n<p>Applicable only to newline-delimited text files.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969053_1553876992","id":"20190424-173158_1860143162","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18327"},{"text":"%md\n## Ingestion of multiple text files with `.wholeTextFiles`\n\nApplicable for multi-line file formats (e.i. XML, JSON, etc.)\n\nMaps whole content of each file in a RDD as a key-value pair of type RDD[(String, String)].","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Ingestion of multiple text files with <code>.wholeTextFiles</code></h2>\n<p>Applicable for multi-line file formats (e.i. XML, JSON, etc.)</p>\n<p>Maps whole content of each file in a RDD as a key-value pair of type RDD[(String, String)].</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969053_-1178809576","id":"20190424-173206_913586574","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18328"},{"text":"%md\n### Example for RDD ingestion out of a single text file","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Example for RDD ingestion out of a single text file</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969054_-1130741284","id":"20190424-173216_264296860","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18329"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T07:51:06+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969054_541649207","id":"20190424-173227_943732525","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:51:06+0000","dateFinished":"2019-05-21T07:51:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18330"},{"text":"%spark\n// Read in a single CSV as text file\nval songRDD = sc.textFile(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")\n\nsongRDD.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-05-21T08:38:44+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"artist,loudness,songs\nBeastieBoys,-5.0,\"Sabotage,Intergalactic\"\nFrankSinatra,-10.0,MyWay\nMuse,-7.0,\"Uprising,Starlight,Madness\"\nsongRDD: org.apache.spark.rdd.RDD[String] = s3a://cs-spark-basic-training/SongDS/SongDS.csv MapPartitionsRDD[329] at textFile at <console>:26\n"}]},"apps":[],"jobName":"paragraph_1558424969055_1997193255","id":"20190424-173235_1792421813","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18331","dateFinished":"2019-05-21T08:38:55+0000","dateStarted":"2019-05-21T08:38:44+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=91"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T07:51:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969055_248594539","id":"20190424-173245_2094772055","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:51:50+0000","dateFinished":"2019-05-21T07:51:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18332"},{"text":"%pyspark\n# Read in a single CSV as text file\nsongRDD = sc.textFile(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\").collect()\n\nfor element in songRDD:\n    print(element)","user":"anonymous","dateUpdated":"2019-05-21T08:40:05+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"artist,loudness,songs\nBeastieBoys,-5.0,\"Sabotage,Intergalactic\"\nFrankSinatra,-10.0,MyWay\nMuse,-7.0,\"Uprising,Starlight,Madness\"\n"}]},"apps":[],"jobName":"paragraph_1558424969056_-988136466","id":"20190424-173254_436182895","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18333","dateFinished":"2019-05-21T08:40:15+0000","dateStarted":"2019-05-21T08:40:05+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=92"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Example for RDD ingestion of multiple text files","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Example for RDD ingestion of multiple text files</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969056_-414121675","id":"20190424-173301_295908340","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18334"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T07:51:12+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969057_-1280870990","id":"20190424-173314_497060504","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:51:12+0000","dateFinished":"2019-05-21T07:51:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18335"},{"text":"%spark\nval multipleFileRDD = sc.wholeTextFiles(\"s3a://cs-spark-basic-training/textDirectory/*\")\n\nmultipleFileRDD.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-05-21T08:42:37+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(s3a://cs-spark-basic-training/textDirectory/textFile1.csv/part-00000,(dbfs:/FileStore/tables/textDirectory/textFile1.csv,This is the first line of the first text file\r\nHere is the second line of the first text file)\n)\n(s3a://cs-spark-basic-training/textDirectory/textFile2.csv/part-00000,(dbfs:/FileStore/tables/textDirectory/textFile2.csv,This is the first line of the second text file\r\nHere is the second line of the second text file)\n)\nmultipleFileRDD: org.apache.spark.rdd.RDD[(String, String)] = s3a://cs-spark-basic-training/textDirectory/* MapPartitionsRDD[335] at wholeTextFiles at <console>:25\n"}]},"apps":[],"jobName":"paragraph_1558424969057_1951741904","id":"20190424-173322_1132184287","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18336","dateFinished":"2019-05-21T08:42:47+0000","dateStarted":"2019-05-21T08:42:37+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=93"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T07:52:02+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969057_-745005756","id":"20190424-173332_857003921","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:52:02+0000","dateFinished":"2019-05-21T07:52:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18337"},{"text":"%pyspark\nmultipleFileRDD = sc.wholeTextFiles(\"s3a://cs-spark-basic-training/textDirectory/*\").collect()\n\nfor element in multipleFileRDD:\n    print(element)","user":"anonymous","dateUpdated":"2019-05-21T08:43:31+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(u's3a://cs-spark-basic-training/textDirectory/textFile1.csv/part-00000', u'(dbfs:/FileStore/tables/textDirectory/textFile1.csv,This is the first line of the first text file\\r\\nHere is the second line of the first text file)\\n')\n(u's3a://cs-spark-basic-training/textDirectory/textFile2.csv/part-00000', u'(dbfs:/FileStore/tables/textDirectory/textFile2.csv,This is the first line of the second text file\\r\\nHere is the second line of the second text file)\\n')\n"}]},"apps":[],"jobName":"paragraph_1558424969058_339281538","id":"20190424-173344_2069309779","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18338","dateFinished":"2019-05-21T08:43:32+0000","dateStarted":"2019-05-21T08:43:31+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=95"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Example for RDD ingestion out of in-memory data\n\nFor creation of RDDs out of in-memory data one have to use `.parallelize`.","user":"anonymous","dateUpdated":"2019-05-21T07:49:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Example for RDD ingestion out of in-memory data</h3>\n<p>For creation of RDDs out of in-memory data one have to use <code>.parallelize</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969058_1784105328","id":"20190424-173355_1142755991","dateCreated":"2019-05-21T07:49:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:18339"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T07:51:22+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969059_-907942285","id":"20190424-173406_1475455515","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:51:22+0000","dateFinished":"2019-05-21T07:51:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18340"},{"text":"%spark\n// Parallelize 'songList'\nval songRddList = sc.parallelize(songList)\n\nsongRddList.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-05-21T08:44:14+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(Frank Sinatra,-10.0)\n(Beastie Boys,-5.0)\n(Muse,-7.0)\nsongRddList: org.apache.spark.rdd.RDD[(String, Double)] = ParallelCollectionRDD[342] at parallelize at <console>:28\n"}]},"apps":[],"jobName":"paragraph_1558424969060_127825831","id":"20190424-173414_1941438649","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18341","dateFinished":"2019-05-21T08:44:15+0000","dateStarted":"2019-05-21T08:44:14+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=96"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T07:52:07+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558424969060_1089118465","id":"20190424-173431_767871192","dateCreated":"2019-05-21T07:49:29+0000","dateStarted":"2019-05-21T07:52:07+0000","dateFinished":"2019-05-21T07:52:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18342"},{"text":"%pyspark\n# Parallelize 'songList'\nsongRddList = sc.parallelize(songList).collect()\n\nfor element in songRddList:\n    print(element)","user":"anonymous","dateUpdated":"2019-05-21T08:45:13+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"('Frank Sinatra', -10.0)\n('Beastie Boys', -5.0)\n('Muse', -7.0)\n"}]},"apps":[],"jobName":"paragraph_1558424969060_1355793872","id":"20190424-173442_836599914","dateCreated":"2019-05-21T07:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18343","dateFinished":"2019-05-21T08:45:13+0000","dateStarted":"2019-05-21T08:45:13+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=98"],"interpreterSettingId":"spark"}}}],"name":"/3. Ingestion & Saving/3.2 Ingestion","id":"2ECQXDX4Q","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}