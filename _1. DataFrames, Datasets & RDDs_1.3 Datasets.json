{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575846_-337579675","id":"20190424-151029_271323062","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:23536"},{"text":"%md\n# 1.3 Datasets","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.3 Datasets</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575847_313986372","id":"20190424-151036_611950532","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23537"},{"text":"%md\n***1.3.1 Datasets in general***\n\n***1.3.2 Dataset example***\n\n***1.3.3 Dataset API (high-level operations)***\n\n***1.3.4 Dataset API (low-level operations)***\n\n***1.3.5 Case classes***\n\n* 1.3.5.1 Define case class\n\n* 1.3.5.2 Create Datasets from case class\n\n* 1.3.5.3 Dataset API\n\n* 1.3.5.4 Customized functions inside case class","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>1.3.1 Datasets in general</em></strong></p>\n<p><strong><em>1.3.2 Dataset example</em></strong></p>\n<p><strong><em>1.3.3 Dataset API (high-level operations)</em></strong></p>\n<p><strong><em>1.3.4 Dataset API (low-level operations)</em></strong></p>\n<p><strong><em>1.3.5 Case classes</em></strong></p>\n<ul>\n  <li>\n  <p>1.3.5.1 Define case class</p></li>\n  <li>\n  <p>1.3.5.2 Create Datasets from case class</p></li>\n  <li>\n  <p>1.3.5.3 Dataset API</p></li>\n  <li>\n  <p>1.3.5.4 Customized functions inside case class</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575847_2144870703","id":"20190424-151042_1564811121","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23538"},{"text":"%md \n## 1.3.1 Datasets in general\n\n*   **Dataset API** - *Strongly typed* collection of domain-specific objects - [Dataset Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset)\n      * Can be transformed in parallel using functional or relational operations\n      * Available in Scala API only\n      * Higher-level implementation of an RDD with more built-in functionality\n      * Most useful for semi-structured data with a predictable type, or can be defined using a Scala case class.\n      * Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.\n      * Adding type information drastically improves memory usage when caching data\n      * Datasets offer type-checking at compile time\n      * In comparison to DataFrames, DataSets can´t get loaded from files (conversion of DataFrame or RDD to Dataset necessary)\n      * Datasets use RDDs internally and provide therefore similar in comparison to RDDs.\n      * Datasets automatically apply optimizations before executing operations. This results in an increased performance compared to RDDs.","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.1 Datasets in general</h2>\n<ul>\n  <li><strong>Dataset API</strong> - <em>Strongly typed</em> collection of domain-specific objects - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset Scaladoc</a>\n    <ul>\n      <li>Can be transformed in parallel using functional or relational operations</li>\n      <li>Available in Scala API only</li>\n      <li>Higher-level implementation of an RDD with more built-in functionality</li>\n      <li>Most useful for semi-structured data with a predictable type, or can be defined using a Scala case class.</li>\n      <li>Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.</li>\n      <li>Adding type information drastically improves memory usage when caching data</li>\n      <li>Datasets offer type-checking at compile time</li>\n      <li>In comparison to DataFrames, DataSets can´t get loaded from files (conversion of DataFrame or RDD to Dataset necessary)</li>\n      <li>Datasets use RDDs internally and provide therefore similar in comparison to RDDs.</li>\n      <li>Datasets automatically apply optimizations before executing operations. This results in an increased performance compared to RDDs.</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575847_-1380398040","id":"20190424-151048_970088704","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23539"},{"text":"%md\n## 1.3.2 Dataset example","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.2 Dataset example</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575847_1376466235","id":"20190424-151054_1962013627","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23540"},{"text":"%spark\n// Path of data source file\nval dataPath = \"s3a://cs-spark-basic-training/SongDS/SongDS.csv\"","user":"anonymous","dateUpdated":"2019-05-15T15:06:25+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dataPath: String = s3a://cs-spark-basic-training/SongDS/SongDS.csv\n"}]},"apps":[],"jobName":"paragraph_1557932575847_-850500099","id":"20190424-151101_1189161016","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23541","dateFinished":"2019-05-15T15:04:00+0000","dateStarted":"2019-05-15T15:04:00+0000"},{"text":"// Create DataFrame from CSV file\nval songDF = spark.read\n                  .option(\"inferSchema\", true)\n                  .option(\"header\", true)\n                  .option(\"delimiter\", \",\")\n                  .csv(dataPath)\n                  \nsongDF.printSchema()\nsongDF.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:06:14+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = true)\n |-- songs: string (nullable = true)\n\n+------------+--------+--------------------------+\n|artist      |loudness|songs                     |\n+------------+--------+--------------------------+\n|BeastieBoys |-5.0    |Sabotage,Intergalactic    |\n|FrankSinatra|-10.0   |MyWay                     |\n|Muse        |-7.0    |Uprising,Starlight,Madness|\n+------------+--------+--------------------------+\n\nsongDF: org.apache.spark.sql.DataFrame = [artist: string, loudness: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1557932575848_1634399755","id":"20190424-151107_1403475661","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23542","dateFinished":"2019-05-15T15:04:17+0000","dateStarted":"2019-05-15T15:04:03+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=162","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=163","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=164"],"interpreterSettingId":"spark"}}},{"text":"// Convert DataFrame to Dataset by storing columns into tuple\nval songDS = songDF.as[(String, Double, String)]\n\nsongDS.printSchema()\nsongDS.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:06:02+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = true)\n |-- songs: string (nullable = true)\n\n+------------+--------+--------------------------+\n|artist      |loudness|songs                     |\n+------------+--------+--------------------------+\n|BeastieBoys |-5.0    |Sabotage,Intergalactic    |\n|FrankSinatra|-10.0   |MyWay                     |\n|Muse        |-7.0    |Uprising,Starlight,Madness|\n+------------+--------+--------------------------+\n\nsongDS: org.apache.spark.sql.Dataset[(String, Double, String)] = [artist: string, loudness: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1557932575848_-577610903","id":"20190424-151207_2000963151","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23543","dateFinished":"2019-05-15T15:05:44+0000","dateStarted":"2019-05-15T15:05:33+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=165"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 1.3.3 Dataset API (high-level operations)","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.3 Dataset API (high-level operations)</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575848_-176039921","id":"20190424-151214_470210732","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23544"},{"text":"%spark\n// Filter artists with loudness greater than -7\nsongDS.filter($\"loudness\" > -7.0).show(false)\n\n// Filter songs which contain 'Star'\nsongDS.filter($\"songs\" like \"%Star%\").show(false)\n\n// Count artists\nsongDS.count()","user":"anonymous","dateUpdated":"2019-05-15T15:05:56+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+--------+----------------------+\n|artist     |loudness|songs                 |\n+-----------+--------+----------------------+\n|BeastieBoys|-5.0    |Sabotage,Intergalactic|\n+-----------+--------+----------------------+\n\n+------+--------+--------------------------+\n|artist|loudness|songs                     |\n+------+--------+--------------------------+\n|Muse  |-7.0    |Uprising,Starlight,Madness|\n+------+--------+--------------------------+\n\nres17: Long = 3\n"}]},"apps":[],"jobName":"paragraph_1557932575848_-411432771","id":"20190424-151221_1875239757","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23545","dateFinished":"2019-05-15T15:05:58+0000","dateStarted":"2019-05-15T15:05:56+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=166","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=167","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=168"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 1.3.4 Dataset API (Low-level operations)","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.4 Dataset API (Low-level operations)</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575848_-465561718","id":"20190424-151227_805721901","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23546"},{"text":"%md\n##### Task: Count songs per artist\n\n- Problem: songs data is unstructered.\n\n- High-level Dataset operations no longer sufficient.\n\n- But Dataset also allow low-level access.\n\n- Dataset allow high- and low-level operations (also in combination).","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>Task: Count songs per artist</h5>\n<ul>\n  <li>\n  <p>Problem: songs data is unstructered.</p></li>\n  <li>\n  <p>High-level Dataset operations no longer sufficient.</p></li>\n  <li>\n  <p>But Dataset also allow low-level access.</p></li>\n  <li>\n  <p>Dataset allow high- and low-level operations (also in combination).</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575848_-38990042","id":"20190424-151243_1891533047","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23547"},{"text":"%spark\nsongDS.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:06:26+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+--------+--------------------------+\n|artist      |loudness|songs                     |\n+------------+--------+--------------------------+\n|BeastieBoys |-5.0    |Sabotage,Intergalactic    |\n|FrankSinatra|-10.0   |MyWay                     |\n|Muse        |-7.0    |Uprising,Starlight,Madness|\n+------------+--------+--------------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1557932575849_1889095300","id":"20190424-151249_2123683881","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23548","dateFinished":"2019-05-15T15:06:26+0000","dateStarted":"2019-05-15T15:06:26+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=169"],"interpreterSettingId":"spark"}}},{"text":"// First of all we need to structure the songs data in a fashion we can count them\n// One artist can have a lot of songs. Therefore we don´t want to distribute all songs over columns.\n// Instead we flatten the songs data row-wise. So we arrange the data in a 'count friendly' fashion -> one row for each song\n// The best way to do this is to split the songs data and use 'flatMap'\n\nval flatSongDS = songDS.flatMap(s => s._3.split(\",\"))    //(Typed) Transformation: Dataset => Dataset\n\nflatSongDS.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:06:34+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+\n|value        |\n+-------------+\n|Sabotage     |\n|Intergalactic|\n|MyWay        |\n|Uprising     |\n|Starlight    |\n|Madness      |\n+-------------+\n\nflatSongDS: org.apache.spark.sql.Dataset[String] = [value: string]\n"}]},"apps":[],"jobName":"paragraph_1557932575849_-529669988","id":"20190424-151305_536009152","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23549","dateFinished":"2019-05-15T15:06:36+0000","dateStarted":"2019-05-15T15:06:34+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=170"],"interpreterSettingId":"spark"}}},{"text":"// As a result we get one row for each song.\n// The problem is that we loose the artist data. So we can´t count songs per artist.\n// Solution: Additional mapping step of songs data to keep artist and loudness data.\n\nval songDsFlattened = songDS.flatMap(s => s._3.split(\",\").map {song => (s._1, s._2, song)})   //(Typed) Transformation: Dataset => Dataset\n\nsongDsFlattened.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:06:39+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+-----+-------------+\n|_1          |_2   |_3           |\n+------------+-----+-------------+\n|BeastieBoys |-5.0 |Sabotage     |\n|BeastieBoys |-5.0 |Intergalactic|\n|FrankSinatra|-10.0|MyWay        |\n|Muse        |-7.0 |Uprising     |\n|Muse        |-7.0 |Starlight    |\n|Muse        |-7.0 |Madness      |\n+------------+-----+-------------+\n\nsongDsFlattened: org.apache.spark.sql.Dataset[(String, Double, String)] = [_1: string, _2: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1557932575849_570252252","id":"20190424-151313_561018803","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23550","dateFinished":"2019-05-15T15:06:41+0000","dateStarted":"2019-05-15T15:06:39+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=171"],"interpreterSettingId":"spark"}}},{"text":"// We can see that the last operation changed the header of the Dataset.\n// As an additional, cosmetical step we manually change the current header to the original one. \n\nval songDsNamed = songDsFlattened.withColumnRenamed(\"_1\", \"artist\")     //(Untyped) Transformation: Dataset => DataFrame\n                                 .withColumnRenamed(\"_2\", \"loudness\")   //(Untyped) Transformation: Dataset => DataFrame\n                                 .withColumnRenamed(\"_3\", \"songs\")      //(Untyped) Transformation: Dataset => DataFrame\nsongDsNamed.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:06:44+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+--------+-------------+\n|artist      |loudness|songs        |\n+------------+--------+-------------+\n|BeastieBoys |-5.0    |Sabotage     |\n|BeastieBoys |-5.0    |Intergalactic|\n|FrankSinatra|-10.0   |MyWay        |\n|Muse        |-7.0    |Uprising     |\n|Muse        |-7.0    |Starlight    |\n|Muse        |-7.0    |Madness      |\n+------------+--------+-------------+\n\nsongDsNamed: org.apache.spark.sql.DataFrame = [artist: string, loudness: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1557932575849_732174106","id":"20190424-151322_1952641322","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23551","dateFinished":"2019-05-15T15:06:45+0000","dateStarted":"2019-05-15T15:06:44+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=172"],"interpreterSettingId":"spark"}}},{"text":"// In the end we receive only structured data which can get easily counted\n\nval songDsCount = songDsNamed.groupBy($\"artist\")   //(Untyped) Transformation: DataFrame => DataFrame\n                             .count()              //Action: DataFrame\n                             \nsongDsCount.show()","user":"anonymous","dateUpdated":"2019-05-15T15:06:48+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+-----+\n|      artist|count|\n+------------+-----+\n|FrankSinatra|    1|\n|        Muse|    3|\n| BeastieBoys|    2|\n+------------+-----+\n\nsongDsCount: org.apache.spark.sql.DataFrame = [artist: string, count: bigint]\n"}]},"apps":[],"jobName":"paragraph_1557932575849_1533074513","id":"20190424-151329_175133160","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23552","dateFinished":"2019-05-15T15:06:52+0000","dateStarted":"2019-05-15T15:06:48+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=173","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=174","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=175","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=176","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=177"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 1.3.5 Case classes\n* Instantiable class\n\n* Very useful to create an individual Dataset structure incl. data types\n\n* Extendable with methods for individual use cases\n\n* Arguments of case class represent Dataset columns incl. their data types","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5 Case classes</h2>\n<ul>\n  <li>\n  <p>Instantiable class</p></li>\n  <li>\n  <p>Very useful to create an individual Dataset structure incl. data types</p></li>\n  <li>\n  <p>Extendable with methods for individual use cases</p></li>\n  <li>\n  <p>Arguments of case class represent Dataset columns incl. their data types</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575849_1514235311","id":"20190424-151342_2001294743","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23553"},{"text":"%md\n## 1.3.5.1 Define case class","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5.1 Define case class</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575850_1192261823","id":"20190424-151349_439462677","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23554"},{"text":"%spark\n// Arugments of the case class represent the columns of the Dataset\ncase class Music(artist: String, loudness: Double, songs: String)\n{\n    // Named function which we will use in chapter 1.3.5.4\n    def artistToUpperCase(): (String, Double, String) = {\n      (artist.toUpperCase, loudness, songs)\n    }\n \n} ","user":"anonymous","dateUpdated":"2019-05-15T15:18:36+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class Music\n"}]},"apps":[],"jobName":"paragraph_1557932575850_793475544","id":"20190424-151356_1970308533","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23555","dateFinished":"2019-05-15T15:17:36+0000","dateStarted":"2019-05-15T15:17:36+0000"},{"text":"%md\n### 1.3.5.2 Create Datasets from case class","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>1.3.5.2 Create Datasets from case class</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575850_209500000","id":"20190424-151403_1037432058","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23556"},{"text":"%spark\n// Create Dataset of type 'Music' out of DataFrame\n\nval musicDS = songDF.as[Music]\n\nmusicDS.printSchema()\nmusicDS.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:17:44+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = true)\n |-- songs: string (nullable = true)\n\n+------------+--------+--------------------------+\n|artist      |loudness|songs                     |\n+------------+--------+--------------------------+\n|BeastieBoys |-5.0    |Sabotage,Intergalactic    |\n|FrankSinatra|-10.0   |MyWay                     |\n|Muse        |-7.0    |Uprising,Starlight,Madness|\n+------------+--------+--------------------------+\n\nmusicDS: org.apache.spark.sql.Dataset[Music] = [artist: string, loudness: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1557932575850_327689498","id":"20190424-151419_992018657","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23557","dateFinished":"2019-05-15T15:17:54+0000","dateStarted":"2019-05-15T15:17:44+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=182"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 1.3.5.3 Use Dataset API","user":"anonymous","dateUpdated":"2019-05-15T15:02:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5.3 Use Dataset API</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575850_-1331242080","id":"20190424-151427_1981328047","dateCreated":"2019-05-15T15:02:55+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:23558"},{"text":"%spark\n// Apply high-level filter\nmusicDS.filter($\"loudness\" > -8.0).show()\n\n// Count lines of Dataset\nmusicDS.count()","user":"anonymous","dateUpdated":"2019-05-15T15:07:28+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+--------+--------------------+\n|     artist|loudness|               songs|\n+-----------+--------+--------------------+\n|BeastieBoys|    -5.0|Sabotage,Intergal...|\n|       Muse|    -7.0|Uprising,Starligh...|\n+-----------+--------+--------------------+\n\nres25: Long = 3\n"}]},"apps":[],"jobName":"paragraph_1557932575851_-1242481712","id":"20190424-151435_2039253808","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23559","dateFinished":"2019-05-15T15:07:28+0000","dateStarted":"2019-05-15T15:07:28+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=179","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=180"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 1.3.5.4 Customized functions inside case class","user":"anonymous","dateUpdated":"2019-05-15T15:07:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5.4 Customized functions inside case class</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557932575851_-483259154","id":"20190424-151445_284042960","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23560","dateFinished":"2019-05-15T15:07:15+0000","dateStarted":"2019-05-15T15:07:15+0000"},{"text":"%spark\n// Call defined function 'upperArtist' in case class\n\nval upperArtist = musicDS.map(a => a.artistToUpperCase)\n\nupperArtist.show(false)","user":"anonymous","dateUpdated":"2019-05-15T15:07:40+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+-----+--------------------------+\n|_1          |_2   |_3                        |\n+------------+-----+--------------------------+\n|BEASTIEBOYS |-5.0 |Sabotage,Intergalactic    |\n|FRANKSINATRA|-10.0|MyWay                     |\n|MUSE        |-7.0 |Uprising,Starlight,Madness|\n+------------+-----+--------------------------+\n\nupperArtist: org.apache.spark.sql.Dataset[(String, Double, String)] = [_1: string, _2: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1557932575851_-1614393950","id":"20190424-151453_343196541","dateCreated":"2019-05-15T15:02:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:23561","dateFinished":"2019-05-15T15:07:32+0000","dateStarted":"2019-05-15T15:07:32+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=181"],"interpreterSettingId":"spark"}}}],"name":"/1. DataFrames, Datasets & RDDs/1.3 Datasets","id":"2EBYVNEF6","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}