{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118602257_-272983604","id":"20190424-171002_1306768548","dateCreated":"2019-04-24T17:10:02+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:43596","text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","dateUpdated":"2019-04-24T17:10:59+0200","dateFinished":"2019-04-24T17:10:59+0200","dateStarted":"2019-04-24T17:10:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]}},{"text":"%md\n# 2.3 DataFrame and Dataset: Transformations & Actions","user":"anonymous","dateUpdated":"2019-04-24T17:11:08+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118659678_492075430","id":"20190424-171059_1976379223","dateCreated":"2019-04-24T17:10:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:43680","dateFinished":"2019-04-24T17:11:08+0200","dateStarted":"2019-04-24T17:11:08+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>2.3 DataFrame and Dataset: Transformations &amp; Actions</h1>\n</div>"}]}},{"text":"%md\n\n***2.3.1 Review: DataFrames & Datasets***\n\n***2.3.2 DataFrame and Dataset transformations***\n\n***2.3.3 DataFrame and Dataset actions***\n\n***2.3.4 Exemplary Dataset operations***\n\n  - Create Dataset out of in-memory \n  \n  - Apply Dataset API\n\n***2.3.5 Exemplary DataFrame operations***\n\n  - Querying DataFrames in a SQL-like fashion","user":"anonymous","dateUpdated":"2019-04-24T17:11:15+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118668869_498420423","id":"20190424-171108_243766197","dateCreated":"2019-04-24T17:11:08+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:43774","dateFinished":"2019-04-24T17:11:15+0200","dateStarted":"2019-04-24T17:11:15+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>2.3.1 Review: DataFrames &amp; Datasets</em></strong></p>\n<p><strong><em>2.3.2 DataFrame and Dataset transformations</em></strong></p>\n<p><strong><em>2.3.3 DataFrame and Dataset actions</em></strong></p>\n<p><strong><em>2.3.4 Exemplary Dataset operations</em></strong></p>\n<ul>\n  <li>\n  <p>Create Dataset out of in-memory</p></li>\n  <li>\n  <p>Apply Dataset API</p></li>\n</ul>\n<p><strong><em>2.3.5 Exemplary DataFrame operations</em></strong></p>\n<ul>\n  <li>Querying DataFrames in a SQL-like fashion</li>\n</ul>\n</div>"}]}},{"text":"%md \n## 2.3.1 Review: DataFrames & Datasets\n\nOverview over the different Spark APIs for working with structured and semi-structured data:\n\n*   **DataFrame** API - *Untyped* view on a Dataset. A DataFrame is a `Dataset[Row]`. ([Dataframe type definition](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]))\n      * DataFrames have a schema\n\n*   **Dataset** API - *Strongly typed* collection of domain-specific objects. Can be transformed in parallel using functional or relational operations. ([Dataset Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset))\n      * Available in Scala API only\n      * Higher-level implementation of an RDD with more built-in functionality\n      * Most useful for semi-structured data with a predictable type, or can be defined using a case class.\n      * Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.\n      * Adding type information drastically improves memory usage when caching data\n      * Datasets offer type-checking at compile time\n\n\n<img src=\"https://i.stack.imgur.com/3rF6p.png\" width=800>","user":"anonymous","dateUpdated":"2019-04-24T17:11:25+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118675581_-2014533946","id":"20190424-171115_2146967781","dateCreated":"2019-04-24T17:11:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:43864","dateFinished":"2019-04-24T17:11:25+0200","dateStarted":"2019-04-24T17:11:25+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.1 Review: DataFrames &amp; Datasets</h2>\n<p>Overview over the different Spark APIs for working with structured and semi-structured data:</p>\n<ul>\n  <li>\n    <p><strong>DataFrame</strong> API - <em>Untyped</em> view on a Dataset. A DataFrame is a <code>Dataset[Row]</code>. (<a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\">Dataframe type definition</a>)</p>\n    <ul>\n      <li>DataFrames have a schema</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Dataset</strong> API - <em>Strongly typed</em> collection of domain-specific objects. Can be transformed in parallel using functional or relational operations. (<a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset Scaladoc</a>)</p>\n    <ul>\n      <li>Available in Scala API only</li>\n      <li>Higher-level implementation of an RDD with more built-in functionality</li>\n      <li>Most useful for semi-structured data with a predictable type, or can be defined using a case class.</li>\n      <li>Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.</li>\n      <li>Adding type information drastically improves memory usage when caching data</li>\n      <li>Datasets offer type-checking at compile time</li>\n    </ul>\n  </li>\n</ul>\n<img src=\"https://i.stack.imgur.com/3rF6p.png\" width=800>\n</div>"}]}},{"text":"%md\n## 2.3.2 DataFrame and Dataset transformations\n\n*   Overview of typed and untyped Dataset transformations can be found [here](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n*   For ***DataFrames*** only the untyped Dataset transformations of the same API are applicable.\n\n*   Examples of some common transformations:\n    - `select`\n    - `where`\n    - `orderBy`\n    - `join`\n    - `filter`","user":"anonymous","dateUpdated":"2019-04-24T17:11:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118685142_1466782302","id":"20190424-171125_496079748","dateCreated":"2019-04-24T17:11:25+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:43954","dateFinished":"2019-04-24T17:11:35+0200","dateStarted":"2019-04-24T17:11:35+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.2 DataFrame and Dataset transformations</h2>\n<ul>\n  <li>\n  <p>Overview of typed and untyped Dataset transformations can be found <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">here</a>.</p></li>\n  <li>\n  <p>For <strong><em>DataFrames</em></strong> only the untyped Dataset transformations of the same API are applicable.</p></li>\n  <li>\n    <p>Examples of some common transformations:</p>\n    <ul>\n      <li><code>select</code></li>\n      <li><code>where</code></li>\n      <li><code>orderBy</code></li>\n      <li><code>join</code></li>\n      <li><code>filter</code></li>\n    </ul>\n  </li>\n</ul>\n</div>"}]}},{"text":"%md\n## 2.3.3 DataFrame and Dataset actions\n\n*   Overview of DataFrame and Dataset actions can be found [here](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n*   Examples of some common actions:\n    - `count`\n    - `take`\n    - `show`\n    - `write`","user":"anonymous","dateUpdated":"2019-04-24T17:11:50+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118692085_-1511397404","id":"20190424-171132_1679925271","dateCreated":"2019-04-24T17:11:32+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44044","dateFinished":"2019-04-24T17:11:50+0200","dateStarted":"2019-04-24T17:11:50+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.3 DataFrame and Dataset actions</h2>\n<ul>\n  <li>\n  <p>Overview of DataFrame and Dataset actions can be found <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">here</a>.</p></li>\n  <li>\n    <p>Examples of some common actions:</p>\n    <ul>\n      <li><code>count</code></li>\n      <li><code>take</code></li>\n      <li><code>show</code></li>\n      <li><code>write</code></li>\n    </ul>\n  </li>\n</ul>\n</div>"}]}},{"text":"%md\n## 2.3.4 Exemplary Dataset operations\n\nDatasets use RDDs internally. The Dataset and DataFrame APIs changed significantly in Spark 2. In contrast to RDDs, Datasets automatically apply optimizations before executing transformations or actions. Therefore they usually execute faster and should be preferred over RDDs.\n\nDatasets provide operations similar to those provided by RDDs.","user":"anonymous","dateUpdated":"2019-04-24T17:11:56+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118710278_1885229997","id":"20190424-171150_1025921975","dateCreated":"2019-04-24T17:11:50+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44157","dateFinished":"2019-04-24T17:11:56+0200","dateStarted":"2019-04-24T17:11:56+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.4 Exemplary Dataset operations</h2>\n<p>Datasets use RDDs internally. The Dataset and DataFrame APIs changed significantly in Spark 2. In contrast to RDDs, Datasets automatically apply optimizations before executing transformations or actions. Therefore they usually execute faster and should be preferred over RDDs.</p>\n<p>Datasets provide operations similar to those provided by RDDs.</p>\n</div>"}]}},{"text":"%md ### Create Dataset out of in-memory data","user":"anonymous","dateUpdated":"2019-04-24T17:12:02+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118716438_-750672745","id":"20190424-171156_1369358331","dateCreated":"2019-04-24T17:11:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44247","dateFinished":"2019-04-24T17:12:02+0200","dateStarted":"2019-04-24T17:12:02+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Create Dataset out of in-memory data</h3>\n</div>"}]}},{"text":"%spark\n// Define case class representing schema of our data.\ncase class Song(artist: String, loudness: Double)\n\n// Create standard Scala Array.\nval songArray = Array(\n  Song(\"Beastie Boys\", -5.0), \n  Song(\"Frank Sinatra\", -10.0), \n  Song(\"Muse\", -7.0)\n)\n\n// Create a Dataset from 'songArray'\nval songsDS = spark.createDataset(songArray)\n\nsongsDS.printSchema()\n\nsongsDS.show(false)","user":"anonymous","dateUpdated":"2019-04-24T17:12:16+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118722478_-1936159320","id":"20190424-171202_1971333088","dateCreated":"2019-04-24T17:12:02+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44337","dateFinished":"2019-04-24T17:12:16+0200","dateStarted":"2019-04-24T17:12:16+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:28: error: Unable to find encoder for type stored in a Dataset.  Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._  Support for serializing other types will be added in future releases.\n       val songsDS = spark.createDataset(songArray)\n                                        ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118728726_823745413","id":"20190424-171208_236094861","dateCreated":"2019-04-24T17:12:08+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44427","text":"%md\n### Apply Dataset API\n\nFor Datasets low-level and high-level operations are possible.","dateUpdated":"2019-04-24T17:12:28+0200","dateFinished":"2019-04-24T17:12:28+0200","dateStarted":"2019-04-24T17:12:28+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Apply Dataset API</h3>\n<p>For Datasets low-level and high-level operations are possible.</p>\n</div>"}]}},{"text":"%spark\n//Low-level operation\nval lowLevelAccess = songsDS.filter(_.loudness > -8.0)\n                            .map(_.artist)\n                            .collect\n\nlowLevelAccess.foreach(println)","user":"anonymous","dateUpdated":"2019-04-24T17:12:40+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118745446_924439640","id":"20190424-171225_1593480697","dateCreated":"2019-04-24T17:12:25+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44545","dateFinished":"2019-04-24T17:12:40+0200","dateStarted":"2019-04-24T17:12:40+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songsDS\n       val lowLevelAccess = songsDS.filter(_.loudness > -8.0)\n                            ^\n"}]}},{"text":"//High-level operation (also in combination with low-level operations)\nval highLevelAccess = songsDS.filter($\"loudness\" > -8.0)\n                             .map(_.artist)\n                             .show(false)","user":"anonymous","dateUpdated":"2019-04-24T17:12:54+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118760667_-1874949031","id":"20190424-171240_1286531070","dateCreated":"2019-04-24T17:12:40+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44657","dateFinished":"2019-04-24T17:12:54+0200","dateStarted":"2019-04-24T17:12:54+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songsDS\n       val highLevelAccess = songsDS.filter($\"loudness\" > -8.0)\n                             ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118774662_-2053442465","id":"20190424-171254_953230961","dateCreated":"2019-04-24T17:12:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44745","text":"%md\n## 2.3.5 Exemplary DataFrame operations\n\nUntyped view of a Dataset. Essentially a sql table that can be accessed via the Spark API.","dateUpdated":"2019-04-24T17:13:03+0200","dateFinished":"2019-04-24T17:13:03+0200","dateStarted":"2019-04-24T17:13:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.5 Exemplary DataFrame operations</h2>\n<p>Untyped view of a Dataset. Essentially a sql table that can be accessed via the Spark API.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T17:13:26+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118783230_-1945304187","id":"20190424-171303_1814518902","dateCreated":"2019-04-24T17:13:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44834","dateFinished":"2019-04-24T17:13:26+0200","dateStarted":"2019-04-24T17:13:26+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Convert songDS to DataFrame\nval songDF = songsDS.toDF()\n\nsongDF.printSchema()\n\n//each field of type Song is now similar to a DB column\nsongDF.show(false)","user":"anonymous","dateUpdated":"2019-04-24T17:13:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118806190_-796324713","id":"20190424-171326_1223035856","dateCreated":"2019-04-24T17:13:26+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44924","dateFinished":"2019-04-24T17:13:45+0200","dateStarted":"2019-04-24T17:13:45+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songsDS\n       val songDF = songsDS.toDF()\n                    ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118815565_-533215753","id":"20190424-171335_1153365415","dateCreated":"2019-04-24T17:13:35+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45014","text":"//Within DataFrames low-level access isn´t possible\nsongDF.map(i => i).take(3)","dateUpdated":"2019-04-24T17:14:01+0200","dateFinished":"2019-04-24T17:14:01+0200","dateStarted":"2019-04-24T17:14:01+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:31: error: not found: value songDF\n       songDF.map(i => i).take(3)\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118841022_1405303746","id":"20190424-171401_1657161762","dateCreated":"2019-04-24T17:14:01+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45182","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T17:14:13+0200","dateFinished":"2019-04-24T17:14:13+0200","dateStarted":"2019-04-24T17:14:13+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nfrom pyspark.sql.types import *\n\nmyData = [('Beastie Boys', -5.0), ('Frank Sinatra', -10.0), ('Muse', -7.0)]\nmySchema = StructType([StructField(\"artist\", StringType()), StructField('loudness', FloatType())])\nsongDF = spark.createDataFrame(myData, schema=mySchema)\nsongDF.show()","user":"anonymous","dateUpdated":"2019-04-24T17:14:21+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118853295_905267030","id":"20190424-171413_534879665","dateCreated":"2019-04-24T17:14:13+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45271","dateFinished":"2019-04-24T17:14:21+0200","dateStarted":"2019-04-24T17:14:21+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nModuleNotFoundError: No module named 'pyspark'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nModuleNotFoundError: No module named 'pyspark'\n\n"}]}},{"text":"%md \n## Querying DataFrames in a SQL-like fashion\n\nDataFrames provide a column oriented API similar to SQL.\nWe can use SQL commands directly on DataFrames.","user":"anonymous","dateUpdated":"2019-04-24T17:14:29+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118861079_-713035938","id":"20190424-171421_619393437","dateCreated":"2019-04-24T17:14:21+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45360","dateFinished":"2019-04-24T17:14:29+0200","dateStarted":"2019-04-24T17:14:29+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Querying DataFrames in a SQL-like fashion</h2>\n<p>DataFrames provide a column oriented API similar to SQL.<br/>We can use SQL commands directly on DataFrames.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T17:14:36+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118869367_1016777945","id":"20190424-171429_2047339428","dateCreated":"2019-04-24T17:14:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45449","dateFinished":"2019-04-24T17:14:36+0200","dateStarted":"2019-04-24T17:14:36+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval filteredSongArrayFromDF = songDF\n    .where($\"loudness\" > -8.0)\n    .select($\"artist\")\n    .show()\n","user":"anonymous","dateUpdated":"2019-04-24T17:14:47+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118876535_2096682879","id":"20190424-171436_236422760","dateCreated":"2019-04-24T17:14:36+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45539","dateFinished":"2019-04-24T17:14:47+0200","dateStarted":"2019-04-24T17:14:47+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value songDF\n       val filteredSongArrayFromDF = songDF\n                                     ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T17:14:54+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118887591_-349595510","id":"20190424-171447_1388774258","dateCreated":"2019-04-24T17:14:47+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45628","dateFinished":"2019-04-24T17:14:54+0200","dateStarted":"2019-04-24T17:14:54+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\n# plenty of syntax options\nsongDF.filter('loudness > -8.0').select('artist').show()\nsongDF.where(songDF.loudness > -8.0).select(songDF.artist).show()","user":"anonymous","dateUpdated":"2019-04-24T17:14:59+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118894918_-186904806","id":"20190424-171454_1079566912","dateCreated":"2019-04-24T17:14:54+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45717","dateFinished":"2019-04-24T17:14:59+0200","dateStarted":"2019-04-24T17:14:59+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\n"}]}}],"name":"/2. Operations: Transformations & Actions/ 2.3 DataFrame and Dataset: Transformations & Actions","id":"2EBKDUB6M","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}