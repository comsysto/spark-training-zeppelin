{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118974485_2005600076","id":"20190424-171614_1563320323","dateCreated":"2019-04-24T17:16:14+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46101","text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","dateUpdated":"2019-04-24T17:16:19+0200","dateFinished":"2019-04-24T17:16:19+0200","dateStarted":"2019-04-24T17:16:19+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]}},{"text":"%md\n# 2.4 Monitoring: Spark web UI","user":"anonymous","dateUpdated":"2019-04-24T17:16:25+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118979846_-775468120","id":"20190424-171619_606788995","dateCreated":"2019-04-24T17:16:19+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46179","dateFinished":"2019-04-24T17:16:25+0200","dateStarted":"2019-04-24T17:16:25+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>2.4 Monitoring: Spark web UI</h1>\n</div>"}]}},{"text":"%md\n***2.4.1 Monitoring options of Spark applications***\n\n***2.4.2 Nomenclature: Tasks, Stages & Jobs***\n\n***2.4.3 Using the Spark web UI in an example***\n\n***2.4.4 Excursion: Ganglia***","user":"anonymous","dateUpdated":"2019-04-24T17:16:31+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118985471_318948254","id":"20190424-171625_1521400062","dateCreated":"2019-04-24T17:16:25+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46273","dateFinished":"2019-04-24T17:16:31+0200","dateStarted":"2019-04-24T17:16:31+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>2.4.1 Monitoring options of Spark applications</em></strong></p>\n<p><strong><em>2.4.2 Nomenclature: Tasks, Stages &amp; Jobs</em></strong></p>\n<p><strong><em>2.4.3 Using the Spark web UI in an example</em></strong></p>\n<p><strong><em>2.4.4 Excursion: Ganglia</em></strong></p>\n</div>"}]}},{"text":"%md\n## 2.4.1 Monitoring options of Spark applications","user":"anonymous","dateUpdated":"2019-04-24T17:16:38+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118991215_1013535024","id":"20190424-171631_1954347856","dateCreated":"2019-04-24T17:16:31+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46363","dateFinished":"2019-04-24T17:16:38+0200","dateStarted":"2019-04-24T17:16:38+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.1 Monitoring options of Spark applications</h2>\n</div>"}]}},{"text":"%md\n***Spark web UI***\n- Every `SparkContext` launches a Spark web UI run by the driver\n- The Spark web UI is only available during the application is runing\n- Accessible via opening `http://<driver-node>:4040` in a web brower\n- In databricks: click on cluster -> View Spark UI\n\n***Spark history server***\n- To view the Spark web UI after applications are finished, you have to set the `spark.eventLog.enabled` [Spark History Server Configuration Option](https://spark.apache.org/docs/latest/monitoring.html#spark-history-server-configuration-options) to `true` in advance\n- Start the history server with executing `./sbin/start-history-server.sh` and access `http://<server-url>:18080`\n\n***Metrics***\n- Spark has a configurable metrics system\n- This metrics system enables to report Spark metrics in separate spaces like HTTP, JMX and CSV\n\n***External instrumentation***\n- Ganglia\n- dstat, iostat, iotop\n- jstack, jmapj, jstat, jconsole","user":"anonymous","dateUpdated":"2019-04-24T17:16:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556118998198_-1456300571","id":"20190424-171638_784775771","dateCreated":"2019-04-24T17:16:38+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46453","dateFinished":"2019-04-24T17:16:44+0200","dateStarted":"2019-04-24T17:16:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Spark web UI</em></strong><br/>- Every <code>SparkContext</code> launches a Spark web UI run by the driver<br/>- The Spark web UI is only available during the application is runing<br/>- Accessible via opening <code>http://&lt;driver-node&gt;:4040</code> in a web brower<br/>- In databricks: click on cluster -&gt; View Spark UI</p>\n<p><strong><em>Spark history server</em></strong><br/>- To view the Spark web UI after applications are finished, you have to set the <code>spark.eventLog.enabled</code> <a href=\"https://spark.apache.org/docs/latest/monitoring.html#spark-history-server-configuration-options\">Spark History Server Configuration Option</a> to <code>true</code> in advance<br/>- Start the history server with executing <code>./sbin/start-history-server.sh</code> and access <code>http://&lt;server-url&gt;:18080</code></p>\n<p><strong><em>Metrics</em></strong><br/>- Spark has a configurable metrics system<br/>- This metrics system enables to report Spark metrics in separate spaces like HTTP, JMX and CSV</p>\n<p><strong><em>External instrumentation</em></strong><br/>- Ganglia<br/>- dstat, iostat, iotop<br/>- jstack, jmapj, jstat, jconsole</p>\n</div>"}]}},{"text":"%md\n## 2.4.2 Nomenclature: Tasks, Stages & Jobs","user":"anonymous","dateUpdated":"2019-04-24T17:16:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119004071_-1682245620","id":"20190424-171644_117715989","dateCreated":"2019-04-24T17:16:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46543","dateFinished":"2019-04-24T17:16:51+0200","dateStarted":"2019-04-24T17:16:51+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.2 Nomenclature: Tasks, Stages &amp; Jobs</h2>\n</div>"}]}},{"text":"%md <img src='http://www.lostinsoftware.com/wp-content/uploads/2016/02/img_56c0634b46ed6.png' style='width:800px'>","user":"anonymous","dateUpdated":"2019-04-24T17:18:20+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119011127_-2121862332","id":"20190424-171651_2121787721","dateCreated":"2019-04-24T17:16:51+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46633","dateFinished":"2019-04-24T17:18:20+0200","dateStarted":"2019-04-24T17:18:20+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='http://www.lostinsoftware.com/wp-content/uploads/2016/02/img_56c0634b46ed6.png' style='width:800px'>\n</div>"}]}},{"text":"%md\n**Task**\nPipeline of operations on one partition\n\n**Stage**\nEntirety of all tasks of one RDD which run in parallel and end with a shuffle event\n\n**Jobs**\nEntirety of all Stages","user":"anonymous","dateUpdated":"2019-04-24T17:17:06+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119018685_625640581","id":"20190424-171658_154636726","dateCreated":"2019-04-24T17:16:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46723","dateFinished":"2019-04-24T17:17:06+0200","dateStarted":"2019-04-24T17:17:06+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong>Task</strong><br/>Pipeline of operations on one partition</p>\n<p><strong>Stage</strong><br/>Entirety of all tasks of one RDD which run in parallel and end with a shuffle event</p>\n<p><strong>Jobs</strong><br/>Entirety of all Stages</p>\n</div>"}]}},{"text":"%md\n## 2.4.3 Using the Spark web UI in an example\nWe will now demonstrate the Spark web UI with an example. The following query reads in the Spark Readme and displays the 10 top most used words in there.","user":"anonymous","dateUpdated":"2019-04-24T17:17:11+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119026015_2023449384","id":"20190424-171706_879560903","dateCreated":"2019-04-24T17:17:06+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46813","dateFinished":"2019-04-24T17:17:11+0200","dateStarted":"2019-04-24T17:17:11+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.3 Using the Spark web UI in an example</h2>\n<p>We will now demonstrate the Spark web UI with an example. The following query reads in the Spark Readme and displays the 10 top most used words in there.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T17:17:21+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119031527_-492563579","id":"20190424-171711_1678899382","dateCreated":"2019-04-24T17:17:11+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46903","dateFinished":"2019-04-24T17:17:21+0200","dateStarted":"2019-04-24T17:17:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval textRDD = sc.textFile(\"dbfs:/cs-spark-training/sparkUI/\")\ntextRDD.take(18).foreach(println)\n\nval topWords = textRDD.flatMap(line => line.split(\" \"))    //flat each word into a single line\n                      .filter(line => !line.isEmpty)       //skip empty lines\n                      .map(word => (word, 1))              //map each word into a tuple (to be able to group and count words)\n                      .groupByKey()                        //group the RDD by each unique word\n                      .map(t => (t._1, t._2.size))         //count appearance of each word\n                      .sortBy(t => t._2, false)            //sort the RDD descending\n\n\nprintln(\"#################### RESULT ####################\")\n\n\ntopWords.take(10).foreach(println)                         //print the 10 top most used words in the Spark Readme file","user":"anonymous","dateUpdated":"2019-04-24T17:17:28+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119041063_245675859","id":"20190424-171721_1523667035","dateCreated":"2019-04-24T17:17:21+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46993","dateFinished":"2019-04-24T17:17:29+0200","dateStarted":"2019-04-24T17:17:28+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1333)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.take(RDD.scala:1327)\n  ... 51 elided\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T17:17:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119048911_1771866020","id":"20190424-171728_1702958561","dateCreated":"2019-04-24T17:17:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:47082","dateFinished":"2019-04-24T17:17:44+0200","dateStarted":"2019-04-24T17:17:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nfrom __future__ import print_function\n\ntextRDD = sc.textFile('dbfs:/cs-spark-training/sparkUI/')\nprint(*textRDD.take(18), sep = '\\n')\n\ntopWords = textRDD.flatMap(lambda line: line.split(' ')).filter(lambda x: x != '').map(lambda x: (x, 1)).groupByKey().map(lambda x: (x[0], len(x[1]))).sortBy(lambda x: x[1], False)\nprint(*topWords.take(10), sep = '\\n')","user":"anonymous","dateUpdated":"2019-04-24T17:17:50+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119064087_2018661180","id":"20190424-171744_775235657","dateCreated":"2019-04-24T17:17:44+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:47183","dateFinished":"2019-04-24T17:17:50+0200","dateStarted":"2019-04-24T17:17:50+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'sc' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'sc' is not defined\n\n"}]}},{"text":"%md\n## 2.4.4 Excursion: Ganglia","user":"anonymous","dateUpdated":"2019-04-24T17:17:59+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119070855_602951822","id":"20190424-171750_423720185","dateCreated":"2019-04-24T17:17:50+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:47272","dateFinished":"2019-04-24T17:17:59+0200","dateStarted":"2019-04-24T17:17:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.4 Excursion: Ganglia</h2>\n</div>"}]}},{"text":"%md\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/image.png'>","user":"anonymous","dateUpdated":"2019-04-24T17:18:11+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119079807_1614623128","id":"20190424-171759_1776467034","dateCreated":"2019-04-24T17:17:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:47361","dateFinished":"2019-04-24T17:18:11+0200","dateStarted":"2019-04-24T17:18:11+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/image.png'>\n</div>"}]}},{"text":"%md\n","user":"anonymous","dateUpdated":"2019-04-24T17:18:05+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556119085183_387618683","id":"20190424-171805_1342013659","dateCreated":"2019-04-24T17:18:05+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:47451"}],"name":"/2. Operations: Transformations & Actions/2.4 Monitoring: Spark web UI","id":"2EBMN4NFG","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}