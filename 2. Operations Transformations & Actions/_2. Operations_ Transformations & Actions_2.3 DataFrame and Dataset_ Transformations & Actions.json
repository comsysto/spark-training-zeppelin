{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072172_-1964449335","id":"20190424-171002_1306768548","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46494"},{"text":"%md\n# 2.3 DataFrame and Dataset: Transformations & Actions","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>2.3 DataFrame and Dataset: Transformations &amp; Actions</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072172_-1478569592","id":"20190424-171059_1976379223","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46495"},{"text":"%md\n\n***2.3.1 Review: DataFrames & Datasets***\n\n***2.3.2 DataFrame and Dataset transformations***\n\n***2.3.3 DataFrame and Dataset actions***\n\n***2.3.4 Exemplary Dataset operations***\n\n  - Create Dataset out of in-memory \n  \n  - Apply Dataset API\n\n***2.3.5 Exemplary DataFrame operations***\n\n  - Querying DataFrames in a SQL-like fashion","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>2.3.1 Review: DataFrames &amp; Datasets</em></strong></p>\n<p><strong><em>2.3.2 DataFrame and Dataset transformations</em></strong></p>\n<p><strong><em>2.3.3 DataFrame and Dataset actions</em></strong></p>\n<p><strong><em>2.3.4 Exemplary Dataset operations</em></strong></p>\n<ul>\n  <li>\n  <p>Create Dataset out of in-memory</p></li>\n  <li>\n  <p>Apply Dataset API</p></li>\n</ul>\n<p><strong><em>2.3.5 Exemplary DataFrame operations</em></strong></p>\n<ul>\n  <li>Querying DataFrames in a SQL-like fashion</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072174_-1786822519","id":"20190424-171108_243766197","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46496"},{"text":"%md \n## 2.3.1 Review: DataFrames & Datasets\n\nOverview over the different Spark APIs for working with structured and semi-structured data:\n\n*   **DataFrame** API - *Untyped* view on a Dataset. A DataFrame is a `Dataset[Row]`. ([Dataframe type definition](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]))\n      * DataFrames have a schema\n\n*   **Dataset** API - *Strongly typed* collection of domain-specific objects. Can be transformed in parallel using functional or relational operations. ([Dataset Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset))\n      * Available in Scala API only\n      * Higher-level implementation of an RDD with more built-in functionality\n      * Most useful for semi-structured data with a predictable type, or can be defined using a case class.\n      * Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.\n      * Adding type information drastically improves memory usage when caching data\n      * Datasets offer type-checking at compile time\n\n\n<img src=\"https://i.stack.imgur.com/3rF6p.png\" width=800>","user":"anonymous","dateUpdated":"2019-05-20T14:48:35+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.1 Review: DataFrames &amp; Datasets</h2>\n<p>Overview over the different Spark APIs for working with structured and semi-structured data:</p>\n<ul>\n  <li>\n    <p><strong>DataFrame</strong> API - <em>Untyped</em> view on a Dataset. A DataFrame is a <code>Dataset[Row]</code>. (<a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\">Dataframe type definition</a>)</p>\n    <ul>\n      <li>DataFrames have a schema</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Dataset</strong> API - <em>Strongly typed</em> collection of domain-specific objects. Can be transformed in parallel using functional or relational operations. (<a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset Scaladoc</a>)</p>\n    <ul>\n      <li>Available in Scala API only</li>\n      <li>Higher-level implementation of an RDD with more built-in functionality</li>\n      <li>Most useful for semi-structured data with a predictable type, or can be defined using a case class.</li>\n      <li>Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.</li>\n      <li>Adding type information drastically improves memory usage when caching data</li>\n      <li>Datasets offer type-checking at compile time</li>\n    </ul>\n  </li>\n</ul>\n<img src=\"https://i.stack.imgur.com/3rF6p.png\" width=800>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072174_104171468","id":"20190424-171115_2146967781","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46497","dateFinished":"2019-05-20T14:48:35+0000","dateStarted":"2019-05-20T14:48:35+0000"},{"text":"%md\n## 2.3.2 DataFrame and Dataset transformations\n\n*   Overview of typed and untyped Dataset transformations can be found [here](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n*   For ***DataFrames*** only the untyped Dataset transformations of the same API are applicable.\n\n*   Examples of some common transformations:\n    - `select`\n    - `where`\n    - `orderBy`\n    - `join`\n    - `filter`","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.2 DataFrame and Dataset transformations</h2>\n<ul>\n  <li>\n  <p>Overview of typed and untyped Dataset transformations can be found <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">here</a>.</p></li>\n  <li>\n  <p>For <strong><em>DataFrames</em></strong> only the untyped Dataset transformations of the same API are applicable.</p></li>\n  <li>\n    <p>Examples of some common transformations:</p>\n    <ul>\n      <li><code>select</code></li>\n      <li><code>where</code></li>\n      <li><code>orderBy</code></li>\n      <li><code>join</code></li>\n      <li><code>filter</code></li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072175_1739632841","id":"20190424-171125_496079748","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46498"},{"text":"%md\n## 2.3.3 DataFrame and Dataset actions\n\n*   Overview of DataFrame and Dataset actions can be found [here](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n*   Examples of some common actions:\n    - `count`\n    - `take`\n    - `show`\n    - `write`","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.3 DataFrame and Dataset actions</h2>\n<ul>\n  <li>\n  <p>Overview of DataFrame and Dataset actions can be found <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">here</a>.</p></li>\n  <li>\n    <p>Examples of some common actions:</p>\n    <ul>\n      <li><code>count</code></li>\n      <li><code>take</code></li>\n      <li><code>show</code></li>\n      <li><code>write</code></li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072175_-62534485","id":"20190424-171132_1679925271","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46499"},{"text":"%md\n## 2.3.4 Exemplary Dataset operations\n\nDatasets use RDDs internally. The Dataset and DataFrame APIs changed significantly in Spark 2. In contrast to RDDs, Datasets automatically apply optimizations before executing transformations or actions. Therefore they usually execute faster and should be preferred over RDDs.\n\nDatasets provide operations similar to those provided by RDDs.","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.4 Exemplary Dataset operations</h2>\n<p>Datasets use RDDs internally. The Dataset and DataFrame APIs changed significantly in Spark 2. In contrast to RDDs, Datasets automatically apply optimizations before executing transformations or actions. Therefore they usually execute faster and should be preferred over RDDs.</p>\n<p>Datasets provide operations similar to those provided by RDDs.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072175_-1319177069","id":"20190424-171150_1025921975","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46500"},{"text":"%md ### Create Dataset out of in-memory data","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Create Dataset out of in-memory data</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072175_2072548732","id":"20190424-171156_1369358331","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46501"},{"text":"%spark\n// Define case class representing schema of the data.\ncase class Song(artist: String, loudness: Double)","user":"anonymous","dateUpdated":"2019-05-20T14:50:45+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false,"lineNumbers":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1558363775200_1365306842","id":"20190520-144935_843326539","dateCreated":"2019-05-20T14:49:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:48441","dateFinished":"2019-05-20T14:49:47+0000","dateStarted":"2019-05-20T14:49:47+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class Song\n"}]}},{"text":"%spark\n// Create in-memory data out of Scala standard array\nval songArray = Array(\n  Song(\"Beastie Boys\", -5.0), \n  Song(\"Frank Sinatra\", -10.0), \n  Song(\"Muse\", -7.0)\n)\n\n// Create a Dataset from 'songArray'\nval songsDS = spark.createDataset(songArray)\n\nsongsDS.printSchema()\n\nsongsDS.show(false)","user":"anonymous","dateUpdated":"2019-05-20T14:50:42+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = false)\n\n+-------------+--------+\n|artist       |loudness|\n+-------------+--------+\n|Beastie Boys |-5.0    |\n|Frank Sinatra|-10.0   |\n|Muse         |-7.0    |\n+-------------+--------+\n\nsongArray: Array[Song] = Array(Song(Beastie Boys,-5.0), Song(Frank Sinatra,-10.0), Song(Muse,-7.0))\nsongsDS: org.apache.spark.sql.Dataset[Song] = [artist: string, loudness: double]\n"}]},"apps":[],"jobName":"paragraph_1558346072176_1077650358","id":"20190424-171202_1971333088","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46502","dateFinished":"2019-05-20T14:50:44+0000","dateStarted":"2019-05-20T14:50:42+0000"},{"text":"%md\n### Apply Dataset API\n\nFor Datasets low-level and high-level operations are possible.","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Apply Dataset API</h3>\n<p>For Datasets low-level and high-level operations are possible.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072176_125248285","id":"20190424-171208_236094861","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46503"},{"text":"%spark\n// Low-level operation\nval lowLevelAccess = songsDS.filter(_.loudness > -8.0)\n                            .map(_.artist)\n                            .collect\n\nlowLevelAccess.foreach(println)","user":"anonymous","dateUpdated":"2019-05-20T14:50:52+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Beastie Boys\nMuse\nlowLevelAccess: Array[String] = Array(Beastie Boys, Muse)\n"}]},"apps":[],"jobName":"paragraph_1558346072176_-446646495","id":"20190424-171225_1593480697","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46504","dateFinished":"2019-05-20T14:51:01+0000","dateStarted":"2019-05-20T14:50:52+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=238"],"interpreterSettingId":"spark"}}},{"text":"// High-level operation (also in combination with low-level operations)\nval highLevelAccess = songsDS.filter($\"loudness\" > -8.0)\n                             .map(_.artist)\n                             .show(false)","user":"anonymous","dateUpdated":"2019-05-20T14:51:01+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+\n|value       |\n+------------+\n|Beastie Boys|\n|Muse        |\n+------------+\n\nhighLevelAccess: Unit = ()\n"}]},"apps":[],"jobName":"paragraph_1558346072176_904656326","id":"20190424-171240_1286531070","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46505","dateFinished":"2019-05-20T14:51:02+0000","dateStarted":"2019-05-20T14:51:01+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=239","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=240"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 2.3.5 Exemplary DataFrame operations\n\nUntyped view of a Dataset. Essentially a sql table that can be accessed via the Spark API.","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.3.5 Exemplary DataFrame operations</h2>\n<p>Untyped view of a Dataset. Essentially a sql table that can be accessed via the Spark API.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072176_-2126094551","id":"20190424-171254_953230961","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46506"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-20T14:51:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072177_-599786664","id":"20190424-171303_1814518902","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46507","dateFinished":"2019-05-20T14:51:18+0000","dateStarted":"2019-05-20T14:51:18+0000"},{"text":"%spark\n// Convert songDS to DataFrame\nval songDF = songsDS.toDF()\n\nsongDF.printSchema()\n\n// Each field of type Song is now similar to a DB column\nsongDF.show(false)","user":"anonymous","dateUpdated":"2019-05-20T14:54:29+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = false)\n\n+-------------+--------+\n|artist       |loudness|\n+-------------+--------+\n|Beastie Boys |-5.0    |\n|Frank Sinatra|-10.0   |\n|Muse         |-7.0    |\n+-------------+--------+\n\nsongDF: org.apache.spark.sql.DataFrame = [artist: string, loudness: double]\n"}]},"apps":[],"jobName":"paragraph_1558346072177_572464013","id":"20190424-171326_1223035856","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46508","dateFinished":"2019-05-20T14:51:26+0000","dateStarted":"2019-05-20T14:51:26+0000"},{"text":"%spark\n// Within DataFrames low-level access isn´t possible\nsongDF.map(i => i).take(3)","user":"anonymous","dateUpdated":"2019-05-20T14:52:11+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:27: error: Unable to find encoder for type org.apache.spark.sql.Row. An implicit Encoder[org.apache.spark.sql.Row] is needed to store org.apache.spark.sql.Row instances in a Dataset. Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._  Support for serializing other types will be added in future releases.\n       songDF.map(i => i).take(3)\n                 ^\n"}]},"apps":[],"jobName":"paragraph_1558346072177_-1648317372","id":"20190424-171335_1153365415","dateCreated":"2019-05-20T09:54:32+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:46509","dateFinished":"2019-05-20T14:52:11+0000","dateStarted":"2019-05-20T14:52:11+0000"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-20T14:52:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072177_-852789180","id":"20190424-171401_1657161762","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46510","dateFinished":"2019-05-20T14:52:20+0000","dateStarted":"2019-05-20T14:52:20+0000"},{"text":"%pyspark\nfrom pyspark.sql.types import *\n\n# Create in-memory data out of a Python list\nmyData = [('Beastie Boys', -5.0), ('Frank Sinatra', -10.0), ('Muse', -7.0)]\n\n# Definition of the schema of the data\nmySchema = StructType([StructField(\"artist\", StringType()), StructField('loudness', FloatType())])\n\n# Create DataFrame\nsongDF = spark.createDataFrame(myData, schema=mySchema)\n\nsongDF.show()","user":"anonymous","dateUpdated":"2019-05-20T14:54:14+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n| Beastie Boys|    -5.0|\n|Frank Sinatra|   -10.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1558346072177_1431581933","id":"20190424-171413_534879665","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46511","dateFinished":"2019-05-20T14:54:23+0000","dateStarted":"2019-05-20T14:54:14+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=243","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=244"],"interpreterSettingId":"spark"}}},{"text":"%md \n## Querying DataFrames in a SQL-like fashion\n\nDataFrames provide a column oriented API similar to SQL.\nWe can use SQL commands directly on DataFrames.","user":"anonymous","dateUpdated":"2019-05-20T09:54:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Querying DataFrames in a SQL-like fashion</h2>\n<p>DataFrames provide a column oriented API similar to SQL.<br/>We can use SQL commands directly on DataFrames.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072178_826510756","id":"20190424-171421_619393437","dateCreated":"2019-05-20T09:54:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46512"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-20T14:55:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072187_-1618999542","id":"20190424-171429_2047339428","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46513","dateFinished":"2019-05-20T14:55:16+0000","dateStarted":"2019-05-20T14:55:16+0000"},{"text":"%spark\nval filteredSongArrayFromDF = songDF.where($\"loudness\" > -8.0)\n                                    .select($\"artist\")\n                                    .show()\n","user":"anonymous","dateUpdated":"2019-05-20T14:56:03+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+\n|      artist|\n+------------+\n|Beastie Boys|\n|        Muse|\n+------------+\n\nfilteredSongArrayFromDF: Unit = ()\n"}]},"apps":[],"jobName":"paragraph_1558346072188_-2053241863","id":"20190424-171436_236422760","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46514","dateFinished":"2019-05-20T14:56:03+0000","dateStarted":"2019-05-20T14:56:03+0000"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-20T14:55:41+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346072189_-51280910","id":"20190424-171447_1388774258","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46515","dateFinished":"2019-05-20T14:55:41+0000","dateStarted":"2019-05-20T14:55:41+0000"},{"text":"%pyspark\nsongDF.where(songDF.loudness > -8.0).select(songDF.artist).show()","user":"anonymous","dateUpdated":"2019-05-20T14:56:30+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+\n|      artist|\n+------------+\n|Beastie Boys|\n|        Muse|\n+------------+\n\n"}]},"apps":[],"jobName":"paragraph_1558346072189_-1391536872","id":"20190424-171454_1079566912","dateCreated":"2019-05-20T09:54:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:46516","dateFinished":"2019-05-20T14:56:31+0000","dateStarted":"2019-05-20T14:56:30+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=247","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=248"],"interpreterSettingId":"spark"}}}],"name":"/2. Operations: Transformations & Actions/2.3 DataFrame and Dataset: Transformations & Actions","id":"2EC8E99DW","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}