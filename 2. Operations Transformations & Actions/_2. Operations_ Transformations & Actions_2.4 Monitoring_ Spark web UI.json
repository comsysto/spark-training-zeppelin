{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091267_-862415939","id":"20190424-171614_1563320323","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:49464"},{"text":"%md\n# 2.4 Monitoring: Spark web UI","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>2.4 Monitoring: Spark web UI</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091267_859068152","id":"20190424-171619_606788995","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49465"},{"text":"%md\n***2.4.1 Monitoring options of Spark applications***\n\n***2.4.2 Nomenclature: Tasks, Stages & Jobs***\n\n***2.4.3 Using the Spark web UI in an example***\n\n***2.4.4 Excursion: Ganglia***","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>2.4.1 Monitoring options of Spark applications</em></strong></p>\n<p><strong><em>2.4.2 Nomenclature: Tasks, Stages &amp; Jobs</em></strong></p>\n<p><strong><em>2.4.3 Using the Spark web UI in an example</em></strong></p>\n<p><strong><em>2.4.4 Excursion: Ganglia</em></strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091267_-1709196225","id":"20190424-171625_1521400062","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49466"},{"text":"%md\n## 2.4.1 Monitoring options of Spark applications","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.1 Monitoring options of Spark applications</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091268_1101299027","id":"20190424-171631_1954347856","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49467"},{"text":"%md\n***Spark web UI***\n- Every `SparkContext` launches a Spark web UI run by the driver\n- The Spark web UI is only available during the application is runing\n- Accessible via opening `http://<driver-node>:4040` in a web brower\n- In databricks: click on cluster -> View Spark UI\n\n***Spark history server***\n- To view the Spark web UI after applications are finished, you have to set the `spark.eventLog.enabled` [Spark History Server Configuration Option](https://spark.apache.org/docs/latest/monitoring.html#spark-history-server-configuration-options) to `true` in advance\n- Start the history server with executing `./sbin/start-history-server.sh` and access `http://<server-url>:18080`\n\n***Metrics***\n- Spark has a configurable metrics system\n- This metrics system enables to report Spark metrics in separate spaces like HTTP, JMX and CSV\n\n***External instrumentation***\n- Ganglia\n- dstat, iostat, iotop\n- jstack, jmapj, jstat, jconsole","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Spark web UI</em></strong><br/>- Every <code>SparkContext</code> launches a Spark web UI run by the driver<br/>- The Spark web UI is only available during the application is runing<br/>- Accessible via opening <code>http://&lt;driver-node&gt;:4040</code> in a web brower<br/>- In databricks: click on cluster -&gt; View Spark UI</p>\n<p><strong><em>Spark history server</em></strong><br/>- To view the Spark web UI after applications are finished, you have to set the <code>spark.eventLog.enabled</code> <a href=\"https://spark.apache.org/docs/latest/monitoring.html#spark-history-server-configuration-options\">Spark History Server Configuration Option</a> to <code>true</code> in advance<br/>- Start the history server with executing <code>./sbin/start-history-server.sh</code> and access <code>http://&lt;server-url&gt;:18080</code></p>\n<p><strong><em>Metrics</em></strong><br/>- Spark has a configurable metrics system<br/>- This metrics system enables to report Spark metrics in separate spaces like HTTP, JMX and CSV</p>\n<p><strong><em>External instrumentation</em></strong><br/>- Ganglia<br/>- dstat, iostat, iotop<br/>- jstack, jmapj, jstat, jconsole</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091268_-1448057018","id":"20190424-171638_784775771","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49468"},{"text":"%md\n## 2.4.2 Nomenclature: Tasks, Stages & Jobs","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.2 Nomenclature: Tasks, Stages &amp; Jobs</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091268_-1124525593","id":"20190424-171644_117715989","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49469"},{"text":"%md <img src='http://www.lostinsoftware.com/wp-content/uploads/2016/02/img_56c0634b46ed6.png' style='width:800px'>","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='http://www.lostinsoftware.com/wp-content/uploads/2016/02/img_56c0634b46ed6.png' style='width:800px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091268_-1516333263","id":"20190424-171651_2121787721","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49470"},{"text":"%md\n**Task**\nPipeline of operations on one partition\n\n**Stage**\nEntirety of all tasks of one RDD which run in parallel and end with a shuffle event\n\n**Jobs**\nEntirety of all Stages","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong>Task</strong><br/>Pipeline of operations on one partition</p>\n<p><strong>Stage</strong><br/>Entirety of all tasks of one RDD which run in parallel and end with a shuffle event</p>\n<p><strong>Jobs</strong><br/>Entirety of all Stages</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091269_-475249268","id":"20190424-171658_154636726","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49471"},{"text":"%md\n## 2.4.3 Using the Spark web UI in an example\nWe will now demonstrate the Spark web UI with an example. The following query reads in the Spark Readme and displays the 10 top most used words in there.","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.3 Using the Spark web UI in an example</h2>\n<p>We will now demonstrate the Spark web UI with an example. The following query reads in the Spark Readme and displays the 10 top most used words in there.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091269_-1533395920","id":"20190424-171706_879560903","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49472"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-20T14:57:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091269_-1532036457","id":"20190424-171711_1678899382","dateCreated":"2019-05-20T09:54:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:49473","dateFinished":"2019-05-20T14:57:00+0000","dateStarted":"2019-05-20T14:57:00+0000"},{"text":"%spark\nval textRDD = sc.textFile(\"s3a://cs-spark-basic-training/sparkUI/\")\ntextRDD.take(18).foreach(println)\n\nval topWords = textRDD.flatMap(line => line.split(\" \"))    // flat each word into a single line\n                      .filter(line => !line.isEmpty)       // skip empty lines\n                      .map(word => (word, 1))              // map each word into a tuple (to be able to group and count words)\n                      .groupByKey()                        // group the RDD by each unique word\n                      .map(t => (t._1, t._2.size))         // count appearance of each word\n                      .sortBy(t => t._2, false)            // sort the RDD descending\n\n\nprintln(\"#################### RESULT ####################\")\n\n\ntopWords.take(10).foreach(println)                         // print the 10 top most used words in the Spark Readme file","user":"anonymous","dateUpdated":"2019-05-20T14:59:19+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"# Apache Spark\n\nSpark is a fast and general cluster computing system for Big Data. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\nMLlib for machine learning, GraphX for graph processing,\nand Spark Streaming for stream processing.\n\n<http://spark.apache.org/>\n\n\n## Online Documentation\n\nYou can find the latest Spark documentation, including a programming\nguide, on the [project web page](http://spark.apache.org/documentation.html).\nThis README file only contains basic setup instructions.\n\n#################### RESULT ####################\n(the,24)\n(to,17)\n(Spark,16)\n(for,12)\n(##,9)\n(and,9)\n(a,8)\n(can,7)\n(run,7)\n(on,7)\ntextRDD: org.apache.spark.rdd.RDD[String] = s3a://cs-spark-basic-training/sparkUI/ MapPartitionsRDD[665] at textFile at <console>:28\ntopWords: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[675] at sortBy at <console>:36\n"}]},"apps":[],"jobName":"paragraph_1558346091269_-124491773","id":"20190424-171721_1523667035","dateCreated":"2019-05-20T09:54:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:49474","dateFinished":"2019-05-20T14:59:20+0000","dateStarted":"2019-05-20T14:59:19+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=252","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=253","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=254"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-20T14:57:37+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091270_-1367634802","id":"20190424-171728_1702958561","dateCreated":"2019-05-20T09:54:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:49475","dateFinished":"2019-05-20T14:57:37+0000","dateStarted":"2019-05-20T14:57:37+0000"},{"text":"%pyspark\ntextRDD = sc.textFile(\"s3a://cs-spark-basic-training/sparkUI/\")\nfor element in textRDD.take(18):\n    print(element)\n\n# flat each word into a single line\n# skip empty lines\n# map each word into a tuple (to be able to group and count words)\n# group the RDD by each unique word\n# count appearance of each word\n# sort the RDD descending\ntopWords = textRDD.flatMap(lambda line: line.split(' ')).filter(lambda x: x != '').map(lambda x: (x, 1)).groupByKey().map(lambda x: (x[0], len(x[1]))).sortBy(lambda x: x[1], False)\nfor element in topWords.take(10):   # print the 10 top most used words in the Spark Readme file\n    print(element)","user":"anonymous","dateUpdated":"2019-05-20T15:07:19+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"# Apache Spark\n\nSpark is a fast and general cluster computing system for Big Data. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\nMLlib for machine learning, GraphX for graph processing,\nand Spark Streaming for stream processing.\n\n<http://spark.apache.org/>\n\n\n## Online Documentation\n\nYou can find the latest Spark documentation, including a programming\nguide, on the [project web page](http://spark.apache.org/documentation.html).\nThis README file only contains basic setup instructions.\n\n(u'the', 24)\n(u'to', 17)\n(u'Spark', 16)\n(u'for', 12)\n(u'##', 9)\n(u'and', 9)\n(u'a', 8)\n(u'run', 7)\n(u'on', 7)\n(u'can', 7)\n"}]},"apps":[],"jobName":"paragraph_1558346091270_-2037901959","id":"20190424-171744_775235657","dateCreated":"2019-05-20T09:54:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:49476","dateFinished":"2019-05-20T15:07:31+0000","dateStarted":"2019-05-20T15:07:19+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=274","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=275","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=276","http://ip-172-31-39-158.eu-central-1.compute.internal:4040/jobs/job?id=277"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 2.4.4 Excursion: Ganglia","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.4.4 Excursion: Ganglia</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091270_-1404624684","id":"20190424-171750_423720185","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49477"},{"text":"%md\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/image.png'>","user":"anonymous","dateUpdated":"2019-05-20T09:54:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/image.png'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558346091270_-1593096317","id":"20190424-171759_1776467034","dateCreated":"2019-05-20T09:54:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:49478"}],"name":"/2. Operations: Transformations & Actions/2.4 Monitoring: Spark web UI","id":"2EAW4TXZ4","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}