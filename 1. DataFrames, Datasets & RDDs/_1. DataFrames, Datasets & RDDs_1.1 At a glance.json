{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-15T09:13:41+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911621723_2011912328","id":"20190424-142725_669102133","dateCreated":"2019-05-15T09:13:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18321"},{"text":"%md \n# 1.1 At a glance: DataFrames, DataSets and RDDs\n\nOverview over the different Spark APIs for working with structured, semi-structured and unstructured data\n\n## **DataFrame** API - *Untyped* view on a Dataset - [Spark SQL Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row])\n- A DataFrame is a [`Dataset[Row]`](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row])\n- DataFrames are the top-level implementation of RDDs with most built-in functionality\n- Most useful for structured data in tabular form\n- DataFrames represent an ordered collection of [`Row`](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row) objects\n- Rows are organized into columns described by a schema\n\n## **Dataset** API - *Strongly typed* collection of domain-specific objects - [Dataset Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset)\n- Can be transformed in parallel using functional or relational operations\n- Available in Scala API only\n- Higher-level implementation of an RDD with more built-in functionality\n- Most useful for semi-structured data with a predictable type, or can be defined using a Scala case class.\n- Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.\n- Adding type information drastically improves memory usage when caching data\n- Datasets offer type-checking at compile time\n\n## **RDD** API - *Strongly typed* Resilient Distributed Dataset - [RDD Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD), [PairRDDFunctions Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions)\n- The basic abstraction in Spark. Represents an immutable, partitioned collection of any type of objects.\n- RDDs are the lowest level distributed dataset type in Spark, and therefore they are most useful for working with semi-structured and unstructured data. \n- RDDs do not have a schema. ","user":"anonymous","dateUpdated":"2019-05-15T14:15:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.1 At a glance: DataFrames, DataSets and RDDs</h1>\n<p>Overview over the different Spark APIs for working with structured, semi-structured and unstructured data</p>\n<h2><strong>DataFrame</strong> API - <em>Untyped</em> view on a Dataset - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\">Spark SQL Scaladoc</a></h2>\n<ul>\n  <li>A DataFrame is a <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\"><code>Dataset[Row]</code></a></li>\n  <li>DataFrames are the top-level implementation of RDDs with most built-in functionality</li>\n  <li>Most useful for structured data in tabular form</li>\n  <li>DataFrames represent an ordered collection of <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row\"><code>Row</code></a> objects</li>\n  <li>Rows are organized into columns described by a schema</li>\n</ul>\n<h2><strong>Dataset</strong> API - <em>Strongly typed</em> collection of domain-specific objects - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset Scaladoc</a></h2>\n<ul>\n  <li>Can be transformed in parallel using functional or relational operations</li>\n  <li>Available in Scala API only</li>\n  <li>Higher-level implementation of an RDD with more built-in functionality</li>\n  <li>Most useful for semi-structured data with a predictable type, or can be defined using a Scala case class.</li>\n  <li>Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.</li>\n  <li>Adding type information drastically improves memory usage when caching data</li>\n  <li>Datasets offer type-checking at compile time</li>\n</ul>\n<h2><strong>RDD</strong> API - <em>Strongly typed</em> Resilient Distributed Dataset - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD\">RDD Scaladoc</a>, <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions\">PairRDDFunctions Scaladoc</a></h2>\n<ul>\n  <li>The basic abstraction in Spark. Represents an immutable, partitioned collection of any type of objects.</li>\n  <li>RDDs are the lowest level distributed dataset type in Spark, and therefore they are most useful for working with semi-structured and unstructured data.</li>\n  <li>RDDs do not have a schema.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911621731_-420309692","id":"20190424-142828_902452779","dateCreated":"2019-05-15T09:13:41+0000","dateStarted":"2019-05-15T14:15:20+0000","dateFinished":"2019-05-15T14:15:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:18322"}],"name":"/1. DataFrames, Datasets & RDDs/1.1 At a glance","id":"2ECXSGBGQ","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}