{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111429983_2068210412","id":"20190424-151029_271323062","dateCreated":"2019-04-24T15:10:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17849","text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","dateUpdated":"2019-04-24T15:10:36+0200","dateFinished":"2019-04-24T15:10:36+0200","dateStarted":"2019-04-24T15:10:36+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]}},{"text":"%md\n# 1.3 Datasets","user":"anonymous","dateUpdated":"2019-04-24T15:10:42+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111436442_-1844812501","id":"20190424-151036_611950532","dateCreated":"2019-04-24T15:10:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17927","dateFinished":"2019-04-24T15:10:42+0200","dateStarted":"2019-04-24T15:10:42+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.3 Datasets</h1>\n</div>"}]}},{"text":"%md\n***1.3.1 Datasets in general***\n\n***1.3.2 Dataset example***\n\n***1.3.3 Dataset API (high-level operations)***\n\n***1.3.4 Dataset API (low-level operations)***\n\n***1.3.5 Case classes***\n\n* 1.3.5.1 Define case class\n\n* 1.3.5.2 Create Datasets from case class\n\n* 1.3.5.3 Dataset API\n\n* 1.3.5.4 Customized functions inside case class","user":"anonymous","dateUpdated":"2019-04-24T15:10:48+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111442251_747230527","id":"20190424-151042_1564811121","dateCreated":"2019-04-24T15:10:42+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18021","dateFinished":"2019-04-24T15:10:48+0200","dateStarted":"2019-04-24T15:10:48+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>1.3.1 Datasets in general</em></strong></p>\n<p><strong><em>1.3.2 Dataset example</em></strong></p>\n<p><strong><em>1.3.3 Dataset API (high-level operations)</em></strong></p>\n<p><strong><em>1.3.4 Dataset API (low-level operations)</em></strong></p>\n<p><strong><em>1.3.5 Case classes</em></strong></p>\n<ul>\n  <li>\n  <p>1.3.5.1 Define case class</p></li>\n  <li>\n  <p>1.3.5.2 Create Datasets from case class</p></li>\n  <li>\n  <p>1.3.5.3 Dataset API</p></li>\n  <li>\n  <p>1.3.5.4 Customized functions inside case class</p></li>\n</ul>\n</div>"}]}},{"text":"%md \n## 1.3.1 Datasets in general\n\n*   **Dataset API** - *Strongly typed* collection of domain-specific objects - [Dataset Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset)\n      * Can be transformed in parallel using functional or relational operations\n      * Available in Scala API only\n      * Higher-level implementation of an RDD with more built-in functionality\n      * Most useful for semi-structured data with a predictable type, or can be defined using a Scala case class.\n      * Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.\n      * Adding type information drastically improves memory usage when caching data\n      * Datasets offer type-checking at compile time\n      * In comparison to DataFrames, DataSets can´t get loaded from files (conversion of DataFrame or RDD to Dataset necessary)\n      * Datasets use RDDs internally and provide therefore similar in comparison to RDDs.\n      * Datasets automatically apply optimizations before executing operations. This results in an increased performance compared to RDDs.","user":"anonymous","dateUpdated":"2019-04-24T15:10:54+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111448067_1955413408","id":"20190424-151048_970088704","dateCreated":"2019-04-24T15:10:48+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18111","dateFinished":"2019-04-24T15:10:54+0200","dateStarted":"2019-04-24T15:10:54+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.1 Datasets in general</h2>\n<ul>\n  <li><strong>Dataset API</strong> - <em>Strongly typed</em> collection of domain-specific objects - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset Scaladoc</a>\n    <ul>\n      <li>Can be transformed in parallel using functional or relational operations</li>\n      <li>Available in Scala API only</li>\n      <li>Higher-level implementation of an RDD with more built-in functionality</li>\n      <li>Most useful for semi-structured data with a predictable type, or can be defined using a Scala case class.</li>\n      <li>Datasets are not available in PySpark, but SchemaRDDs are the most similar implementation to Datasets available in PySpark.</li>\n      <li>Adding type information drastically improves memory usage when caching data</li>\n      <li>Datasets offer type-checking at compile time</li>\n      <li>In comparison to DataFrames, DataSets can´t get loaded from files (conversion of DataFrame or RDD to Dataset necessary)</li>\n      <li>Datasets use RDDs internally and provide therefore similar in comparison to RDDs.</li>\n      <li>Datasets automatically apply optimizations before executing operations. This results in an increased performance compared to RDDs.</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]}},{"text":"%md\n## 1.3.2 Dataset example","user":"anonymous","dateUpdated":"2019-04-24T15:11:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111454835_-1326151732","id":"20190424-151054_1962013627","dateCreated":"2019-04-24T15:10:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18201","dateFinished":"2019-04-24T15:11:01+0200","dateStarted":"2019-04-24T15:11:01+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.2 Dataset example</h2>\n</div>"}]}},{"text":"%spark\n//path of data source file\nval dataPath = \"dbfs:/cs-spark-training/SongDS/SongDS.csv\"","user":"anonymous","dateUpdated":"2019-04-24T15:11:17+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111461579_-1019669110","id":"20190424-151101_1189161016","dateCreated":"2019-04-24T15:11:01+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18291","dateFinished":"2019-04-24T15:11:17+0200","dateStarted":"2019-04-24T15:11:17+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dataPath: String = dbfs:/cs-spark-training/SongDS/SongDS.csv\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111467715_916431246","id":"20190424-151107_1403475661","dateCreated":"2019-04-24T15:11:07+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18381","text":"// create DataFrame from CSV file\nval songDF = spark.read\n                  .option(\"inferSchema\", true)\n                  .option(\"header\", true)\n                  .option(\"delimiter\", \",\")\n                  .csv(dataPath)\n                  \nsongDF.printSchema()\nsongDF.show(false)","dateUpdated":"2019-04-24T15:12:07+0200","dateFinished":"2019-04-24T15:12:08+0200","dateStarted":"2019-04-24T15:12:07+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:412)\n  ... 51 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111527747_11924352","id":"20190424-151207_2000963151","dateCreated":"2019-04-24T15:12:07+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18518","text":"//Convert DataFrame to Dataset by storing columns into tuple\nval songDS = songDF.as[(String, Double, String)]\n\nsongDS.printSchema()\nsongDS.show(false)","dateUpdated":"2019-04-24T15:12:14+0200","dateFinished":"2019-04-24T15:12:14+0200","dateStarted":"2019-04-24T15:12:14+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songDF\n       val songDS = songDF.as[(String, Double, String)]\n                    ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111534939_1280589624","id":"20190424-151214_470210732","dateCreated":"2019-04-24T15:12:14+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18615","text":"%md\n## 1.3.3 Dataset API (high-level operations)","dateUpdated":"2019-04-24T15:12:21+0200","dateFinished":"2019-04-24T15:12:21+0200","dateStarted":"2019-04-24T15:12:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.3 Dataset API (high-level operations)</h2>\n</div>"}]}},{"text":"%spark\n//Filter artists with loudness greater than -7\nsongDS.filter($\"loudness\" > -7.0).show(false)\n\n//Filter songs which contain 'Star'\nsongDS.filter($\"songs\" like \"%Star%\").show(false)\n\n//Count artists\nsongDS.count()","user":"anonymous","dateUpdated":"2019-04-24T15:12:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111541083_1709299528","id":"20190424-151221_1875239757","dateCreated":"2019-04-24T15:12:21+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18704","dateFinished":"2019-04-24T15:12:35+0200","dateStarted":"2019-04-24T15:12:35+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:38: error: not found: value songDS\n       songDS.count()\n       ^\n<console>:30: error: not found: value songDS\n       songDS.filter($\"loudness\" > -7.0).show(false)\n       ^\n<console>:33: error: not found: value songDS\n       songDS.filter($\"songs\" like \"%Star%\").show(false)\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111547779_-1163043475","id":"20190424-151227_805721901","dateCreated":"2019-04-24T15:12:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18794","text":"%md\n## 1.3.4 Dataset API (Low-level operations)","dateUpdated":"2019-04-24T15:12:43+0200","dateFinished":"2019-04-24T15:12:43+0200","dateStarted":"2019-04-24T15:12:43+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.4 Dataset API (Low-level operations)</h2>\n</div>"}]}},{"text":"%md\n##### Task: Count songs per artist\n\n- Problem: songs data is unstructered.\n\n- High-level Dataset operations no longer sufficient.\n\n- But Dataset also allow low-level access.\n\n- Dataset allow high- and low-level operations (also in combination).","user":"anonymous","dateUpdated":"2019-04-24T15:12:55+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111563531_1702609205","id":"20190424-151243_1891533047","dateCreated":"2019-04-24T15:12:43+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18918","dateFinished":"2019-04-24T15:12:55+0200","dateStarted":"2019-04-24T15:12:55+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>Task: Count songs per artist</h5>\n<ul>\n  <li>\n  <p>Problem: songs data is unstructered.</p></li>\n  <li>\n  <p>High-level Dataset operations no longer sufficient.</p></li>\n  <li>\n  <p>But Dataset also allow low-level access.</p></li>\n  <li>\n  <p>Dataset allow high- and low-level operations (also in combination).</p></li>\n</ul>\n</div>"}]}},{"text":"%spark\nsongDS.show(false)","user":"anonymous","dateUpdated":"2019-04-24T15:13:05+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111569132_1854237090","id":"20190424-151249_2123683881","dateCreated":"2019-04-24T15:12:49+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19008","dateFinished":"2019-04-24T15:13:05+0200","dateStarted":"2019-04-24T15:13:05+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songDS\n       songDS.show(false)\n       ^\n"}]}},{"text":"//First of all we need to structure the songs data in a fashion we can count them\n//One artist can have a lot of songs. Therefore we don´t want to distribute all songs over columns.\n//Instead we flatten the songs data row-wise. So we arrange the data in a 'count friendly' fashion -> one row for each song\n//The best way to do this is to split the songs data and use 'flatMap'\n\nval flatSongDS = songDS.flatMap(s => s._3.split(\",\"))    //(Typed) Transformation: Dataset => Dataset\n\nflatSongDS.show(false)","user":"anonymous","dateUpdated":"2019-04-24T15:13:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111585875_-905513442","id":"20190424-151305_536009152","dateCreated":"2019-04-24T15:13:05+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19120","dateFinished":"2019-04-24T15:13:13+0200","dateStarted":"2019-04-24T15:13:13+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:34: error: not found: value songDS\n       val flatSongDS = songDS.flatMap(s => s._3.split(\",\"))    //(Typed) Transformation: Dataset => Dataset\n                        ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111593436_-438530614","id":"20190424-151313_561018803","dateCreated":"2019-04-24T15:13:13+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19208","text":"//As a result we get one row for each song.\n//The problem is that we loose the artist data. So we can´t count songs per artist.\n//Solution: Additional mapping step of songs data to keep artist and loudness data.\n\nval songDsFlattened = songDS.flatMap(s => s._3.split(\",\").map {song => (s._1, s._2, song)})   //(Typed) Transformation: Dataset => Dataset\n\nsongDsFlattened.show(false)","dateUpdated":"2019-04-24T15:13:22+0200","dateFinished":"2019-04-24T15:13:22+0200","dateStarted":"2019-04-24T15:13:22+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:33: error: not found: value songDS\n       val songDsFlattened = songDS.flatMap(s => s._3.split(\",\").map {song => (s._1, s._2, song)})   //(Typed) Transformation: Dataset => Dataset\n                             ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111602195_-243246113","id":"20190424-151322_1952641322","dateCreated":"2019-04-24T15:13:22+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19296","text":"//We can see that the last operation changed the header of the Dataset.\n//As an additional, cosmetical step we manually change the current header to the original one. \n\nval songDsNamed = songDsFlattened.withColumnRenamed(\"_1\", \"artist\")     //(Untyped) Transformation: Dataset => DataFrame\n                                 .withColumnRenamed(\"_2\", \"loudness\")   //(Untyped) Transformation: Dataset => DataFrame\n                                 .withColumnRenamed(\"_3\", \"songs\")      //(Untyped) Transformation: Dataset => DataFrame\nsongDsNamed.show(false)","dateUpdated":"2019-04-24T15:13:29+0200","dateFinished":"2019-04-24T15:13:29+0200","dateStarted":"2019-04-24T15:13:29+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:32: error: not found: value songDsFlattened\n       val songDsNamed = songDsFlattened.withColumnRenamed(\"_1\", \"artist\")     //(Untyped) Transformation: Dataset => DataFrame\n                         ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111609484_2048904950","id":"20190424-151329_175133160","dateCreated":"2019-04-24T15:13:29+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19384","text":"//In the end we receive only structured data which can get easily counted\n\nval songDsCount = songDsNamed.groupBy($\"artist\")   //(Untyped) Transformation: DataFrame => DataFrame\n                             .count()              //Action: DataFrame\n                             \nsongDsCount.show()","dateUpdated":"2019-04-24T15:13:42+0200","dateFinished":"2019-04-24T15:13:42+0200","dateStarted":"2019-04-24T15:13:42+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:31: error: not found: value songDsNamed\n       val songDsCount = songDsNamed.groupBy($\"artist\")   //(Untyped) Transformation: DataFrame => DataFrame\n                         ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111622452_-1935580640","id":"20190424-151342_2001294743","dateCreated":"2019-04-24T15:13:42+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19472","text":"%md\n## 1.3.5 Case classes\n* Instantiable class\n\n* Very useful to create an individual Dataset structure incl. data types\n\n* Extendable with methods for individual use cases\n\n* Arguments of case class represent Dataset columns incl. their data types","dateUpdated":"2019-04-24T15:13:49+0200","dateFinished":"2019-04-24T15:13:49+0200","dateStarted":"2019-04-24T15:13:49+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5 Case classes</h2>\n<ul>\n  <li>\n  <p>Instantiable class</p></li>\n  <li>\n  <p>Very useful to create an individual Dataset structure incl. data types</p></li>\n  <li>\n  <p>Extendable with methods for individual use cases</p></li>\n  <li>\n  <p>Arguments of case class represent Dataset columns incl. their data types</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n## 1.3.5.1 Define case class","user":"anonymous","dateUpdated":"2019-04-24T15:13:56+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111629348_1870335134","id":"20190424-151349_439462677","dateCreated":"2019-04-24T15:13:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19561","dateFinished":"2019-04-24T15:13:56+0200","dateStarted":"2019-04-24T15:13:56+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5.1 Define case class</h2>\n</div>"}]}},{"text":"%spark\n//arugments of the case class represent the columns of the DataSet\ncase class Music(artist: String, loudness: Double, songs: String)\n{\n  \n    def artistToUpperCase(): (String, Double, String) = {\n      (artist.toUpperCase, loudness, songs)\n    }\n \n} ","user":"anonymous","dateUpdated":"2019-04-24T15:14:10+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111636700_322507657","id":"20190424-151356_1970308533","dateCreated":"2019-04-24T15:13:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19651","dateFinished":"2019-04-24T15:14:10+0200","dateStarted":"2019-04-24T15:14:10+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class Music\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111643748_-903698999","id":"20190424-151403_1037432058","dateCreated":"2019-04-24T15:14:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19741","text":"%md\n### 1.3.5.2 Create Datasets from case class","dateUpdated":"2019-04-24T15:14:19+0200","dateFinished":"2019-04-24T15:14:19+0200","dateStarted":"2019-04-24T15:14:19+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>1.3.5.2 Create Datasets from case class</h3>\n</div>"}]}},{"text":"%spark\n//create DataSet of type 'Music' out of DataFrame\n\nval musicDS = songDF.as[Music]\n\nmusicDS.printSchema()\nmusicDS.show(false)","user":"anonymous","dateUpdated":"2019-04-24T15:14:27+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111659932_-1985011748","id":"20190424-151419_992018657","dateCreated":"2019-04-24T15:14:19+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19879","dateFinished":"2019-04-24T15:14:27+0200","dateStarted":"2019-04-24T15:14:27+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:33: error: not found: value songDF\n       val musicDS = songDF.as[Music]\n                     ^\n"}]}},{"text":"%md\n## 1.3.5.3 Use Dataset API","user":"anonymous","dateUpdated":"2019-04-24T15:14:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111667803_2070272014","id":"20190424-151427_1981328047","dateCreated":"2019-04-24T15:14:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19968","dateFinished":"2019-04-24T15:14:35+0200","dateStarted":"2019-04-24T15:14:35+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5.3 Use Dataset API</h2>\n</div>"}]}},{"text":"%spark\n//apply high-level filter\nmusicDS.filter($\"loudness\" > -8.0).show()\n\n//count lines of Dataset\nmusicDS.count()","user":"anonymous","dateUpdated":"2019-04-24T15:14:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111675660_1778498404","id":"20190424-151435_2039253808","dateCreated":"2019-04-24T15:14:35+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:20057","dateFinished":"2019-04-24T15:14:46+0200","dateStarted":"2019-04-24T15:14:45+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:35: error: not found: value musicDS\n       musicDS.count()\n       ^\n<console>:30: error: not found: value musicDS\n       musicDS.filter($\"loudness\" > -8.0).show()\n       ^\n"}]}},{"text":"%md\n## 1.3.5.4 Customized functions inside case class","user":"anonymous","dateUpdated":"2019-04-24T15:14:53+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111685972_-535215067","id":"20190424-151445_284042960","dateCreated":"2019-04-24T15:14:45+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:20146","dateFinished":"2019-04-24T15:14:53+0200","dateStarted":"2019-04-24T15:14:53+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.3.5.4 Customized functions inside case class</h2>\n</div>"}]}},{"text":"%spark\n//call defined function 'upperArtist' in case class\n\nval upperArtist = musicDS.map(a => a.artistToUpperCase)\n\nupperArtist.show(false)","user":"anonymous","dateUpdated":"2019-04-24T15:15:08+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111693284_407179071","id":"20190424-151453_343196541","dateCreated":"2019-04-24T15:14:53+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:20235","dateFinished":"2019-04-24T15:15:08+0200","dateStarted":"2019-04-24T15:15:08+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:31: error: not found: value musicDS\n       val upperArtist = musicDS.map(a => a.artistToUpperCase)\n                         ^\n"}]}}],"name":"/1. DataFrames, Datasets & RDDs/1.3 Datasets","id":"2EBAZUT9S","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}