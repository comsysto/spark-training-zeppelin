{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-04-24T15:16:16+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1556111769872_-1247460441","id":"20190424-151609_1929210218","dateCreated":"2019-04-24T15:16:09+0200","dateStarted":"2019-04-24T15:16:16+0200","dateFinished":"2019-04-24T15:16:16+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:24624"},{"text":"%md\n# 1.4 RDDs","user":"anonymous","dateUpdated":"2019-04-24T15:24:36+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.4 RDDs</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1556111776788_1387258553","id":"20190424-151616_2001197698","dateCreated":"2019-04-24T15:16:16+0200","dateStarted":"2019-04-24T15:24:36+0200","dateFinished":"2019-04-24T15:24:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:24625"},{"text":"%md\n***1.4.1 RDDs in general***\n\n***1.4.2 RDD example***\n\n***1.4.3 RDD API***\n\n***1.4.3.1 Named transformation function***\n\n***1.4.3.2 Anonymous transformation function (lambda function)***","user":"anonymous","dateUpdated":"2019-04-24T15:24:41+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>1.4.1 RDDs in general</em></strong></p>\n<p><strong><em>1.4.2 RDD example</em></strong></p>\n<p><strong><em>1.4.3 RDD API</em></strong></p>\n<p><strong><em>1.4.3.1 Named transformation function</em></strong></p>\n<p><strong><em>1.4.3.2 Anonymous transformation function (lambda function)</em></strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1556112276110_1905669147","id":"20190424-152436_60308220","dateCreated":"2019-04-24T15:24:36+0200","dateStarted":"2019-04-24T15:24:41+0200","dateFinished":"2019-04-24T15:24:41+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:24626"},{"text":"%md\n## 1.4.1 RDDs in general\n\n*   **RDD API** - *Strongly typed* Resilient Distributed Dataset - [RDD Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD), [PairRDDFunctions Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions)\n      *   The basic abstraction and key concept in Spark. Represents an immutable, partitioned collection of any type of objects.\n      *   RDDs are the lowest level distributed dataset type in Spark, and therefore they are most useful for working with semi-structured and unstructured data. \n      *   RDDs do not provide a schema.\n      *   Spark SQL not applicable on RDDs.\n      *   RDD transformations usually use lambda functions (anonymous functions).\n      *   RDDs can contain any type of object\n      *   RDDs are less efficient in comparison to DataFrames and Datasets.","user":"anonymous","dateUpdated":"2019-04-24T15:24:50+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.4.1 RDDs in general</h2>\n<ul>\n  <li><strong>RDD API</strong> - <em>Strongly typed</em> Resilient Distributed Dataset - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD\">RDD Scaladoc</a>, <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions\">PairRDDFunctions Scaladoc</a>\n    <ul>\n      <li>The basic abstraction and key concept in Spark. Represents an immutable, partitioned collection of any type of objects.</li>\n      <li>RDDs are the lowest level distributed dataset type in Spark, and therefore they are most useful for working with semi-structured and unstructured data.</li>\n      <li>RDDs do not provide a schema.</li>\n      <li>Spark SQL not applicable on RDDs.</li>\n      <li>RDD transformations usually use lambda functions (anonymous functions).</li>\n      <li>RDDs can contain any type of object</li>\n      <li>RDDs are less efficient in comparison to DataFrames and Datasets.</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1556112281381_-1326616104","id":"20190424-152441_1164603987","dateCreated":"2019-04-24T15:24:41+0200","dateStarted":"2019-04-24T15:24:50+0200","dateFinished":"2019-04-24T15:24:50+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:24627"},{"text":"%md\n## 1.4.2 RDD example","user":"anonymous","dateUpdated":"2019-04-24T15:24:57+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.4.2 RDD example</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1556112290454_466879797","id":"20190424-152450_218496276","dateCreated":"2019-04-24T15:24:50+0200","dateStarted":"2019-04-24T15:24:57+0200","dateFinished":"2019-04-24T15:24:57+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:24628"},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:26:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112297181_-1471004179","id":"20190424-152457_152223263","dateCreated":"2019-04-24T15:24:57+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:24629","dateFinished":"2019-04-24T15:26:03+0200","dateStarted":"2019-04-24T15:26:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//path of data source file\nval dataPath = \"dbfs:/cs-spark-training/SongRDD/\"","user":"anonymous","dateUpdated":"2019-04-24T15:26:15+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112363542_-1262434820","id":"20190424-152603_273665513","dateCreated":"2019-04-24T15:26:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25100","dateFinished":"2019-04-24T15:26:15+0200","dateStarted":"2019-04-24T15:26:15+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dataPath: String = dbfs:/cs-spark-training/SongRDD/\n"}]}},{"text":"//read in text file as RDD\nval songRDD = sc.textFile(dataPath) //sc is the preconfigured SparkContext in databricks notebooks","user":"anonymous","dateUpdated":"2019-04-24T15:26:34+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112389150_-1225991647","id":"20190424-152629_1611906913","dateCreated":"2019-04-24T15:26:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25377","dateFinished":"2019-04-24T15:26:35+0200","dateStarted":"2019-04-24T15:26:34+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"songRDD: org.apache.spark.rdd.RDD[String] = dbfs:/cs-spark-training/SongRDD/ MapPartitionsRDD[1] at textFile at <console>:34\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T15:26:22+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112375478_-1850256209","id":"20190424-152615_1324355282","dateCreated":"2019-04-24T15:26:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25190","dateFinished":"2019-04-24T15:26:22+0200","dateStarted":"2019-04-24T15:26:22+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\ndataPath = r'dbfs:/cs-spark-training/SongRDD/'\nsongRDD = sc.textFile(dataPath)\nsongRDD.take(2)","user":"anonymous","dateUpdated":"2019-04-24T15:26:59+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112382839_1775702984","id":"20190424-152622_226263089","dateCreated":"2019-04-24T15:26:22+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25288","dateFinished":"2019-04-24T15:26:59+0200","dateStarted":"2019-04-24T15:26:59+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'sc' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'sc' is not defined\n\n"}]}},{"text":"%md\n### Display content\n\n*   The RDD API doesn´t provide a high-level implementation to display the elements of a RDD.\n\n*   If the RDD is located on a single machine it is sufficient to call `foreach(println)`or `map(println)`.\n\n*   If the RDD is distributed across a cluster you have to call `collect` first which will bring the RDD to the driver node.\n\n###### ATTENTION: If your RDD is too big respectively your cluster is to small, the `collect` call maybe cause the driver to run out of memory. Therefore it is suggested to use `take()` instead which will return only a subset of elements of the RDD.######","user":"anonymous","dateUpdated":"2019-04-24T15:27:12+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112419733_-273605674","id":"20190424-152659_1427670486","dateCreated":"2019-04-24T15:26:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25474","dateFinished":"2019-04-24T15:27:12+0200","dateStarted":"2019-04-24T15:27:12+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Display content</h3>\n<ul>\n  <li>\n  <p>The RDD API doesn´t provide a high-level implementation to display the elements of a RDD.</p></li>\n  <li>\n  <p>If the RDD is located on a single machine it is sufficient to call <code>foreach(println)</code>or <code>map(println)</code>.</p></li>\n  <li>\n  <p>If the RDD is distributed across a cluster you have to call <code>collect</code> first which will bring the RDD to the driver node.</p></li>\n</ul>\n<h6>ATTENTION: If your RDD is too big respectively your cluster is to small, the <code>collect</code> call maybe cause the driver to run out of memory. Therefore it is suggested to use <code>take()</code> instead which will return only a subset of elements of the RDD.</h6>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:27:25+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112427119_-735653937","id":"20190424-152707_2052929290","dateCreated":"2019-04-24T15:27:07+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25563","dateFinished":"2019-04-24T15:27:25+0200","dateStarted":"2019-04-24T15:27:25+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//display all elements of the RDD\nsongRDD.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-04-24T15:27:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112445726_1814761542","id":"20190424-152725_558124096","dateCreated":"2019-04-24T15:27:25+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25676","dateFinished":"2019-04-24T15:27:35+0200","dateStarted":"2019-04-24T15:27:35+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n  ... 51 elided\n"}]}},{"text":"//display only the first two elements of the RDD\nsongRDD.take(2).map(println)","user":"anonymous","dateUpdated":"2019-04-24T15:28:04+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112469949_-749863002","id":"20190424-152749_806312458","dateCreated":"2019-04-24T15:27:49+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25952","dateFinished":"2019-04-24T15:28:05+0200","dateStarted":"2019-04-24T15:28:04+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1333)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.take(RDD.scala:1327)\n  ... 51 elided\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T15:27:42+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112455167_1457019942","id":"20190424-152735_1330172356","dateCreated":"2019-04-24T15:27:35+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25765","dateFinished":"2019-04-24T15:27:42+0200","dateStarted":"2019-04-24T15:27:42+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\n# for python 2.x you will need a properly defined function, because print ist NOT a function\n# def f(x): print(x)\n# alternative is either using python 3.x or:\nfrom __future__ import print_function\n\n# this will still not work on databricks notebooks ¯\\_(ツ)_/¯\nsongRDD.foreach(print)\nsongRDD.map(print)\n\n# the expressive way\nfor entry in songRDD.take(3): print(entry)\n  \n# the pythonic way\nprint(*songRDD.take(3), sep='\\n')\n\n# or just...\nsongRDD.take(3)","user":"anonymous","dateUpdated":"2019-04-24T15:28:28+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112462303_95893709","id":"20190424-152742_114999039","dateCreated":"2019-04-24T15:27:42+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:25863","dateFinished":"2019-04-24T15:28:28+0200","dateStarted":"2019-04-24T15:28:28+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'songRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'songRDD' is not defined\n\n"}]}},{"text":"%md\n## 1.4.3 RDD API\n\n*   Transformations of RDDs in general require use case specific **transformation functions**. A few transformations like `distinct` or `union` use their own, preconfigured transformation function.\n\n*   Functional programming as the underlying paradigm for transformation functions.\n\n*   Transformation functions can either be **named** or **anonymous**.","user":"anonymous","dateUpdated":"2019-04-24T15:28:40+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112508791_1165207157","id":"20190424-152828_250043999","dateCreated":"2019-04-24T15:28:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26049","dateFinished":"2019-04-24T15:28:40+0200","dateStarted":"2019-04-24T15:28:40+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.4.3 RDD API</h2>\n<ul>\n  <li>\n  <p>Transformations of RDDs in general require use case specific <strong>transformation functions</strong>. A few transformations like <code>distinct</code> or <code>union</code> use their own, preconfigured transformation function.</p></li>\n  <li>\n  <p>Functional programming as the underlying paradigm for transformation functions.</p></li>\n  <li>\n  <p>Transformation functions can either be <strong>named</strong> or <strong>anonymous</strong>.</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n### 1.4.3.1 Named transformation function","user":"anonymous","dateUpdated":"2019-04-24T15:28:53+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112520895_1857545578","id":"20190424-152840_1171699574","dateCreated":"2019-04-24T15:28:40+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26138","dateFinished":"2019-04-24T15:28:53+0200","dateStarted":"2019-04-24T15:28:53+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>1.4.3.1 Named transformation function</h3>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:29:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112528551_308097207","id":"20190424-152848_1601840268","dateCreated":"2019-04-24T15:28:48+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26228","dateFinished":"2019-04-24T15:29:03+0200","dateStarted":"2019-04-24T15:29:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Named transformation function\ndef rddToUpper(element: String): String = {\n  element.toUpperCase\n}\n\n//Call named transformation function 'rddToUpper' and display the transformed elements of the RDD\nsongRDD.map(rddToUpper).collect.foreach(println)","user":"anonymous","dateUpdated":"2019-04-24T15:29:15+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112543943_-40611169","id":"20190424-152903_639900368","dateCreated":"2019-04-24T15:29:03+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26341","dateFinished":"2019-04-24T15:29:16+0200","dateStarted":"2019-04-24T15:29:15+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n  ... 51 elided\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T15:29:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112555750_-208339460","id":"20190424-152915_438468124","dateCreated":"2019-04-24T15:29:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26430","dateFinished":"2019-04-24T15:29:35+0200","dateStarted":"2019-04-24T15:29:35+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\ndef rddToUpper(x): return str(x).upper()\nprint(*songRDD.map(rddToUpper).collect(), sep='\\n')","user":"anonymous","dateUpdated":"2019-04-24T15:29:42+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112575735_-643720590","id":"20190424-152935_1420873011","dateCreated":"2019-04-24T15:29:35+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26528","dateFinished":"2019-04-24T15:29:43+0200","dateStarted":"2019-04-24T15:29:43+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'songRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'songRDD' is not defined\n\n"}]}},{"text":"%md\n### 1.4.3.2 Anonymous transformation function (lambda function)","user":"anonymous","dateUpdated":"2019-04-24T15:29:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112582983_55021310","id":"20190424-152942_428476182","dateCreated":"2019-04-24T15:29:42+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26617","dateFinished":"2019-04-24T15:29:58+0200","dateStarted":"2019-04-24T15:29:58+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>1.4.3.2 Anonymous transformation function (lambda function)</h3>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:30:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112590224_-266095811","id":"20190424-152950_224184215","dateCreated":"2019-04-24T15:29:50+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26706","dateFinished":"2019-04-24T15:30:13+0200","dateStarted":"2019-04-24T15:30:13+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Anonymous transformation function\n//The '=>' Scala operator specifies one or more input parameters as well as the transformation function itself\nval anonySongRDD = songRDD.map(element => element.toUpperCase)\n\n//Display all transformed elements of the RDD\nanonySongRDD.collect.foreach(println)","user":"anonymous","dateUpdated":"2019-04-24T15:30:26+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112613392_-2118268888","id":"20190424-153013_218755475","dateCreated":"2019-04-24T15:30:13+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26841","dateFinished":"2019-04-24T15:30:26+0200","dateStarted":"2019-04-24T15:30:26+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n  ... 51 elided\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T15:30:37+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112626291_-542964524","id":"20190424-153026_926379215","dateCreated":"2019-04-24T15:30:26+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26930","dateFinished":"2019-04-24T15:30:37+0200","dateStarted":"2019-04-24T15:30:37+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\n# in python an anonymous function can be constructed using lambdas\nanonFunction = lambda x: str(x).upper()\nprint(*songRDD.map(anonFunction).collect(), sep='\\n')\n","user":"anonymous","dateUpdated":"2019-04-24T15:30:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556112637496_-926085763","id":"20190424-153037_1017658666","dateCreated":"2019-04-24T15:30:37+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:27028","dateFinished":"2019-04-24T15:30:44+0200","dateStarted":"2019-04-24T15:30:44+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'songRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'songRDD' is not defined\n\n"}]}}],"name":"/1. DataFrames, Datasets & RDDs/1.4 RDDs","id":"2E9F65M54","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}