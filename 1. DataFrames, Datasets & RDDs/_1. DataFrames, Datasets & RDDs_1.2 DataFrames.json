{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-15T09:14:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658787_-790185323","id":"20190424-142914_936966154","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11394"},{"title":"# 1.2 DataFrames","text":"%md\n# 1.2 DataFrames\n\n***1.2.1 DataFrames in general***\n\n***1.2.2 DataFrame example***\n\n***1.2.3 Schema inferencing***\n\n***1.2.4 Manually schema definition***\n\n***1.2.5 DataFrame API***\n\n* Column names, column expressions and column operations\n\n* Joining DataFrames\n\n* Aggregating and Grouping","user":"anonymous","dateUpdated":"2019-05-15T13:10:18+0000","config":{"lineNumbers":false,"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.2 DataFrames</h1>\n<p><strong><em>1.2.1 DataFrames in general</em></strong></p>\n<p><strong><em>1.2.2 DataFrame example</em></strong></p>\n<p><strong><em>1.2.3 Schema inferencing</em></strong></p>\n<p><strong><em>1.2.4 Manually schema definition</em></strong></p>\n<p><strong><em>1.2.5 DataFrame API</em></strong></p>\n<ul>\n  <li>\n  <p>Column names, column expressions and column operations</p></li>\n  <li>\n  <p>Joining DataFrames</p></li>\n  <li>\n  <p>Aggregating and Grouping</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658787_-790583323","id":"20190424-142950_1617538647","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11395","dateFinished":"2019-05-15T13:10:18+0000","dateStarted":"2019-05-15T13:10:18+0000"},{"text":"%md \n## 1.2.1 DataFrames in general\n\n*   **DataFrame API** - *Untyped* view on a Dataset - [Spark SQL Scaladoc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row])\n      * A DataFrame equals a [`Dataset[Row]`](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row])\n      \n      * DataFrames are the top-level implementation of RDDs with most built-in functionality\n      \n      * Most useful for structured data in tabular form\n      \n      * DataFrames represent an ordered collection of [`Row`](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row) objects\n      \n      * Rows are organized into columns described by a schema\n      \n      * DataFrames provide a column oriented API similar to SQL. SQL commands can be applied directly on DataFrames.","user":"anonymous","dateUpdated":"2019-05-15T09:42:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.1 DataFrames in general</h2>\n<ul>\n  <li><strong>DataFrame API</strong> - <em>Untyped</em> view on a Dataset - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\">Spark SQL Scaladoc</a>\n    <ul>\n      <li>\n      <p>A DataFrame equals a <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\"><code>Dataset[Row]</code></a></p></li>\n      <li>\n      <p>DataFrames are the top-level implementation of RDDs with most built-in functionality</p></li>\n      <li>\n      <p>Most useful for structured data in tabular form</p></li>\n      <li>\n      <p>DataFrames represent an ordered collection of <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row\"><code>Row</code></a> objects</p></li>\n      <li>\n      <p>Rows are organized into columns described by a schema</p></li>\n      <li>\n      <p>DataFrames provide a column oriented API similar to SQL. SQL commands can be applied directly on DataFrames.</p></li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658787_339028501","id":"20190424-142957_1563721771","dateCreated":"2019-05-15T09:14:18+0000","dateStarted":"2019-05-15T09:42:51+0000","dateFinished":"2019-05-15T09:42:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11396"},{"text":"%md\n## 1.2.2 DataFrame example","user":"anonymous","dateUpdated":"2019-05-15T09:14:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.2 DataFrame example</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658788_1171698388","id":"20190424-143010_1052351999","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11397"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n","user":"anonymous","dateUpdated":"2019-05-15T09:44:01+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658788_766103865","id":"20190430-164628_737632598","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11398","dateFinished":"2019-05-15T09:44:01+0000","dateStarted":"2019-05-15T09:44:01+0000"},{"text":"%spark\n// path of data source file\nval dataPath = \"s3a://cs-spark-basic-training/Songs/\"","user":"anonymous","dateUpdated":"2019-05-15T09:53:45+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dataPath: String = s3a://cs-spark-basic-training/Songs/\n"}]},"apps":[],"jobName":"paragraph_1557911658788_-881292442","id":"20190424-143021_1689717938","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11399","dateFinished":"2019-05-15T09:43:01+0000","dateStarted":"2019-05-15T09:43:01+0000"},{"text":"%spark\n// create DataFrame from file\nval songDF = spark.read.load(dataPath)","user":"anonymous","dateUpdated":"2019-05-15T09:43:03+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"songDF: org.apache.spark.sql.DataFrame = [artist: string, loudness: double]\n"}]},"apps":[],"jobName":"paragraph_1557911658789_-156752413","id":"20190424-143036_1016672624","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11400","dateFinished":"2019-05-15T09:43:13+0000","dateStarted":"2019-05-15T09:43:03+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}}},{"text":"%spark\n// show songDF\nsongDF.show()","user":"anonymous","dateUpdated":"2019-05-15T09:53:56+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1557911658789_-1603516001","id":"20190424-143715_222427483","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11402"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-15T09:45:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658789_-1168949797","id":"20190424-143755_678312751","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11403","dateFinished":"2019-05-15T09:45:03+0000","dateStarted":"2019-05-15T09:45:03+0000"},{"text":"%pyspark\n#  path of data source file\ndataPath = \"s3a://cs-spark-basic-training/Songs/\"\n","user":"anonymous","dateUpdated":"2019-05-15T09:55:58+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1557911658790_1118114711","id":"20190424-145333_1662160467","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11404","dateFinished":"2019-05-15T09:55:13+0000","dateStarted":"2019-05-15T09:55:13+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=31"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\n# create DataFrame from file\nsongDF = spark.read.load(dataPath)","user":"anonymous","dateUpdated":"2019-05-15T09:56:14+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1557914153728_151508516","id":"20190515-095553_919429170","dateCreated":"2019-05-15T09:55:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15378","dateFinished":"2019-05-15T09:56:15+0000","dateStarted":"2019-05-15T09:56:14+0000","results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=34"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\n# show songDF\nsongDF.show()","user":"anonymous","dateUpdated":"2019-05-15T09:56:28+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1557911658795_13623824","id":"20190424-145613_1381343186","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11405","dateFinished":"2019-05-15T09:56:29+0000","dateStarted":"2019-05-15T09:56:28+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=35","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=36"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 1.2.3 Schema inferencing\n\n- DataFrames provide table structures with a schema.\n\n- The schema gets inferred simultaneously at the DataFrame creation step.\n\n- Schema defines column names and data types.\n\n- Schema is immutable.\n\n- Schema inferencing is possbile for structured data and semi-structured data (at least possible to attempt).","user":"anonymous","dateUpdated":"2019-05-15T09:14:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.3 Schema inferencing</h2>\n<ul>\n  <li>\n  <p>DataFrames provide table structures with a schema.</p></li>\n  <li>\n  <p>The schema gets inferred simultaneously at the DataFrame creation step.</p></li>\n  <li>\n  <p>Schema defines column names and data types.</p></li>\n  <li>\n  <p>Schema is immutable.</p></li>\n  <li>\n  <p>Schema inferencing is possbile for structured data and semi-structured data (at least possible to attempt).</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658795_-1305867776","id":"20190424-145632_1953285619","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11406"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-15T09:45:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658795_889719707","id":"20190424-145645_117640830","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11407","dateFinished":"2019-05-15T09:45:53+0000","dateStarted":"2019-05-15T09:45:53+0000"},{"text":"%spark\n// dispaly Schema of songDF -> schema inferred at creation step\nsongDF.printSchema()","user":"anonymous","dateUpdated":"2019-05-15T09:45:55+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1557911658797_670704277","id":"20190424-145843_1903574220","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11408","dateFinished":"2019-05-15T09:45:55+0000","dateStarted":"2019-05-15T09:45:55+0000"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-15T09:46:02+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658798_1923318010","id":"20190424-145954_1572315035","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11409","dateFinished":"2019-05-15T09:46:02+0000","dateStarted":"2019-05-15T09:46:02+0000"},{"text":"%pyspark\n# dispaly Schema of songDF -> schema inferred at creation step\nsongDF.printSchema()","user":"anonymous","dateUpdated":"2019-05-15T09:56:44+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1557911658798_-230748982","id":"20190424-150029_1627223572","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11410","dateFinished":"2019-05-15T09:56:44+0000","dateStarted":"2019-05-15T09:56:44+0000"},{"text":"%md\n## 1.2.4 Manually schema definition\n\n- Can be used if schema inferecing isn´t correct or even impossible due to data type deviations.\n\n- `StructType` corresponds the schema which consists of a list of `StructField`.\n\n- `StructField` correspond the column names and data types.\n\n- Instead of manually defining a DataFrame schema you should consider to use a Dataset instead.","user":"anonymous","dateUpdated":"2019-05-15T09:14:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.4 Manually schema definition</h2>\n<ul>\n  <li>\n  <p>Can be used if schema inferecing isn´t correct or even impossible due to data type deviations.</p></li>\n  <li>\n  <p><code>StructType</code> corresponds the schema which consists of a list of <code>StructField</code>.</p></li>\n  <li>\n  <p><code>StructField</code> correspond the column names and data types.</p></li>\n  <li>\n  <p>Instead of manually defining a DataFrame schema you should consider to use a Dataset instead.</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658799_954377686","id":"20190424-150036_1754209787","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11411"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-15T09:46:09+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658799_1980701058","id":"20190424-150045_1062197240","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11412","dateFinished":"2019-05-15T09:46:09+0000","dateStarted":"2019-05-15T09:46:09+0000"},{"text":"%spark\nimport org.apache.spark.sql.types._ // to be able to use 'StructType' and 'StructField'\n\n// Schema definition\nval mySchema = StructType(List(\n                   StructField(\"artist\", StringType),\n                   StructField(\"loudness\", StringType)))     // We want to read in 'loudness' as data type String","user":"anonymous","dateUpdated":"2019-05-15T10:00:03+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.types._\nmySchema: org.apache.spark.sql.types.StructType = StructType(StructField(artist,StringType,true), StructField(loudness,StringType,true))\n"}]},"apps":[],"jobName":"paragraph_1557911658799_1475417047","id":"20190424-150100_2112087099","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11413","dateFinished":"2019-05-15T09:46:14+0000","dateStarted":"2019-05-15T09:46:13+0000"},{"text":"// Apply manually defined schema\nval songDfMySchema = spark.read.option(\"header\", true).schema(mySchema).csv(\"s3a://cs-spark-basic-training/SongDS/SongDS.csv\")\n\n// Column 'loudness' is now of type String\nsongDfMySchema.printSchema()\nsongDfMySchema.show(false)","user":"anonymous","dateUpdated":"2019-05-15T09:54:02+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: string (nullable = true)\n\n+------------+--------+\n|artist      |loudness|\n+------------+--------+\n|BeastieBoys |-5.0    |\n|FrankSinatra|-10.0   |\n|Muse        |-7.0    |\n+------------+--------+\n\nsongDfMySchema: org.apache.spark.sql.DataFrame = [artist: string, loudness: string]\n"}]},"apps":[],"jobName":"paragraph_1557911658800_-1164054561","id":"20190424-150107_810537491","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11414","dateFinished":"2019-05-15T09:50:43+0000","dateStarted":"2019-05-15T09:50:33+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=10"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-15T09:50:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658800_-677151900","id":"20190424-150129_1213909991","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11415","dateFinished":"2019-05-15T09:50:53+0000","dateStarted":"2019-05-15T09:50:53+0000"},{"text":"%pyspark\nfrom pyspark.sql.types import *          # to be able to use 'StructType' and 'StructField'\n\n# Schema definition\nmySchema = StructType([\n                        StructField('artist', StringType()),\n                        StructField('loudness', StringType())           # We want to read in 'loudness' as data type String\n])","user":"anonymous","dateUpdated":"2019-05-15T10:00:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1557914339994_761548669","id":"20190515-095859_1421698042","dateCreated":"2019-05-15T09:58:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15531","dateFinished":"2019-05-15T10:00:36+0000","dateStarted":"2019-05-15T10:00:36+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\n# Apply manually defined schema\nsongDFMySchema = spark.read.csv('s3a://cs-spark-basic-training/SongDS/SongDS.csv', header = True, schema = mySchema)\n\n# Column 'loudness' is now of type String\nsongDFMySchema.printSchema()\nsongDFMySchema.show()","user":"anonymous","dateUpdated":"2019-05-15T10:01:10+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- artist: string (nullable = true)\n |-- loudness: string (nullable = true)\n\n+------------+--------+\n|      artist|loudness|\n+------------+--------+\n| BeastieBoys|    -5.0|\n|FrankSinatra|   -10.0|\n|        Muse|    -7.0|\n+------------+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1557911658801_-1974499085","id":"20190424-150141_718914286","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11416","dateFinished":"2019-05-15T10:01:21+0000","dateStarted":"2019-05-15T10:01:10+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=38"],"interpreterSettingId":"spark"}}},{"text":"%md \n## 1.2.5 Use Dataframe API","user":"anonymous","dateUpdated":"2019-05-15T09:14:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.5 Use Dataframe API</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658801_-984573124","id":"20190424-150148_1348322792","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11417"},{"text":"%md\n### Column names, column references and column expressions\n\n* ***Column names*** are string types (e.g. `df.select(\"columnName\")`) and are often used inside Transformations.\n\n* Transformations can refer to ***column references*** or ***column expressions*** instead of ***column names***.\n\n* ***Column references*** refer to columns by using the column name in combination with the DataFrame itself (e.g. `df(\"columnName\")`)\n***OR*** - in case of Scala - by using the short hand `$` without the DataFrame (e.g. `$\"columnName\"`).\n\n* ***Column expressions*** can be created by applying operators or functions to ***column references*** (e.g. `$\"columnName\" * 10`).\n\n* ***Column expressions*** can´t be created by applying operators or functions to ***column names***.\n\n\n* All available column operations and functions can be found in the [Column Class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column).","user":"anonymous","dateUpdated":"2019-05-15T13:33:09+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1557925563607_-204723178","id":"20190515-130603_2045495731","dateCreated":"2019-05-15T13:06:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16133","dateFinished":"2019-05-15T13:33:09+0000","dateStarted":"2019-05-15T13:33:09+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Column names, column references and column expressions</h3>\n<ul>\n  <li>\n  <p><strong><em>Column names</em></strong> are string types (e.g. <code>df.select(&quot;columnName&quot;)</code>) and are often used inside Transformations.</p></li>\n  <li>\n  <p>Transformations can refer to <strong><em>column references</em></strong> or <strong><em>column expressions</em></strong> instead of <strong><em>column names</em></strong>.</p></li>\n  <li>\n  <p><strong><em>Column references</em></strong> refer to columns by using the column name in combination with the DataFrame itself (e.g. <code>df(&quot;columnName&quot;)</code>)<br/><strong><em>OR</em></strong> - in case of Scala - by using the short hand <code>$</code> without the DataFrame (e.g. <code>$&quot;columnName&quot;</code>).</p></li>\n  <li>\n  <p><strong><em>Column expressions</em></strong> can be created by applying operators or functions to <strong><em>column references</em></strong> (e.g. <code>$&quot;columnName&quot; * 10</code>).</p></li>\n  <li>\n  <p><strong><em>Column expressions</em></strong> can´t be created by applying operators or functions to <strong><em>column names</em></strong>.</p></li>\n  <li>\n  <p>All available column operations and functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column\">Column Class</a>.</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-15T09:51:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658802_-1653692397","id":"20190424-150206_1748105933","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11419","dateFinished":"2019-05-15T09:51:16+0000","dateStarted":"2019-05-15T09:51:16+0000"},{"text":"%spark\n// Column names\nsongDF.select(\"artist\", \"loudness\")                    // selecting columns by simply stating their names as strings      \n      .show()\n\n// Column references\nsongDF.select(songDF(\"artist\"), $\"loudness\")           // selecting columns by using the full column reference and by using the Scala short hand '$' for column references\n      .show()\n\n// Column expressions (based on column references)\nsongDF.select($\"artist\", $\"loudness\" * 10)             // creating a column expression out of a column reference\n      .show()\n                      \n// Column expressions (based on column names) -> leads to an exception!\nsongDF.select(\"artist\", \"loudness\" * 10)               // creating column expressions out of column names is not possible\n      .show()","user":"anonymous","dateUpdated":"2019-05-15T13:45:23+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{"0":{"graph":{"mode":"table","height":1604,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+---------------+\n|       artist|(loudness * 10)|\n+-------------+---------------+\n|Frank Sinatra|         -100.0|\n| Beastie Boys|          -50.0|\n|         Muse|          -70.0|\n+-------------+---------------+\n\norg.apache.spark.sql.AnalysisException: cannot resolve '`loudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudness`' given input columns: [artist, loudness];;\n'Project [artist#11, 'loudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudness]\n+- Relation[artist#11,loudness#12] parquet\n\n  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n  at scala.collection.AbstractTraversable.map(Traversable.scala:104)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3407)\n  at org.apache.spark.sql.Dataset.select(Dataset.scala:1335)\n  at org.apache.spark.sql.Dataset.select(Dataset.scala:1353)\n  ... 49 elided\n"}]},"apps":[],"jobName":"paragraph_1557911658803_1435980949","id":"20190424-150219_1073153304","dateCreated":"2019-05-15T09:14:18+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11420","dateFinished":"2019-05-15T13:45:36+0000","dateStarted":"2019-05-15T13:45:23+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=97","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=98","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=99","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=100","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=101","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=102"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-15T09:51:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658803_831767257","id":"20190424-150232_6248463","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11421","dateFinished":"2019-05-15T09:51:24+0000","dateStarted":"2019-05-15T09:51:24+0000"},{"text":"%pyspark\n# Column names\nsongDF.select(\"artist\", \"loudness\").show()                        # selecting columns by simply stating their names as strings\n\n# Column references     \nsongDF.select(songDF[\"artist\"], songDF.loudness).show()           # selecting columns by using two different ways of Python column references which are equivalent\n      \n# Column expressions based on column references\nsongDF.select(songDF.artist, songDF.loudness * 10).show()         # creating a column expression out of a column reference\n      \n# Column expressions based on column names -> lead to an exception!\nsongDF.select(\"artist\", \"loudness\" * 10).show()                   # creating column expressions out of column names is not possible","user":"anonymous","dateUpdated":"2019-05-15T14:01:52+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":494,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+---------------+\n|       artist|(loudness * 10)|\n+-------------+---------------+\n|Frank Sinatra|         -100.0|\n| Beastie Boys|          -50.0|\n|         Muse|          -70.0|\n+-------------+---------------+\n\n"},{"type":"TEXT","data":"Fail to execute line 11: songDF.select(\"artist\", \"loudness\" * 10).show()                   # creating column expressions out of column names is not possible\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-6702533554108065785.py\", line 380, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 11, in <module>\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 1320, in select\n    jdf = self._jdf.select(self._jcols(*cols))\n  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\nAnalysisException: u\"cannot resolve '`loudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudness`' given input columns: [artist, loudness];;\\n'Project [artist#183, 'loudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudnessloudness]\\n+- Relation[artist#183,loudness#184] parquet\\n\"\n"}]},"apps":[],"jobName":"paragraph_1557911658803_512199650","id":"20190424-150246_1263602230","dateCreated":"2019-05-15T09:14:18+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11422","dateFinished":"2019-05-15T14:01:40+0000","dateStarted":"2019-05-15T14:01:38+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=133","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=134","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=135","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=136","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=137","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=138"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Joining DataFrames\n\n***Available join types:***\n\n * inner\n \n * cross\n \n * outer\n \n * full\n \n * full_outer\n \n * left\n \n * left_outer\n \n * right\n \n * right_outer\n \n * left_semi\n \n * left_anti","user":"anonymous","dateUpdated":"2019-05-15T09:14:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Joining DataFrames</h3>\n<p><strong><em>Available join types:</em></strong></p>\n<ul>\n  <li>\n  <p>inner</p></li>\n  <li>\n  <p>cross</p></li>\n  <li>\n  <p>outer</p></li>\n  <li>\n  <p>full</p></li>\n  <li>\n  <p>full_outer</p></li>\n  <li>\n  <p>left</p></li>\n  <li>\n  <p>left_outer</p></li>\n  <li>\n  <p>right</p></li>\n  <li>\n  <p>right_outer</p></li>\n  <li>\n  <p>left_semi</p></li>\n  <li>\n  <p>left_anti</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658804_813611456","id":"20190424-150252_2037953031","dateCreated":"2019-05-15T09:14:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11423"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-15T09:51:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658804_1921272796","id":"20190424-150300_492544382","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11424","dateFinished":"2019-05-15T09:51:33+0000","dateStarted":"2019-05-15T09:51:33+0000"},{"text":"%spark\n// The first DataFrame is the already known 'songDF'\nsongDF.show()\n\n// Create second DataFrame out of in-memory data\nval listenersDF = spark.createDataFrame(Seq((\"Muse\", 4571),(\"Frank Sinatra\", 1658),(\"Beastie Boys\", 2483)))\n                        .withColumnRenamed(\"_1\", \"band\")\n                        .withColumnRenamed(\"_2\", \"listeners\")\n\nlistenersDF.show(false)\n\n// Join songDF with listenersDF\nval joinDF = songDF.join(listenersDF, songDF(\"artist\") === listenersDF(\"band\"), \"inner\")\n\njoinDF.show(false)","user":"anonymous","dateUpdated":"2019-05-15T14:04:23+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{"0":{"graph":{"mode":"table","height":1244,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+---------+\n|band         |listeners|\n+-------------+---------+\n|Muse         |4571     |\n|Frank Sinatra|1658     |\n|Beastie Boys |2483     |\n+-------------+---------+\n\n+-------------+--------+-------------+---------+\n|artist       |loudness|band         |listeners|\n+-------------+--------+-------------+---------+\n|Frank Sinatra|-10.0   |Frank Sinatra|1658     |\n|Beastie Boys |-5.0    |Beastie Boys |2483     |\n|Muse         |-7.0    |Muse         |4571     |\n+-------------+--------+-------------+---------+\n\nlistenersDF: org.apache.spark.sql.DataFrame = [band: string, listeners: int]\njoinDF: org.apache.spark.sql.DataFrame = [artist: string, loudness: double ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1557911658804_-1795793300","id":"20190424-150314_836071349","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11425","dateFinished":"2019-05-15T14:04:25+0000","dateStarted":"2019-05-15T14:04:23+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=145","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=146","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=147","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=148","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=149"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-15T09:51:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658805_-1293950753","id":"20190424-150320_1138574063","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11426","dateFinished":"2019-05-15T09:51:50+0000","dateStarted":"2019-05-15T09:51:50+0000"},{"text":"%pyspark\n# The first DataFrame is the already known 'songDF'\nsongDF.show()\n\n# Create second DataFrame out of in-memory data\nlistenersDF = spark.createDataFrame([[\"Muse\", 4571], [\"Frank Sinatra\", 1658], [\"Beastie Boys\", 2483]]).withColumnRenamed(\"_1\", \"band\").withColumnRenamed(\"_2\", \"loudness\")\n\nlistenersDF.show()\n\n# Join songDF with listenersDF\njoinDF = songDF.join(listenersDF, songDF[\"artist\"] == listenersDF[\"band\"], \"inner\")\n\njoinDF.show()","user":"anonymous","dateUpdated":"2019-05-15T14:12:51+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":378,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+--------+\n|       artist|loudness|\n+-------------+--------+\n|Frank Sinatra|   -10.0|\n| Beastie Boys|    -5.0|\n|         Muse|    -7.0|\n+-------------+--------+\n\n+-------------+--------+\n|         band|loudness|\n+-------------+--------+\n|         Muse|    4571|\n|Frank Sinatra|    1658|\n| Beastie Boys|    2483|\n+-------------+--------+\n\n+-------------+--------+-------------+--------+\n|       artist|loudness|         band|loudness|\n+-------------+--------+-------------+--------+\n|         Muse|    -7.0|         Muse|    4571|\n|Frank Sinatra|   -10.0|Frank Sinatra|    1658|\n| Beastie Boys|    -5.0| Beastie Boys|    2483|\n+-------------+--------+-------------+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1557911658806_-305832805","id":"20190424-150346_1258259699","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11427","dateFinished":"2019-05-15T14:11:17+0000","dateStarted":"2019-05-15T14:11:03+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=155","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=156","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=157","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=158","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=159","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=160","http://ip-172-31-45-220.eu-central-1.compute.internal:4040/jobs/job?id=161"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Aggregating and grouping\n\n* DataFrames can be grouped (`groupBy`, `groupByKey`) in a SQL-like fashion. Grouping functions can be found in the [Dataset API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n* DataFrames can be aggregated as well. Aggregation functions can be found in the [built-in DataFrame functions](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$).\n\n* Examples for aggregation functions:\n    - count\n    - sum\n    - first\n    - max\n    - avg\n \n* For Py-Spark: [API Docs](https://spark.apache.org/docs/latest/api/python/index.html).","user":"anonymous","dateUpdated":"2019-05-15T14:12:32+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Aggregating and grouping</h3>\n<ul>\n  <li>\n  <p>DataFrames can be grouped (<code>groupBy</code>, <code>groupByKey</code>) in a SQL-like fashion. Grouping functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset API</a>.</p></li>\n  <li>\n  <p>DataFrames can be aggregated as well. Aggregation functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\">built-in DataFrame functions</a>.</p></li>\n  <li>\n    <p>Examples for aggregation functions:</p>\n    <ul>\n      <li>count</li>\n      <li>sum</li>\n      <li>first</li>\n      <li>max</li>\n      <li>avg</li>\n    </ul>\n  </li>\n  <li>\n  <p>For Py-Spark: <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\">API Docs</a>.</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1557911658807_1419733456","id":"20190424-150352_1471422808","dateCreated":"2019-05-15T09:14:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11428","dateFinished":"2019-05-15T14:12:32+0000","dateStarted":"2019-05-15T14:12:32+0000"}],"name":"/1. DataFrames, Datasets & RDDs/1.2 DataFrames","id":"2EAWDHP39","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}