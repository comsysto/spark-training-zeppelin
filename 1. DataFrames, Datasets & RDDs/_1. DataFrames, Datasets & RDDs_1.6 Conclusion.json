{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-17T16:03:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558108990320_557986705","id":"20190424-163717_1121679874","dateCreated":"2019-05-17T16:03:10+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:34438"},{"text":"%md\n# 1.6 Conclusion","user":"anonymous","dateUpdated":"2019-05-17T16:03:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.6 Conclusion</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1558108990321_-1807866206","id":"20190424-163724_1544939763","dateCreated":"2019-05-17T16:03:10+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:34439"},{"text":"%md\n## RDDs\nRDDs remain the core component for the native distributed collections.\nBut due to lack of built-in optimization, DFs and DSs should be prefered. \n\n\n## DataFrames\n**DataFrames** and **Spark SQL** are very flexible and bring built-in optimization also for dynamic languages like Python and R. Beside this, it allows to combine both *declarative* and *functional* way of working with structured data.\nIt's regarded to be most stable and flexible API.\n\n<img src='https://databricks.com/wp-content/uploads/2015/02/Screen-Shot-2015-02-16-at-9.46.39-AM-1024x457.png' style='width:600px'>\n\n\n## Datasets\n**Datasets** unify the best from both worlds: **type safety** from **RDDs** and **built-in optimization** available for **DataFrames**. DSs allow even further optimizations (memory compaction + faster serialization using encoders).\n\nHere some benchmarks of DataSets:\n\n<img src='https://databricks.com/wp-content/uploads/2016/01/Distributed-Wordcount-Chart-1024x371.png' style='width:600px'>\n<img src='https://databricks.com/wp-content/uploads/2016/01/Memory-Usage-when-Caching-Chart-1024x359.png?noresize' style='width:600px'>\n\n","user":"anonymous","dateUpdated":"2019-05-17T16:03:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>RDDs</h2>\n<p>RDDs remain the core component for the native distributed collections.<br/>But due to lack of built-in optimization, DFs and DSs should be prefered. </p>\n<h2>DataFrames</h2>\n<p><strong>DataFrames</strong> and <strong>Spark SQL</strong> are very flexible and bring built-in optimization also for dynamic languages like Python and R. Beside this, it allows to combine both <em>declarative</em> and <em>functional</em> way of working with structured data.<br/>It&rsquo;s regarded to be most stable and flexible API.</p>\n<img src='https://databricks.com/wp-content/uploads/2015/02/Screen-Shot-2015-02-16-at-9.46.39-AM-1024x457.png' style='width:600px'>\n<h2>Datasets</h2>\n<p><strong>Datasets</strong> unify the best from both worlds: <strong>type safety</strong> from <strong>RDDs</strong> and <strong>built-in optimization</strong> available for <strong>DataFrames</strong>. DSs allow even further optimizations (memory compaction + faster serialization using encoders).</p>\n<p>Here some benchmarks of DataSets:</p>\n<img src='https://databricks.com/wp-content/uploads/2016/01/Distributed-Wordcount-Chart-1024x371.png' style='width:600px'>\n<img src='https://databricks.com/wp-content/uploads/2016/01/Memory-Usage-when-Caching-Chart-1024x359.png?noresize' style='width:600px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558108990321_-2111045429","id":"20190424-163730_696337015","dateCreated":"2019-05-17T16:03:10+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:34440"}],"name":"/1. DataFrames, Datasets & RDDs/1.6 Conclusion","id":"2ECYWM3U1","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}