{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-04-24T14:29:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1556108954127_-1146026161","id":"20190424-142914_936966154","dateCreated":"2019-04-24T14:29:14+0200","dateStarted":"2019-04-24T14:29:45+0200","dateFinished":"2019-04-24T14:29:45+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12613"},{"text":"%md\n# 1.2 DataFrames","user":"anonymous","dateUpdated":"2019-04-24T14:34:28+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>1.2 DataFrames</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1556108985202_-72256258","id":"20190424-142945_2103570325","dateCreated":"2019-04-24T14:29:45+0200","dateStarted":"2019-04-24T14:34:28+0200","dateFinished":"2019-04-24T14:34:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12614"},{"title":"# 1.2 DataFrames","text":"%md\n***1.2.1 DataFrames in general***\n\n***1.2.2 DataFrame example***\n\n***1.2.3 Schema inferencing***\n\n***1.2.4 Manually schema definition***\n\n***1.2.5 DataFrame API***\n\n* Column names, column expressions and column operations\n\n* Joining DataFrames\n\n* Aggregating and Grouping","user":"anonymous","dateUpdated":"2019-04-24T14:34:26+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":false,"lineNumbers":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>1.2.1 DataFrames in general</em></strong></p>\n<p><strong><em>1.2.2 DataFrame example</em></strong></p>\n<p><strong><em>1.2.3 Schema inferencing</em></strong></p>\n<p><strong><em>1.2.4 Manually schema definition</em></strong></p>\n<p><strong><em>1.2.5 DataFrame API</em></strong></p>\n<ul>\n  <li>\n  <p>Column names, column expressions and column operations</p></li>\n  <li>\n  <p>Joining DataFrames</p></li>\n  <li>\n  <p>Aggregating and Grouping</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1556108990929_1740214163","id":"20190424-142950_1617538647","dateCreated":"2019-04-24T14:29:50+0200","dateStarted":"2019-04-24T14:34:26+0200","dateFinished":"2019-04-24T14:34:26+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12615"},{"text":"%md \n## 1.2.1 DataFrames in general\n\n*   **DataFrame API** - *Untyped* view on a Dataset \n      * A DataFrame equals a `Dataset[Row]` - [Dataframe definition](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row])\n      \n      * DataFrames are the top-level implementation of RDDs with most built-in functionality\n      \n      * Most useful for structured data in tabular form\n      \n      * DataFrames represent an ordered collection of `Row` objects\n      \n      * Rows are organized into columns described by a schema\n      \n      * DataFrames provide a column oriented API similar to SQL. SQL commands can be applied directly on DataFrames.","user":"anonymous","dateUpdated":"2019-04-24T14:30:10+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.1 DataFrames in general</h2>\n<ul>\n  <li><strong>DataFrame API</strong> - <em>Untyped</em> view on a Dataset\n    <ul>\n      <li>\n      <p>A DataFrame equals a <code>Dataset[Row]</code> - <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.package@DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\">Dataframe definition</a></p></li>\n      <li>\n      <p>DataFrames are the top-level implementation of RDDs with most built-in functionality</p></li>\n      <li>\n      <p>Most useful for structured data in tabular form</p></li>\n      <li>\n      <p>DataFrames represent an ordered collection of <code>Row</code> objects</p></li>\n      <li>\n      <p>Rows are organized into columns described by a schema</p></li>\n      <li>\n      <p>DataFrames provide a column oriented API similar to SQL. SQL commands can be applied directly on DataFrames.</p></li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1556108997362_994916323","id":"20190424-142957_1563721771","dateCreated":"2019-04-24T14:29:57+0200","dateStarted":"2019-04-24T14:30:10+0200","dateFinished":"2019-04-24T14:30:10+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12616"},{"text":"%md\n## 1.2.2 DataFrame example","user":"anonymous","dateUpdated":"2019-04-24T14:44:04+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.2 DataFrame example</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1556109010170_-238272174","id":"20190424-143010_1052351999","dateCreated":"2019-04-24T14:30:10+0200","dateStarted":"2019-04-24T14:44:04+0200","dateFinished":"2019-04-24T14:44:04+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12617"},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T14:58:53+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556109567394_-2132583848","id":"20190424-143927_574681169","dateCreated":"2019-04-24T14:39:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12618","dateFinished":"2019-04-24T14:58:53+0200","dateStarted":"2019-04-24T14:58:53+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"//path of data source file\nval dataPath = \"dbfs:/cs-spark-training/Songs/\"","user":"anonymous","dateUpdated":"2019-04-24T14:38:53+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false,"lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dataPath: String = dbfs:/cs-spark-training/Songs/\n"}]},"apps":[],"jobName":"paragraph_1556109021698_-1006592355","id":"20190424-143021_1689717938","dateCreated":"2019-04-24T14:30:21+0200","dateStarted":"2019-04-24T14:30:36+0200","dateFinished":"2019-04-24T14:30:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12619"},{"text":"// create DataFrame from file\nval songDF = spark.read.load(dataPath)","user":"anonymous","dateUpdated":"2019-04-24T14:38:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 47 elided\n"}]},"apps":[],"jobName":"paragraph_1556109036250_-1724895758","id":"20190424-143036_1016672624","dateCreated":"2019-04-24T14:30:36+0200","dateStarted":"2019-04-24T14:37:15+0200","dateFinished":"2019-04-24T14:37:16+0200","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:12620"},{"text":"//show songDF\nsongDF.show()","user":"anonymous","dateUpdated":"2019-04-24T14:39:05+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:25: error: not found: value songDF\n       songDF.show()\n       ^\n"}]},"apps":[],"jobName":"paragraph_1556109435427_-1717224189","id":"20190424-143715_222427483","dateCreated":"2019-04-24T14:37:15+0200","dateStarted":"2019-04-24T14:37:55+0200","dateFinished":"2019-04-24T14:37:55+0200","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:12621"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556109475491_-1377767414","id":"20190424-143755_678312751","dateCreated":"2019-04-24T14:37:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:12622","text":"%md\n<b><font color='blue'size=5>Python</font>\n\n","dateUpdated":"2019-04-24T15:00:24+0200","dateFinished":"2019-04-24T15:00:24+0200","dateStarted":"2019-04-24T15:00:24+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\ndataPath = r'dbfs:/cs-spark-training/Songs/'\nsongDF = spark.read.load(dataPath)","user":"anonymous","dateUpdated":"2019-04-24T14:56:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110413222_1123611655","id":"20190424-145333_1662160467","dateCreated":"2019-04-24T14:53:33+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14179","dateFinished":"2019-04-24T14:56:17+0200","dateStarted":"2019-04-24T14:56:13+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'spark' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'spark' is not defined\n\n"}]}},{"text":"%python\nsongDF.show()","user":"anonymous","dateUpdated":"2019-04-24T14:56:32+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110573103_-470152783","id":"20190424-145613_1381343186","dateCreated":"2019-04-24T14:56:13+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14638","dateFinished":"2019-04-24T14:56:32+0200","dateStarted":"2019-04-24T14:56:32+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\n"}]}},{"text":"%md\n## 1.2.3 Schema inferencing\n\n- DataFrames provide table structures with a schema.\n\n- The schema gets inferred simultaneously at the DataFrame creation step.\n\n- Schema defines column names and data types.\n\n- Schema is immutable.\n\n- Schema inferencing is possbile for structured data and semi-structured data (at least possible to attempt).","user":"anonymous","dateUpdated":"2019-04-24T14:56:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110592528_849785417","id":"20190424-145632_1953285619","dateCreated":"2019-04-24T14:56:32+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14735","dateFinished":"2019-04-24T14:56:45+0200","dateStarted":"2019-04-24T14:56:45+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.3 Schema inferencing</h2>\n<ul>\n  <li>\n  <p>DataFrames provide table structures with a schema.</p></li>\n  <li>\n  <p>The schema gets inferred simultaneously at the DataFrame creation step.</p></li>\n  <li>\n  <p>Schema defines column names and data types.</p></li>\n  <li>\n  <p>Schema is immutable.</p></li>\n  <li>\n  <p>Schema inferencing is possbile for structured data and semi-structured data (at least possible to attempt).</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:00:55+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110605439_-1945855997","id":"20190424-145645_117640830","dateCreated":"2019-04-24T14:56:45+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14824","dateFinished":"2019-04-24T15:00:55+0200","dateStarted":"2019-04-24T15:00:55+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n// dispaly Schema of songDF -> schema inferred at creation step\nsongDF.printSchema()","user":"anonymous","dateUpdated":"2019-04-24T15:00:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110723492_-1732776242","id":"20190424-145843_1903574220","dateCreated":"2019-04-24T14:58:43+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14913","dateFinished":"2019-04-24T15:00:09+0200","dateStarted":"2019-04-24T15:00:09+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:25: error: not found: value songDF\n       songDF.printSchema()\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110794472_-1398222511","id":"20190424-145954_1572315035","dateCreated":"2019-04-24T14:59:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15026","text":"%md\n<b><font color='blue'size=5>Python</font>\n\n","dateUpdated":"2019-04-24T15:01:36+0200","dateFinished":"2019-04-24T15:00:29+0200","dateStarted":"2019-04-24T15:00:29+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nsongDF.printSchema()","user":"anonymous","dateUpdated":"2019-04-24T15:00:36+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110829920_-38689769","id":"20190424-150029_1627223572","dateCreated":"2019-04-24T15:00:29+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15191","dateFinished":"2019-04-24T15:00:36+0200","dateStarted":"2019-04-24T15:00:36+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\n"}]}},{"text":"%md\n## 1.2.4 Manually schema definition\n\n- Can be used if schema inferecing isn´t correct or even impossible due to data type deviations.\n\n- `StructType` corresponds the schema which consists of a list of `StructField`.\n\n- `StructField` correspond the column names and data types.\n\n- Instead of manually defining a DataFrame schema you should consider to use a Dataset instead.","user":"anonymous","dateUpdated":"2019-04-24T15:00:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110836680_1404380456","id":"20190424-150036_1754209787","dateCreated":"2019-04-24T15:00:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15280","dateFinished":"2019-04-24T15:00:45+0200","dateStarted":"2019-04-24T15:00:45+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.4 Manually schema definition</h2>\n<ul>\n  <li>\n  <p>Can be used if schema inferecing isn´t correct or even impossible due to data type deviations.</p></li>\n  <li>\n  <p><code>StructType</code> corresponds the schema which consists of a list of <code>StructField</code>.</p></li>\n  <li>\n  <p><code>StructField</code> correspond the column names and data types.</p></li>\n  <li>\n  <p>Instead of manually defining a DataFrame schema you should consider to use a Dataset instead.</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:02:14+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110845848_-2111697458","id":"20190424-150045_1062197240","dateCreated":"2019-04-24T15:00:45+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15369","dateFinished":"2019-04-24T15:02:14+0200","dateStarted":"2019-04-24T15:02:14+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nimport org.apache.spark.sql.types._\n\n//Schema definition\nval mySchema = StructType(List(\n                   StructField(\"artist\", StringType),\n                   StructField(\"loudness\", StringType)))     //We want to read in 'loudness' as data type String","user":"anonymous","dateUpdated":"2019-04-24T15:01:17+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110860736_1908934291","id":"20190424-150100_2112087099","dateCreated":"2019-04-24T15:01:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15482","dateFinished":"2019-04-24T15:01:17+0200","dateStarted":"2019-04-24T15:01:17+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.types._\nmySchema: org.apache.spark.sql.types.StructType = StructType(StructField(artist,StringType,true), StructField(loudness,StringType,true))\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110867105_-1226116665","id":"20190424-150107_810537491","dateCreated":"2019-04-24T15:01:07+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15572","text":"//Apply manually defined schema\nval songDfMySchema = spark.read.option(\"header\", true).schema(mySchema).csv(\"dbfs:/cs-spark-training/SongDS/SongDS.csv\")\n\n//Column 'loudness' is now of type String\nsongDfMySchema.printSchema()\nsongDfMySchema.show(false)","dateUpdated":"2019-04-24T15:01:29+0200","dateFinished":"2019-04-24T15:01:30+0200","dateStarted":"2019-04-24T15:01:29+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:412)\n  ... 51 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110889905_-976693881","id":"20190424-150129_1213909991","dateCreated":"2019-04-24T15:01:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15712","text":"%md\n<b><font color='blue'size=5>Python</font>\n\n","dateUpdated":"2019-04-24T15:02:40+0200","dateFinished":"2019-04-24T15:01:41+0200","dateStarted":"2019-04-24T15:01:41+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nfrom pyspark.sql.types import *\n\nmySchema = StructType([\n  StructField('artist', StringType()),\n  StructField('loudness', StringType())\n])\n\nsongDFMySchema = spark.read.csv('dbfs:/cs-spark-training/SongDS/SongDS.csv', header = True, schema = mySchema)\n\nsongDFMySchema.printSchema()\nsongDFMySchema.show()","user":"anonymous","dateUpdated":"2019-04-24T15:01:48+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110901480_-1103581980","id":"20190424-150141_718914286","dateCreated":"2019-04-24T15:01:41+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15816","dateFinished":"2019-04-24T15:01:48+0200","dateStarted":"2019-04-24T15:01:48+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nModuleNotFoundError: No module named 'pyspark'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nModuleNotFoundError: No module named 'pyspark'\n\n"}]}},{"text":"%md \n## 1.2.5 Use Dataframe API","user":"anonymous","dateUpdated":"2019-04-24T15:02:00+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110908065_-634482516","id":"20190424-150148_1348322792","dateCreated":"2019-04-24T15:01:48+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15905","dateFinished":"2019-04-24T15:02:00+0200","dateStarted":"2019-04-24T15:02:00+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>1.2.5 Use Dataframe API</h2>\n</div>"}]}},{"text":"%md\n### Column names, column expressions and column operations\n\n* DataFrame transformations can refer to column names and/or column expressions.\n\n* Column names are string types.\n\n* Column expressions are column names starting with a `$` as prefix and of type `Column`.\n\n* All available column operations can be found in the [API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column)","user":"anonymous","dateUpdated":"2019-04-24T15:02:06+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110920177_1380413403","id":"20190424-150200_1140982921","dateCreated":"2019-04-24T15:02:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15994","dateFinished":"2019-04-24T15:02:06+0200","dateStarted":"2019-04-24T15:02:06+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Column names, column expressions and column operations</h3>\n<ul>\n  <li>\n  <p>DataFrame transformations can refer to column names and/or column expressions.</p></li>\n  <li>\n  <p>Column names are string types.</p></li>\n  <li>\n  <p>Column expressions are column names starting with a <code>$</code> as prefix and of type <code>Column</code>.</p></li>\n  <li>\n  <p>All available column operations can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column\">API</a></p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:03:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110926289_-735739186","id":"20190424-150206_1748105933","dateCreated":"2019-04-24T15:02:06+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16084","dateFinished":"2019-04-24T15:03:09+0200","dateStarted":"2019-04-24T15:03:09+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Column names\nval songDfColNames = songDF\n                      .filter(\"loudness > -8.0\")\n                      .select(\"artist\")             \n                      .show()\n\n//Column expressions\nval songDfColExp = songDF\n                      .filter($\"loudness\" > -8.0)\n                      .select($\"artist\")\n                      .show()","user":"anonymous","dateUpdated":"2019-04-24T15:02:32+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110939993_-1584629814","id":"20190424-150219_1073153304","dateCreated":"2019-04-24T15:02:19+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16197","dateFinished":"2019-04-24T15:02:32+0200","dateStarted":"2019-04-24T15:02:32+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songDF\n       val songDfColNames = songDF\n                            ^\n<console>:36: error: not found: value songDF\n       val songDfColExp = songDF\n                          ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>\n\n","user":"anonymous","dateUpdated":"2019-04-24T15:03:42+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110952729_-504372955","id":"20190424-150232_6248463","dateCreated":"2019-04-24T15:02:32+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16286","dateFinished":"2019-04-24T15:03:42+0200","dateStarted":"2019-04-24T15:03:42+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\n# several ways...\nsongDF.filter('loudness > -8.0').select('artist').show()\nsongDF.filter(songDF.loudness > -8.0).select(songDF.artist).show()","user":"anonymous","dateUpdated":"2019-04-24T15:02:52+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110966129_-1949411162","id":"20190424-150246_1263602230","dateCreated":"2019-04-24T15:02:46+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16381","dateFinished":"2019-04-24T15:02:52+0200","dateStarted":"2019-04-24T15:02:52+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\n"}]}},{"text":"%md\n### Joining DataFrames\n\n***Available join types:***\n\n * inner\n \n * cross\n \n * outer\n \n * full\n \n * full_outer\n \n * left\n \n * left_outer\n \n * right\n \n * right_outer\n \n * left_semi\n \n * left_anti","user":"anonymous","dateUpdated":"2019-04-24T15:03:00+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110972217_-143097164","id":"20190424-150252_2037953031","dateCreated":"2019-04-24T15:02:52+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16470","dateFinished":"2019-04-24T15:03:00+0200","dateStarted":"2019-04-24T15:03:00+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Joining DataFrames</h3>\n<p><strong><em>Available join types:</em></strong></p>\n<ul>\n  <li>\n  <p>inner</p></li>\n  <li>\n  <p>cross</p></li>\n  <li>\n  <p>outer</p></li>\n  <li>\n  <p>full</p></li>\n  <li>\n  <p>full_outer</p></li>\n  <li>\n  <p>left</p></li>\n  <li>\n  <p>left_outer</p></li>\n  <li>\n  <p>right</p></li>\n  <li>\n  <p>right_outer</p></li>\n  <li>\n  <p>left_semi</p></li>\n  <li>\n  <p>left_anti</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T15:03:14+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110980201_-1891266245","id":"20190424-150300_492544382","dateCreated":"2019-04-24T15:03:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16559","dateFinished":"2019-04-24T15:03:14+0200","dateStarted":"2019-04-24T15:03:14+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Create second DataFrame out of in-memory data\nval listenersDF = spark.createDataFrame(Seq((\"Muse\", 4571),(\"Frank Sinatra\", 1658),(\"Beastie Boys\", 2483)))\n                        .withColumnRenamed(\"_1\", \"band\")\n                        .withColumnRenamed(\"_2\", \"listeners\")\n\nlistenersDF.show(false)\n\n//Join songDF with listenersDF\nval joinDF = songDF.join(listenersDF, songDF(\"artist\") === listenersDF(\"band\"), \"inner\")\n\njoinDF.show(false)\n\n// val listenersDFa = listenersDF.withColumnRenamed(\"band\", \"artist\")\n// songDF.join(listenersDFa, Seq(\"artist\"), \"inner\").show()","user":"anonymous","dateUpdated":"2019-04-24T15:03:30+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556110994585_190477997","id":"20190424-150314_836071349","dateCreated":"2019-04-24T15:03:14+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16672","dateFinished":"2019-04-24T15:03:30+0200","dateStarted":"2019-04-24T15:03:30+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:37: error: not found: value songDF\n       val joinDF = songDF.join(listenersDF, songDF(\"artist\") === listenersDF(\"band\"), \"inner\")\n                    ^\n<console>:37: error: not found: value songDF\n       val joinDF = songDF.join(listenersDF, songDF(\"artist\") === listenersDF(\"band\"), \"inner\")\n                                             ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111000873_-977940246","id":"20190424-150320_1138574063","dateCreated":"2019-04-24T15:03:20+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16762","text":"%md\n<b><font color='blue'size=5>Python</font>\n\n","dateUpdated":"2019-04-24T15:03:46+0200","dateFinished":"2019-04-24T15:03:46+0200","dateStarted":"2019-04-24T15:03:46+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nfrom pyspark.sql.types import *\n\nmyData = [['Muse', 4571], ['Frank Sinatra', 1658], ['Beastie Boys', 2483]] \nmySchema = StructType([\n  StructField('band', StringType()),\n  StructField('listeners', IntegerType())\n])\n\nlistenersDF = spark.createDataFrame(myData, schema = mySchema) \nlistenersDF.show()\n\njoinDF = songDF.join(listenersDF, songDF['artist'] == listenersDF['band'], how = 'inner')\njoinDF.show()\n\n# listenersDFa = listenersDF.withColumnRenamed(\"band\", \"artist\")\n# songDF.join(listenersDFa, ['artist'], how = 'inner').show()","user":"anonymous","dateUpdated":"2019-04-24T15:03:52+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111026681_-588994203","id":"20190424-150346_1258259699","dateCreated":"2019-04-24T15:03:46+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16931","dateFinished":"2019-04-24T15:03:52+0200","dateStarted":"2019-04-24T15:03:52+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nModuleNotFoundError: No module named 'pyspark'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nModuleNotFoundError: No module named 'pyspark'\n\n"}]}},{"text":"%md\n### Aggregating and grouping\n\n* DataFrames can be grouped (`groupBy`, `groupByKey`) in a SQL-like fashion. Grouping functions can be found in the [Dataset API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n* DataFrames can be aggregated as well. Aggregation functions can be found in the [built-in DataFrame functions](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$).\n\n* Examples for aggregation functions:\n - count\n - sum\n - first\n - max\n - avg\n \n* For Spark Python: [API Docs](https://spark.apache.org/docs/2.4.0/api/python/index.html).","user":"anonymous","dateUpdated":"2019-04-24T15:04:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556111032906_-76202356","id":"20190424-150352_1471422808","dateCreated":"2019-04-24T15:03:52+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17020","dateFinished":"2019-04-24T15:04:01+0200","dateStarted":"2019-04-24T15:04:01+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Aggregating and grouping</h3>\n<ul>\n  <li>\n  <p>DataFrames can be grouped (<code>groupBy</code>, <code>groupByKey</code>) in a SQL-like fashion. Grouping functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset API</a>.</p></li>\n  <li>\n  <p>DataFrames can be aggregated as well. Aggregation functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\">built-in DataFrame functions</a>.</p></li>\n  <li>\n  <p>Examples for aggregation functions:</p></li>\n  <li>count</li>\n  <li>sum</li>\n  <li>first</li>\n  <li>max</li>\n  <li>avg</li>\n  <li>\n  <p>For Spark Python: <a href=\"https://spark.apache.org/docs/2.4.0/api/python/index.html\">API Docs</a>.</p></li>\n</ul>\n</div>"}]}}],"name":"/1. DataFrames, Datasets & RDDs/1.2 DataFrames","id":"2E942YWS9","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}