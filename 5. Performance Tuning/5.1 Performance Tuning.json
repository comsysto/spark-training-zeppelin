{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121806619_1757657372","id":"20190424-180326_1520032827","dateCreated":"2019-04-24T18:03:26+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59290","text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","dateUpdated":"2019-04-24T18:03:36+0200","dateFinished":"2019-04-24T18:03:36+0200","dateStarted":"2019-04-24T18:03:36+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]}},{"text":"%md\n# 5.1 Performance tuning","user":"anonymous","dateUpdated":"2019-04-24T18:03:43+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121816593_742325193","id":"20190424-180336_581231720","dateCreated":"2019-04-24T18:03:36+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59370","dateFinished":"2019-04-24T18:03:43+0200","dateStarted":"2019-04-24T18:03:43+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>5.1 Performance tuning</h1>\n</div>"}]}},{"text":"%md \n***5.1.1 Caching***\n\n***5.1.2 Order of Operations***\n\n***5.1.3 Broadcast Joins***\n\n***5.1.4 Prefer DataFrames/Datasets over RDDs (Catalyst Optimizer)***\n\n***5.1.5 Partitioning***\n\n***5.1.6 Avoid overloading of master/driver node***","user":"anonymous","dateUpdated":"2019-04-24T18:03:50+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121823048_-1196617381","id":"20190424-180343_1830598094","dateCreated":"2019-04-24T18:03:43+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59464","dateFinished":"2019-04-24T18:03:50+0200","dateStarted":"2019-04-24T18:03:50+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>5.1.1 Caching</em></strong></p>\n<p><strong><em>5.1.2 Order of Operations</em></strong></p>\n<p><strong><em>5.1.3 Broadcast Joins</em></strong></p>\n<p><strong><em>5.1.4 Prefer DataFrames/Datasets over RDDs (Catalyst Optimizer)</em></strong></p>\n<p><strong><em>5.1.5 Partitioning</em></strong></p>\n<p><strong><em>5.1.6 Avoid overloading of master/driver node</em></strong></p>\n</div>"}]}},{"text":"%md \n## 5.1.1 Caching\nBy default, each transformed RDD may be recomputed each time you run an action on it. This means, executing two actions on the same execution chain will perform all transformations in the chain twice.","user":"anonymous","dateUpdated":"2019-04-24T18:03:59+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121830120_-1382240485","id":"20190424-180350_860899934","dateCreated":"2019-04-24T18:03:50+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59554","dateFinished":"2019-04-24T18:03:59+0200","dateStarted":"2019-04-24T18:03:59+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.1 Caching</h2>\n<p>By default, each transformed RDD may be recomputed each time you run an action on it. This means, executing two actions on the same execution chain will perform all transformations in the chain twice.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:04:07+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121839792_1940530312","id":"20190424-180359_200234917","dateCreated":"2019-04-24T18:03:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59644","dateFinished":"2019-04-24T18:04:07+0200","dateStarted":"2019-04-24T18:04:07+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval textRDD = sc.textFile(\"dbfs:/cs-spark-training/sparkUI/\")\ntextRDD.take(3).foreach(println)","user":"anonymous","dateUpdated":"2019-04-24T18:04:20+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121847416_1660087246","id":"20190424-180407_1760179896","dateCreated":"2019-04-24T18:04:07+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59734","dateFinished":"2019-04-24T18:04:20+0200","dateStarted":"2019-04-24T18:04:20+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1333)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.take(RDD.scala:1327)\n  ... 51 elided\n"}]}},{"text":"val words = textRDD.flatMap(line => line.split(\" \"))       //flat each word into a single line\n                   .filter(line => !line.isEmpty)          //skip empty lines\n                   .map(word => (word, 1))                 //map each word into a tuple (to be able to group and count words)\n                      \nval groupWords = words.groupByKey()                        //group RDD by each unique word\n                      .map(t => (t._1, t._2.size))         //count appearance of each word\n                      .sortBy(t => t._2, false)            //sort RDD descending (1st action)\n\nval filterWords = groupWords.filter(t => t._1.startsWith(\"a\"))\n                            .count()                              //2nd action\n\ngroupWords.take(10).foreach(println)                              //3rd action","user":"anonymous","dateUpdated":"2019-04-24T18:04:28+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121860536_715108100","id":"20190424-180420_1700298424","dateCreated":"2019-04-24T18:04:20+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59823","dateFinished":"2019-04-24T18:04:28+0200","dateStarted":"2019-04-24T18:04:28+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value textRDD\n       val words = textRDD.flatMap(line => line.split(\" \"))       //flat each word into a single line\n                   ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121868672_385614626","id":"20190424-180428_834518584","dateCreated":"2019-04-24T18:04:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:59920","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T18:04:39+0200","dateFinished":"2019-04-24T18:04:39+0200","dateStarted":"2019-04-24T18:04:39+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nfrom __future__ import print_function\n\ntextRDD = sc.textFile('dbfs:/cs-spark-training/sparkUI/')\nprint(textRDD.take(3), sep = '\\n')","user":"anonymous","dateUpdated":"2019-04-24T18:04:45+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121879296_1359226739","id":"20190424-180439_1276087743","dateCreated":"2019-04-24T18:04:39+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60009","dateFinished":"2019-04-24T18:04:45+0200","dateStarted":"2019-04-24T18:04:45+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'sc' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'sc' is not defined\n\n"}]}},{"text":"%python\nwords = textRDD.flatMap(lambda text: text.split(' ')).filter(lambda line: line.strip()).map(lambda word: (word, 1))           \n\ngroupWords = words.groupByKey().map(lambda words: (words[0], len(words[1]))).sortBy(lambda words: words[1], ascending=False) \n\nfilterWords = groupWords.filter(lambda word: word[0].startswith('a')).count()  \ngroupWords.take(10)","user":"anonymous","dateUpdated":"2019-04-24T18:04:52+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121885593_-1861937377","id":"20190424-180445_429138024","dateCreated":"2019-04-24T18:04:45+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60098","dateFinished":"2019-04-24T18:04:52+0200","dateStarted":"2019-04-24T18:04:52+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'textRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'textRDD' is not defined\n\n"}]}},{"text":"%md\n##### Caching\n\n*   Caching should be used, in order to reuse intermediate transformation results (if enough memory available).\n\n*   In order to cache data the `.cache()` (or the synonym `.persist()`) method can be called on any DataFrame, Dataset or RDD.\n\n*   Caching can be configured with storage level parameters.\n\n*   The default storage level for DataFrames and Datasets is `MEMORY_AND_DISK`. For RDDs the default is `MEMORY_ONLY`.\n\n*   In addition views can also be cached using `CACHE TABLE`: `spark.sql(\"CACHE TABLE viewName\")`. \n\nStorage levels provided by Spark:\n\n* `MEMORY_ONLY`: If the data fits it will be stored in memory.\n\n* `DISK_ONLY`: All partitions will be stored on disk.\n\n* `MEMORY_AND_DISK`: All partitions which do not fit in memory are stored on disk. So called 'spilling'.\n\n\nFurthermore Spark provides special storage levels to serialize data in memory (onyl available in Scala):\n\n* `MEMORY_ONLY_SER`\n\n* `MEMORY_AND_DISK_SER`\n\nThese specialized serialization storage levels are more space efficient but take more time to be read by CPU.\n\nYou can also replicate partitions with the following storage levels:\n\n* `DISK_ONLY_2`\n\n* `MEMORY_AND_DISK_2`\n\n* `MEMORY_ONLY_2`\n\n* `MEMORY_AND_DISK_SER_2`\n\n* `MEMORY_ONLY_SER_2`\n\nFor views there are no storage levels available.\n\nYou can view more about storage levels [here](https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/which_storage_level_to_choose.html).","user":"anonymous","dateUpdated":"2019-04-24T18:05:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121892232_862408408","id":"20190424-180452_1678578896","dateCreated":"2019-04-24T18:04:52+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60186","dateFinished":"2019-04-24T18:05:03+0200","dateStarted":"2019-04-24T18:05:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>Caching</h5>\n<ul>\n  <li>\n  <p>Caching should be used, in order to reuse intermediate transformation results (if enough memory available).</p></li>\n  <li>\n  <p>In order to cache data the <code>.cache()</code> (or the synonym <code>.persist()</code>) method can be called on any DataFrame, Dataset or RDD.</p></li>\n  <li>\n  <p>Caching can be configured with storage level parameters.</p></li>\n  <li>\n  <p>The default storage level for DataFrames and Datasets is <code>MEMORY_AND_DISK</code>. For RDDs the default is <code>MEMORY_ONLY</code>.</p></li>\n  <li>\n  <p>In addition views can also be cached using <code>CACHE TABLE</code>: <code>spark.sql(&quot;CACHE TABLE viewName&quot;)</code>. </p></li>\n</ul>\n<p>Storage levels provided by Spark:</p>\n<ul>\n  <li>\n  <p><code>MEMORY_ONLY</code>: If the data fits it will be stored in memory.</p></li>\n  <li>\n  <p><code>DISK_ONLY</code>: All partitions will be stored on disk.</p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK</code>: All partitions which do not fit in memory are stored on disk. So called &lsquo;spilling&rsquo;.</p></li>\n</ul>\n<p>Furthermore Spark provides special storage levels to serialize data in memory (onyl available in Scala):</p>\n<ul>\n  <li>\n  <p><code>MEMORY_ONLY_SER</code></p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK_SER</code></p></li>\n</ul>\n<p>These specialized serialization storage levels are more space efficient but take more time to be read by CPU.</p>\n<p>You can also replicate partitions with the following storage levels:</p>\n<ul>\n  <li>\n  <p><code>DISK_ONLY_2</code></p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK_2</code></p></li>\n  <li>\n  <p><code>MEMORY_ONLY_2</code></p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK_SER_2</code></p></li>\n  <li>\n  <p><code>MEMORY_ONLY_SER_2</code></p></li>\n</ul>\n<p>For views there are no storage levels available.</p>\n<p>You can view more about storage levels <a href=\"https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/which_storage_level_to_choose.html\">here</a>.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:05:14+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121903592_601447109","id":"20190424-180503_1852591774","dateCreated":"2019-04-24T18:05:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60275","dateFinished":"2019-04-24T18:05:14+0200","dateStarted":"2019-04-24T18:05:14+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval words2 = textRDD.flatMap(line => line.split(\" \"))    //flat each word into a single line\n                     .filter(line => !line.isEmpty)      //skip empty lines\n                     .map(word => (word, 1))             //map each word into a tuple (to be able to group and count words)\n\nval groupWords2 = words2.groupByKey()                    //group RDD by each unique word\n                      .map(t => (t._1, t._2.size))       //count appearance of each word\n                      .sortBy(t => t._2, false)          //sort RDD descending\n\ngroupWords2.cache()\n\nval filterWords2 = groupWords2.filter(t => t._1.startsWith(\"a\")).count()  //1st action\n\ngroupWords2.take(10).foreach(println)                                     //2nd action","user":"anonymous","dateUpdated":"2019-04-24T18:05:25+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121914113_-1785906286","id":"20190424-180514_2000812945","dateCreated":"2019-04-24T18:05:14+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60365","dateFinished":"2019-04-24T18:05:25+0200","dateStarted":"2019-04-24T18:05:25+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value textRDD\n       val words2 = textRDD.flatMap(line => line.split(\" \"))    //flat each word into a single line\n                    ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T18:05:33+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121925225_134678757","id":"20190424-180525_881229586","dateCreated":"2019-04-24T18:05:25+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60454","dateFinished":"2019-04-24T18:05:33+0200","dateStarted":"2019-04-24T18:05:33+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nwords2 = textRDD.flatMap(lambda text: text.split(' ')).filter(lambda line: line.strip()).map(lambda word: (word, 1))           \ngroupWords2 = words2.groupByKey().map(lambda words: (words[0], len(words[1]))).sortBy(lambda words: words[1], ascending=False) \n\ngroupWords2.cache()\nfilterWords2 = groupWords2.filter(lambda word: word[0].startswith('a')).count()  \n\ngroupWords2.take(10)","user":"anonymous","dateUpdated":"2019-04-24T18:05:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121933873_-2024132835","id":"20190424-180533_317337455","dateCreated":"2019-04-24T18:05:33+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60543","dateFinished":"2019-04-24T18:05:46+0200","dateStarted":"2019-04-24T18:05:46+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'textRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'textRDD' is not defined\n\n"}]}},{"text":"%md\n#### Unpersist data\n\nRelease memory on your spark cluster for more important data with `.unpersist()`.","user":"anonymous","dateUpdated":"2019-04-24T18:05:55+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121946194_147211665","id":"20190424-180546_1963921081","dateCreated":"2019-04-24T18:05:46+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60632","dateFinished":"2019-04-24T18:05:55+0200","dateStarted":"2019-04-24T18:05:55+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Unpersist data</h4>\n<p>Release memory on your spark cluster for more important data with <code>.unpersist()</code>.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:06:04+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121955457_901850678","id":"20190424-180555_102621773","dateCreated":"2019-04-24T18:05:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60721","dateFinished":"2019-04-24T18:06:04+0200","dateStarted":"2019-04-24T18:06:04+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n// Clear the cache and regain memory\ngroupWords2.unpersist()","user":"anonymous","dateUpdated":"2019-04-24T18:06:14+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121964577_1211678336","id":"20190424-180604_1225885881","dateCreated":"2019-04-24T18:06:04+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60811","dateFinished":"2019-04-24T18:06:14+0200","dateStarted":"2019-04-24T18:06:14+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:31: error: not found: value groupWords2\n       groupWords2.unpersist()\n       ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T18:06:24+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121974193_1221175586","id":"20190424-180614_1259640087","dateCreated":"2019-04-24T18:06:14+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60900","dateFinished":"2019-04-24T18:06:24+0200","dateStarted":"2019-04-24T18:06:24+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\ngroupWords2.unpersist()","user":"anonymous","dateUpdated":"2019-04-24T18:06:38+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121984041_795482389","id":"20190424-180624_1766712801","dateCreated":"2019-04-24T18:06:24+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:60989","dateFinished":"2019-04-24T18:06:38+0200","dateStarted":"2019-04-24T18:06:38+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'groupWords2' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'groupWords2' is not defined\n\n"}]}},{"text":"%md\n## 5.1.2 Order of operations\n\n### Rough guidelines to consider for improving Spark performance\n\n*   Spark optimization engine is stronger with SQL Statements\n\n*   `.distinct` called last if necessary, or on fewest number of rows and columns necessary\n\n\n\n### Operations from least to most expensive\n\n*   Generally, you should try to perform your least expensive operations as soon as possible, and your most expensive operations afterwards, if possible. \n\n##### Transformations where no communication is needed.\n*  SELECT (COLUMNS) -> Especially when working with Parquet files\n*  FILTER (ROWS)    -> If you are filtering out a lot of rows, it is wise to cache the resulting filtered data\n*  SAMPLE (ROWS)    -> Take a sample of your input data\n*  MAP              -> Does not reduce the number of rows, but applies a function in parallel to all elements\n\n\n##### Actions where some communication is needed:\n*  REDUCE -> Passes only results from worker nodes to the driver          \n*  TAKE -> Brings some data from worker nodes and sends it to the driver\n*  COUNT -> Passes only resulting counts from worker nodes to the driver          \n*  COLLECT -> Brings all data from worker nodes and sends it to the driver\n\n\n##### Shuffles where a lot of communication is needed\n*  SORT          -> See Window Functions if sorting is only necessary within partitions\n*  JOIN          -> See Broadcast Join below\n*  REPARTITION   -> Useful if you know data will be analyzed by single partitions\n*  DISTINCT      -> Complexity can increase exponentially with the number of columns in the data\n\n`.ByKey` Operations can be faster if data is already partitioned by the same fields you are reducing by\n*  SORTBYKEY\n*  REDUCEBYKEY     ","user":"anonymous","dateUpdated":"2019-04-24T18:06:47+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121990601_-1153760387","id":"20190424-180630_1079750895","dateCreated":"2019-04-24T18:06:30+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61078","dateFinished":"2019-04-24T18:06:47+0200","dateStarted":"2019-04-24T18:06:47+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.2 Order of operations</h2>\n<h3>Rough guidelines to consider for improving Spark performance</h3>\n<ul>\n  <li>\n  <p>Spark optimization engine is stronger with SQL Statements</p></li>\n  <li>\n  <p><code>.distinct</code> called last if necessary, or on fewest number of rows and columns necessary</p></li>\n</ul>\n<h3>Operations from least to most expensive</h3>\n<ul>\n  <li>Generally, you should try to perform your least expensive operations as soon as possible, and your most expensive operations afterwards, if possible.</li>\n</ul>\n<h5>Transformations where no communication is needed.</h5>\n<ul>\n  <li>SELECT (COLUMNS) -&gt; Especially when working with Parquet files</li>\n  <li>FILTER (ROWS) -&gt; If you are filtering out a lot of rows, it is wise to cache the resulting filtered data</li>\n  <li>SAMPLE (ROWS) -&gt; Take a sample of your input data</li>\n  <li>MAP -&gt; Does not reduce the number of rows, but applies a function in parallel to all elements</li>\n</ul>\n<h5>Actions where some communication is needed:</h5>\n<ul>\n  <li>REDUCE -&gt; Passes only results from worker nodes to the driver</li>\n  <li>TAKE -&gt; Brings some data from worker nodes and sends it to the driver</li>\n  <li>COUNT -&gt; Passes only resulting counts from worker nodes to the driver</li>\n  <li>COLLECT -&gt; Brings all data from worker nodes and sends it to the driver</li>\n</ul>\n<h5>Shuffles where a lot of communication is needed</h5>\n<ul>\n  <li>SORT -&gt; See Window Functions if sorting is only necessary within partitions</li>\n  <li>JOIN -&gt; See Broadcast Join below</li>\n  <li>REPARTITION -&gt; Useful if you know data will be analyzed by single partitions</li>\n  <li>DISTINCT -&gt; Complexity can increase exponentially with the number of columns in the data</li>\n</ul>\n<p><code>.ByKey</code> Operations can be faster if data is already partitioned by the same fields you are reducing by<br/>* SORTBYKEY<br/>* REDUCEBYKEY</p>\n</div>"}]}},{"text":"%md\nCalling distinct on fewer columns reduces the number of comparisons required","user":"anonymous","dateUpdated":"2019-04-24T18:06:55+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122007417_-808853112","id":"20190424-180647_2054337143","dateCreated":"2019-04-24T18:06:47+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61183","dateFinished":"2019-04-24T18:06:55+0200","dateStarted":"2019-04-24T18:06:55+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Calling distinct on fewer columns reduces the number of comparisons required</p>\n</div>"}]}},{"text":"%spark\ncase class Song(artist: String, year: Int, loudness: Double)\n\nval millionSongRDD = spark.read\n                          .option(\"inferSchema\", true)\n                          .option(\"delimiter\", \"\\t\")\n                          .csv(\"dbfs:/databricks-datasets/songs/data-002/part-*\")\n                          .select($\"_c2\" as \"artist\", $\"_c15\" as \"year\", $\"_c9\" as \"loudness\")\n                          .as[Song]\n                          .rdd","user":"anonymous","dateUpdated":"2019-04-24T18:07:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122015369_1149686427","id":"20190424-180655_1165809301","dateCreated":"2019-04-24T18:06:55+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61273","dateFinished":"2019-04-24T18:07:03+0200","dateStarted":"2019-04-24T18:07:03+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:21: error: value $ is not a member of StringContext\n                                 .select($\"_c2\" as \"artist\", $\"_c15\" as \"year\", $\"_c9\" as \"loudness\")\n                                         ^\n<console>:21: error: value $ is not a member of StringContext\n                                 .select($\"_c2\" as \"artist\", $\"_c15\" as \"year\", $\"_c9\" as \"loudness\")\n                                                             ^\n<console>:21: error: value $ is not a member of StringContext\n                                 .select($\"_c2\" as \"artist\", $\"_c15\" as \"year\", $\"_c9\" as \"loudness\")\n                                                                                ^\n"}]}},{"text":"millionSongRDD.distinct.count","user":"anonymous","dateUpdated":"2019-04-24T18:07:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122023810_-1574447655","id":"20190424-180703_694555154","dateCreated":"2019-04-24T18:07:03+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61362","dateFinished":"2019-04-24T18:07:13+0200","dateStarted":"2019-04-24T18:07:13+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value millionSongRDD\n       millionSongRDD.distinct.count\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122033441_-1206262028","id":"20190424-180713_1552790904","dateCreated":"2019-04-24T18:07:13+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61450","text":"millionSongRDD.map(s => (s.artist, s.year)).distinct.count","dateUpdated":"2019-04-24T18:07:20+0200","dateFinished":"2019-04-24T18:07:20+0200","dateStarted":"2019-04-24T18:07:20+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value millionSongRDD\n       millionSongRDD.map(s => (s.artist, s.year)).distinct.count\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122040304_-2020147354","id":"20190424-180720_316245475","dateCreated":"2019-04-24T18:07:20+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61538","text":"millionSongRDD.map(s => (s.artist)).distinct.count","dateUpdated":"2019-04-24T18:07:26+0200","dateFinished":"2019-04-24T18:07:26+0200","dateStarted":"2019-04-24T18:07:26+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value millionSongRDD\n       millionSongRDD.map(s => (s.artist)).distinct.count\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122046721_-1085268987","id":"20190424-180726_303674004","dateCreated":"2019-04-24T18:07:26+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61626","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T18:07:38+0200","dateFinished":"2019-04-24T18:07:38+0200","dateStarted":"2019-04-24T18:07:38+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nmillionSongRDD = spark.read.option('delimiter', '\\t').csv(\"dbfs:/databricks-datasets/songs/data-002/part-*\", inferSchema = True).select('_c2', '_c15', '_c9').rdd.map(tuple)","user":"anonymous","dateUpdated":"2019-04-24T18:07:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122058193_1018539492","id":"20190424-180738_773171126","dateCreated":"2019-04-24T18:07:38+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61715","dateFinished":"2019-04-24T18:07:46+0200","dateStarted":"2019-04-24T18:07:46+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'spark' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'spark' is not defined\n\n"}]}},{"text":"%python\nmillionSongRDD.distinct().count()","user":"anonymous","dateUpdated":"2019-04-24T18:07:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122066753_1149971459","id":"20190424-180746_1954462912","dateCreated":"2019-04-24T18:07:46+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61804","dateFinished":"2019-04-24T18:07:58+0200","dateStarted":"2019-04-24T18:07:58+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongRDD' is not defined\n\n"}]}},{"text":"%python\nmillionSongRDD.map(lambda song: (song[0], song[1])).distinct().count()","user":"anonymous","dateUpdated":"2019-04-24T18:08:06+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122078921_78055219","id":"20190424-180758_479087572","dateCreated":"2019-04-24T18:07:58+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61892","dateFinished":"2019-04-24T18:08:06+0200","dateStarted":"2019-04-24T18:08:06+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongRDD' is not defined\n\n"}]}},{"text":"%python\n# millionSongRDD.map(s => (s.artist)).distinct.count\nmillionSongRDD.map(lambda song: song[0]).distinct().count()","user":"anonymous","dateUpdated":"2019-04-24T18:08:13+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122086306_364255916","id":"20190424-180806_849998208","dateCreated":"2019-04-24T18:08:06+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61980","dateFinished":"2019-04-24T18:08:13+0200","dateStarted":"2019-04-24T18:08:13+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongRDD' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongRDD' is not defined\n\n"}]}},{"text":"%md\n## 5.1.3 Broadcast Joins\nUsing the broadcast functionality available in `.SparkContext` can greatly reduce the size of each serialized task, and the cost of launching a job over a cluster. If your tasks use any large object from the driver program inside of them (e.g. a static lookup table), consider turning it into a broadcast variable. \n\nThis should be done for smaller dataframes used in joins or for dictionaries and map lookups.\n","user":"anonymous","dateUpdated":"2019-04-24T18:08:21+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122093914_-263799861","id":"20190424-180813_1103906047","dateCreated":"2019-04-24T18:08:13+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62068","dateFinished":"2019-04-24T18:08:21+0200","dateStarted":"2019-04-24T18:08:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.3 Broadcast Joins</h2>\n<p>Using the broadcast functionality available in <code>.SparkContext</code> can greatly reduce the size of each serialized task, and the cost of launching a job over a cluster. If your tasks use any large object from the driver program inside of them (e.g. a static lookup table), consider turning it into a broadcast variable. </p>\n<p>This should be done for smaller dataframes used in joins or for dictionaries and map lookups.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:09:52+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122101198_646597484","id":"20190424-180821_982166438","dateCreated":"2019-04-24T18:08:21+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62157","dateFinished":"2019-04-24T18:09:52+0200","dateStarted":"2019-04-24T18:09:52+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval millionSongs = spark.read\n                        .option(\"inferSchema\", true)\n                        .option(\"delimiter\", \"\\t\")\n                        .csv(\"dbfs:/databricks-datasets/songs/data-002/part-*\")\n                        .select($\"_c0\" as \"artist_id\",\n                                $\"_c1\" as \"analysis_sample_rate\",\n                                $\"_c2\" as \"artist_name\",\n                                $\"_c3\" as \"artist_familarity\",\n                                $\"_c4\" as \"artist_hotness\",\n                                $\"_c5\" as \"end_of_fade_in\",\n                                $\"_c6\" as \"key\",\n                                $\"_c7\" as \"key_confidence\",\n                                $\"_c8\" as \"duration\",\n                                $\"_c9\" as \"loudness\",\n                                $\"_c10\" as \"mode\",\n                                $\"_c11\" as \"mode_confidence\",\n                                $\"_c12\" as \"tempo\",\n                                $\"_c13\" as \"time_signature\",\n                                $\"_c14\" as \"time_signature_confidence\",\n                                $\"_c15\" as \"year\")","user":"anonymous","dateUpdated":"2019-04-24T18:10:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122192685_-686275078","id":"20190424-180952_1756968848","dateCreated":"2019-04-24T18:09:52+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62247","dateFinished":"2019-04-24T18:10:04+0200","dateStarted":"2019-04-24T18:10:03+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)\n  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:412)\n  ... 51 elided\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T18:10:17+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122203900_2078847257","id":"20190424-181003_555034064","dateCreated":"2019-04-24T18:10:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62336","dateFinished":"2019-04-24T18:10:17+0200","dateStarted":"2019-04-24T18:10:17+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\ncols = [\t\t\t\n\t\t\t\"artist_id\",\n\t\t\t\"analysis_sample_rate\",\n            \"artist_name\",\n            \"artist_familarity\",\n            \"artist_hotness\",\n            \"end_of_fade_in\",\n            \"key\",\n            \"key_confidence\",\n            \"duration\",\n            \"loudness\",\n            \"mode\",\n            \"mode_confidence\",\n            \"tempo\",\n            \"time_signature\",\n            \"time_signature_confidence\",\n            \"year\"\n]\nmillionSongs = spark.read.option('delimiter', '\\t').csv('dbfs:/databricks-datasets/songs/data-002/part-*').toDF(*cols)","user":"anonymous","dateUpdated":"2019-04-24T18:10:23+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122217812_-836223957","id":"20190424-181017_832045933","dateCreated":"2019-04-24T18:10:17+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62434","dateFinished":"2019-04-24T18:10:23+0200","dateStarted":"2019-04-24T18:10:23+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 19, in <module>\nNameError: name 'spark' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 19, in <module>\nNameError: name 'spark' is not defined\n\n"}]}},{"text":"%md\n### Regular join without broadcasting","user":"anonymous","dateUpdated":"2019-04-24T18:10:38+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122223299_1544347477","id":"20190424-181023_1802490440","dateCreated":"2019-04-24T18:10:23+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62523","dateFinished":"2019-04-24T18:10:38+0200","dateStarted":"2019-04-24T18:10:38+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Regular join without broadcasting</h3>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:10:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122232980_1133766156","id":"20190424-181032_304961585","dateCreated":"2019-04-24T18:10:32+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62612","dateFinished":"2019-04-24T18:10:46+0200","dateStarted":"2019-04-24T18:10:46+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval lookupTable = millionSongs.select(\"artist_name\", \"artist_id\").distinct()\n\nval joinedTable1 = millionSongs.join(lookupTable,\n                                     millionSongs(\"artist_name\") === lookupTable(\"artist_name\"),\n                                    \"leftouter\")\n\njoinedTable1.count()","user":"anonymous","dateUpdated":"2019-04-24T18:10:55+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122246324_-1804335059","id":"20190424-181046_898012742","dateCreated":"2019-04-24T18:10:46+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62725","dateFinished":"2019-04-24T18:10:55+0200","dateStarted":"2019-04-24T18:10:55+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value millionSongs\n       val lookupTable = millionSongs.select(\"artist_name\", \"artist_id\").distinct()\n                         ^\n<console>:31: error: not found: value millionSongs\n       val joinedTable1 = millionSongs.join(lookupTable,\n                          ^\n<console>:32: error: not found: value millionSongs\n                                            millionSongs(\"artist_name\") === lookupTable(\"artist_name\"),\n                                            ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T18:11:05+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122255220_-170901903","id":"20190424-181055_299171026","dateCreated":"2019-04-24T18:10:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62814","dateFinished":"2019-04-24T18:11:05+0200","dateStarted":"2019-04-24T18:11:05+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nlookupTable = millionSongs[['artist_name', 'artist_id']].distinct()\n\njoinedTable1 = millionSongs.join(lookupTable, millionSongs['artist_name'] == lookupTable['artist_name'], how = \"leftouter\")\n\njoinedTable1.count()","user":"anonymous","dateUpdated":"2019-04-24T18:11:12+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122265164_1641254345","id":"20190424-181105_1068204527","dateCreated":"2019-04-24T18:11:05+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62903","dateFinished":"2019-04-24T18:11:12+0200","dateStarted":"2019-04-24T18:11:12+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\n"}]}},{"text":"%md\n### Use broadcast for smaller dataframes in joins","user":"anonymous","dateUpdated":"2019-04-24T18:11:22+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122272037_26638555","id":"20190424-181112_962119685","dateCreated":"2019-04-24T18:11:12+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:62992","dateFinished":"2019-04-24T18:11:22+0200","dateStarted":"2019-04-24T18:11:22+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Use broadcast for smaller dataframes in joins</h3>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:11:30+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122278812_1212945350","id":"20190424-181118_775504325","dateCreated":"2019-04-24T18:11:18+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63081","dateFinished":"2019-04-24T18:11:30+0200","dateStarted":"2019-04-24T18:11:30+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nval lookupTable2 = millionSongs.select(\"artist_name\", \"artist_id\").distinct()\n\nimport org.apache.spark.sql.functions.broadcast  \n\n// Broadcast will fully copy the smaller table to each worker node before joining\nval joinedTable2 = millionSongs.join(broadcast(lookupTable2),\n                                     millionSongs(\"artist_name\") === lookupTable2(\"artist_name\"),\n                                     \"leftouter\")\n\njoinedTable2.count()","user":"anonymous","dateUpdated":"2019-04-24T18:11:41+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122290900_850184713","id":"20190424-181130_93049248","dateCreated":"2019-04-24T18:11:30+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63194","dateFinished":"2019-04-24T18:11:41+0200","dateStarted":"2019-04-24T18:11:41+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value millionSongs\n       val lookupTable2 = millionSongs.select(\"artist_name\", \"artist_id\").distinct()\n                          ^\n<console>:34: error: not found: value millionSongs\n       val joinedTable2 = millionSongs.join(broadcast(lookupTable2),\n                          ^\n<console>:35: error: not found: value millionSongs\n                                            millionSongs(\"artist_name\") === lookupTable2(\"artist_name\"),\n                                            ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T18:11:50+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122301325_1641124721","id":"20190424-181141_1221205570","dateCreated":"2019-04-24T18:11:41+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63283","dateFinished":"2019-04-24T18:11:50+0200","dateStarted":"2019-04-24T18:11:50+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nlookupTable2 = millionSongs[['artist_name', 'artist_id']].distinct()\n\nfrom pyspark.sql.functions import broadcast  \n\n# Broadcast will fully copy the smaller table to each worker node before joining\njoinedTable2 = millionSongs.join(broadcast(lookupTable2), millionSongs['artist_name'] == lookupTable2['artist_name'], how = 'leftouter')\n\njoinedTable2.count()","user":"anonymous","dateUpdated":"2019-04-24T18:11:56+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122310699_-1501189252","id":"20190424-181150_1897833219","dateCreated":"2019-04-24T18:11:50+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63372","dateFinished":"2019-04-24T18:11:56+0200","dateStarted":"2019-04-24T18:11:56+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\n"}]}},{"text":"%md\n## 5.1.4 Prefer DataFrames/Datasets to RDDs","user":"anonymous","dateUpdated":"2019-04-24T18:12:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122316677_938245708","id":"20190424-181156_1134628556","dateCreated":"2019-04-24T18:11:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63461","dateFinished":"2019-04-24T18:12:03+0200","dateStarted":"2019-04-24T18:12:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.4 Prefer DataFrames/Datasets to RDDs</h2>\n</div>"}]}},{"text":"%md\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/CatalystOptimizer.png'>","user":"anonymous","dateUpdated":"2019-04-24T18:12:10+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122323861_1959864909","id":"20190424-181203_819940109","dateCreated":"2019-04-24T18:12:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63550","dateFinished":"2019-04-24T18:12:10+0200","dateStarted":"2019-04-24T18:12:10+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/CatalystOptimizer.png'>\n</div>"}]}},{"text":"%md\n***Catalyst Optimzer for DataFrames/Datasets***\n\n* Determines and optimize partitions and stages of each job in case of DataFrames/Datasets\n\n* Jobs are executed due to catalyst execution plans\n\n* Catalyst execution plans consist out of:\n  - Parsed logical plan\n  - Analyzed logical plan\n  - Optimized plan\n  - Physical plan\n  - Code generation\n\n* Investigate catalyst execution plan by checking the SQL tab in the Spark web UI or by calling `explain(true)` at the end of query\n\n* Benefits:\n  - Minimizes data transfer between workers and shuffle operations\n  - Pipelines maximum number of operations into one stage\n  - Code generation for every stage at run time (spark.sql.codegen.wholeStage)\n  - If beneficial, jobs can be expanded into multiple jobs \n\n\n* RDDs have to be optimized manually (see also 5.1.5. Partitioning)\n\n* RDDs execution plans can be investigated by checking the Jobs and/or Stages tab in the Spark web UI or by calling `toDebugString`\n\nFurther readings: [Deep Dive into Spark SQL’s Catalyst Optimize](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)","user":"anonymous","dateUpdated":"2019-04-24T18:12:17+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122329973_-1130880494","id":"20190424-181209_65266865","dateCreated":"2019-04-24T18:12:09+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63640","dateFinished":"2019-04-24T18:12:17+0200","dateStarted":"2019-04-24T18:12:17+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Catalyst Optimzer for DataFrames/Datasets</em></strong></p>\n<ul>\n  <li>\n  <p>Determines and optimize partitions and stages of each job in case of DataFrames/Datasets</p></li>\n  <li>\n  <p>Jobs are executed due to catalyst execution plans</p></li>\n  <li>\n  <p>Catalyst execution plans consist out of:</p></li>\n  <li>Parsed logical plan</li>\n  <li>Analyzed logical plan</li>\n  <li>Optimized plan</li>\n  <li>Physical plan</li>\n  <li>Code generation</li>\n  <li>\n  <p>Investigate catalyst execution plan by checking the SQL tab in the Spark web UI or by calling <code>explain(true)</code> at the end of query</p></li>\n  <li>\n  <p>Benefits:</p></li>\n  <li>Minimizes data transfer between workers and shuffle operations</li>\n  <li>Pipelines maximum number of operations into one stage</li>\n  <li>Code generation for every stage at run time (spark.sql.codegen.wholeStage)</li>\n  <li>If beneficial, jobs can be expanded into multiple jobs</li>\n  <li>\n  <p>RDDs have to be optimized manually (see also 5.1.5. Partitioning)</p></li>\n  <li>\n  <p>RDDs execution plans can be investigated by checking the Jobs and/or Stages tab in the Spark web UI or by calling <code>toDebugString</code></p></li>\n</ul>\n<p>Further readings: <a href=\"https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html\">Deep Dive into Spark SQL’s Catalyst Optimize</a></p>\n</div>"}]}},{"text":"%md\n***Exemplary investigation of catalyst execution plan***","user":"anonymous","dateUpdated":"2019-04-24T18:12:25+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122337734_1497454880","id":"20190424-181217_856614330","dateCreated":"2019-04-24T18:12:17+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63730","dateFinished":"2019-04-24T18:12:25+0200","dateStarted":"2019-04-24T18:12:25+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Exemplary investigation of catalyst execution plan</em></strong></p>\n</div>"}]}},{"text":"joinedTable2.explain(true)","user":"anonymous","dateUpdated":"2019-04-24T18:12:33+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122345069_689511536","id":"20190424-181225_820201251","dateCreated":"2019-04-24T18:12:25+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63820","dateFinished":"2019-04-24T18:12:33+0200","dateStarted":"2019-04-24T18:12:33+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value joinedTable2\n       joinedTable2.explain(true)\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122353525_928228616","id":"20190424-181233_651047719","dateCreated":"2019-04-24T18:12:33+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63909","text":"%md\n## 5.1.5 Partitioning\n\nIf most of your processing will be done on specific subsets of your dataset (i.e. individual artists, genres, etc.) or you want to leverage the performance by utilize parallelism it makes sense to manually repartition your data. This will ensure data locality which means data that needs to be processed together will be located together on the same server.\n\nSpark provides two ways of (re-)partitioning:\n\n* `.coalesce()`: Can *only reduce* the number of partitions. It´s not possible to increase the number of partitions with `coalesce`. Does *not* require to shuffle data and is therefore a efficient way to reduce the number of partitions.\n\n* `.repartition()`: Can *increase and decrease* the number of partitions. `repartition` does require to shuffle data and equaly distributes the data among the partitions.\n\n***Sparks rule of thumb for `repartition()`: ***\nnumber of partitions = 2 or 3 X CPUs in cluster X cores per CPU\n\nSee also [*Level of parallelism*](https://spark.apache.org/docs/latest/tuning.html#level-of-parallelism)","dateUpdated":"2019-04-24T18:12:44+0200","dateFinished":"2019-04-24T18:12:44+0200","dateStarted":"2019-04-24T18:12:44+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.5 Partitioning</h2>\n<p>If most of your processing will be done on specific subsets of your dataset (i.e. individual artists, genres, etc.) or you want to leverage the performance by utilize parallelism it makes sense to manually repartition your data. This will ensure data locality which means data that needs to be processed together will be located together on the same server.</p>\n<p>Spark provides two ways of (re-)partitioning:</p>\n<ul>\n  <li>\n  <p><code>.coalesce()</code>: Can <em>only reduce</em> the number of partitions. It´s not possible to increase the number of partitions with <code>coalesce</code>. Does <em>not</em> require to shuffle data and is therefore a efficient way to reduce the number of partitions.</p></li>\n  <li>\n  <p><code>.repartition()</code>: Can <em>increase and decrease</em> the number of partitions. <code>repartition</code> does require to shuffle data and equaly distributes the data among the partitions.</p></li>\n</ul>\n<p>***Sparks rule of thumb for <code>repartition()</code>: ***<br/>number of partitions = 2 or 3 X CPUs in cluster X cores per CPU</p>\n<p>See also <a href=\"https://spark.apache.org/docs/latest/tuning.html#level-of-parallelism\"><em>Level of parallelism</em></a></p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:12:53+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122364837_305456798","id":"20190424-181244_1708327145","dateCreated":"2019-04-24T18:12:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63998","dateFinished":"2019-04-24T18:12:53+0200","dateStarted":"2019-04-24T18:12:53+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nmillionSongs.groupBy(\"artist_name\").count().count()","user":"anonymous","dateUpdated":"2019-04-24T18:13:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122373037_-1299677239","id":"20190424-181253_812535340","dateCreated":"2019-04-24T18:12:53+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64088","dateFinished":"2019-04-24T18:13:03+0200","dateStarted":"2019-04-24T18:13:03+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value millionSongs\n       millionSongs.groupBy(\"artist_name\").count().count()\n       ^\n"}]}},{"text":"val songs_partitioned = millionSongs.repartition($\"artist_name\")","user":"anonymous","dateUpdated":"2019-04-24T18:13:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122383105_803256330","id":"20190424-181303_1029262996","dateCreated":"2019-04-24T18:13:03+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64177","dateFinished":"2019-04-24T18:13:09+0200","dateStarted":"2019-04-24T18:13:09+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:29: error: not found: value millionSongs\n       val songs_partitioned = millionSongs.repartition($\"artist_name\")\n                               ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122389661_-106778021","id":"20190424-181309_2090048473","dateCreated":"2019-04-24T18:13:09+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64265","text":"songs_partitioned.groupBy(\"artist_name\").count().count()","dateUpdated":"2019-04-24T18:13:16+0200","dateFinished":"2019-04-24T18:13:16+0200","dateStarted":"2019-04-24T18:13:16+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songs_partitioned\n       songs_partitioned.groupBy(\"artist_name\").count().count()\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122396125_257817112","id":"20190424-181316_521507640","dateCreated":"2019-04-24T18:13:16+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64353","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T18:13:23+0200","dateFinished":"2019-04-24T18:13:23+0200","dateStarted":"2019-04-24T18:13:23+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python \nmillionSongs.groupBy('artist_name').count().count()","user":"anonymous","dateUpdated":"2019-04-24T18:13:34+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122403214_-412433028","id":"20190424-181323_1164057972","dateCreated":"2019-04-24T18:13:23+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64442","dateFinished":"2019-04-24T18:13:34+0200","dateStarted":"2019-04-24T18:13:34+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\n"}]}},{"text":"%python\nsongs_partitioned = millionSongs.repartition('artist_name')","user":"anonymous","dateUpdated":"2019-04-24T18:13:40+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122414061_137474801","id":"20190424-181334_727863397","dateCreated":"2019-04-24T18:13:34+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64531","dateFinished":"2019-04-24T18:13:40+0200","dateStarted":"2019-04-24T18:13:40+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'millionSongs' is not defined\n\n"}]}},{"text":"%python\nsongs_partitioned.groupBy('artist_name').count().count()","user":"anonymous","dateUpdated":"2019-04-24T18:13:47+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122420070_1305437393","id":"20190424-181340_2078089042","dateCreated":"2019-04-24T18:13:40+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64619","dateFinished":"2019-04-24T18:13:47+0200","dateStarted":"2019-04-24T18:13:47+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songs_partitioned' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songs_partitioned' is not defined\n\n"}]}},{"text":"%md\n## 5.1.6 Avoid overloading of master/driver node\n\n*   Use `.collect` for large datasets carefully. `.collect` brings all of your data to the master node and can easily kill your application.\n\n*   If you want to check whether your dataframe is empty use data.take(1).length == 0 instead.\n\n*   Use `.takeSample` if you want to check out more than a few rows of data.","user":"anonymous","dateUpdated":"2019-04-24T18:13:54+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556122427262_486189946","id":"20190424-181347_1027871197","dateCreated":"2019-04-24T18:13:47+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:64707","dateFinished":"2019-04-24T18:13:54+0200","dateStarted":"2019-04-24T18:13:54+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.6 Avoid overloading of master/driver node</h2>\n<ul>\n  <li>\n  <p>Use <code>.collect</code> for large datasets carefully. <code>.collect</code> brings all of your data to the master node and can easily kill your application.</p></li>\n  <li>\n  <p>If you want to check whether your dataframe is empty use data.take(1).length == 0 instead.</p></li>\n  <li>\n  <p>Use <code>.takeSample</code> if you want to check out more than a few rows of data.</p></li>\n</ul>\n</div>"}]}}],"name":"/5. Performance Tuning/5.1 Performance Tuning","id":"2E9X8V23M","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}