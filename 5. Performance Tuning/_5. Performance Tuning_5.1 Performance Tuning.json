{"paragraphs":[{"text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893978_1854669762","id":"20190424-180326_1520032827","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:38284"},{"text":"%md\n# 5.1 Performance tuning","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>5.1 Performance tuning</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893979_2115876976","id":"20190424-180336_581231720","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38285"},{"text":"%md \n***5.1.1 Caching***\n\n***5.1.2 Order of Operations***\n\n***5.1.3 Broadcast Joins***\n\n***5.1.4 Prefer DataFrames/Datasets over RDDs (Catalyst Optimizer)***\n\n***5.1.5 Partitioning***\n\n***5.1.6 Avoid overloading of master/driver node***","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>5.1.1 Caching</em></strong></p>\n<p><strong><em>5.1.2 Order of Operations</em></strong></p>\n<p><strong><em>5.1.3 Broadcast Joins</em></strong></p>\n<p><strong><em>5.1.4 Prefer DataFrames/Datasets over RDDs (Catalyst Optimizer)</em></strong></p>\n<p><strong><em>5.1.5 Partitioning</em></strong></p>\n<p><strong><em>5.1.6 Avoid overloading of master/driver node</em></strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893979_-1104610212","id":"20190424-180343_1830598094","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38286"},{"text":"%md \n## 5.1.1 Caching\nBy default, each transformed RDD may be recomputed each time you run an action on it. This means, executing two actions on the same execution chain will perform all transformations in the chain twice.","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.1 Caching</h2>\n<p>By default, each transformed RDD may be recomputed each time you run an action on it. This means, executing two actions on the same execution chain will perform all transformations in the chain twice.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893979_-284591071","id":"20190424-180350_860899934","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38287"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T09:45:12+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893979_254631170","id":"20190424-180359_200234917","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:45:12+0000","dateFinished":"2019-05-21T09:45:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38288"},{"text":"%spark\nval textRDD = sc.textFile(\"s3a://cs-spark-basic-training/sparkUI/\")\ntextRDD.take(3).foreach(println)","user":"anonymous","dateUpdated":"2019-05-21T09:29:03+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"# Apache Spark\n\nSpark is a fast and general cluster computing system for Big Data. It provides\ntextRDD: org.apache.spark.rdd.RDD[String] = s3a://cs-spark-basic-training/sparkUI/ MapPartitionsRDD[579] at textFile at <console>:31\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=190"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893979_-1605812538","id":"20190424-180407_1760179896","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:29:03+0000","dateFinished":"2019-05-21T09:29:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38289"},{"text":"val words = textRDD.flatMap(line => line.split(\" \"))       // flat each word into a single line\n                   .filter(line => !line.isEmpty)          // skip empty lines\n                   .map(word => (word, 1))                 // map each word into a tuple (to be able to group and count words)\n                      \nval groupWords = words.groupByKey()                        // group RDD by each unique word\n                      .map(t => (t._1, t._2.size))         // count appearance of each word\n                      .sortBy(t => t._2, false)            // sort RDD descending (1st action)\n\nval filterWords = groupWords.filter(t => t._1.startsWith(\"a\"))\n                            .count()                              // 2nd action\n\ngroupWords.take(10).foreach(println)                              // 3rd action","user":"anonymous","dateUpdated":"2019-05-21T09:30:03+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(the,24)\n(to,17)\n(Spark,16)\n(for,12)\n(##,9)\n(and,9)\n(a,8)\n(can,7)\n(run,7)\n(on,7)\nwords: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[582] at map at <console>:33\ngroupWords: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[589] at sortBy at <console>:37\nfilterWords: Long = 10\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=191","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=192","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=193"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893980_-1731650469","id":"20190424-180420_1700298424","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:30:03+0000","dateFinished":"2019-05-21T09:30:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38290"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T09:45:25+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893980_-1314776659","id":"20190424-180428_834518584","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:45:25+0000","dateFinished":"2019-05-21T09:45:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38291"},{"text":"%pyspark\ntextRDD = sc.textFile(\"s3a://cs-spark-basic-training/sparkUI/\")\n\nfor element in textRDD.collect():\n    print(element)","user":"anonymous","dateUpdated":"2019-05-21T09:31:07+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"# Apache Spark\n\nSpark is a fast and general cluster computing system for Big Data. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\nMLlib for machine learning, GraphX for graph processing,\nand Spark Streaming for stream processing.\n\n<http://spark.apache.org/>\n\n\n## Online Documentation\n\nYou can find the latest Spark documentation, including a programming\nguide, on the [project web page](http://spark.apache.org/documentation.html).\nThis README file only contains basic setup instructions.\n\n## Building Spark\n\nSpark is built using [Apache Maven](http://maven.apache.org/).\nTo build Spark and its example programs, run:\n\n    build/mvn -DskipTests clean package\n\n(You do not need to do this if you downloaded a pre-built package.)\n\nYou can build Spark using more than one thread by using the -T option with Maven, see [\"Parallel builds in Maven 3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).\nMore detailed documentation is available from the project site, at\n[\"Building Spark\"](http://spark.apache.org/docs/latest/building-spark.html).\n\nFor general development tips, including info on developing Spark using an IDE, see [\"Useful Developer Tools\"](http://spark.apache.org/developer-tools.html).\n\n## Interactive Scala Shell\n\nThe easiest way to start using Spark is through the Scala shell:\n\n    ./bin/spark-shell\n\nTry the following command, which should return 1000:\n\n    scala> sc.parallelize(1 to 1000).count()\n\n## Interactive Python Shell\n\nAlternatively, if you prefer Python, you can use the Python shell:\n\n    ./bin/pyspark\n\nAnd run the following command, which should also return 1000:\n\n    >>> sc.parallelize(range(1000)).count()\n\n## Example Programs\n\nSpark also comes with several sample programs in the `examples` directory.\nTo run one of them, use `./bin/run-example <class> [params]`. For example:\n\n    ./bin/run-example SparkPi\n\nwill run the Pi example locally.\n\nYou can set the MASTER environment variable when running examples to submit\nexamples to a cluster. This can be a mesos:// or spark:// URL,\n\"yarn\" to run on YARN, and \"local\" to run\nlocally with one thread, or \"local[N]\" to run locally with N threads. You\ncan also use an abbreviated class name if the class is in the `examples`\npackage. For instance:\n\n    MASTER=spark://host:7077 ./bin/run-example SparkPi\n\nMany of the example programs print usage help if no params are given.\n\n## Running Tests\n\nTesting first requires [building Spark](#building-spark). Once Spark is built, tests\ncan be run using:\n\n    ./dev/run-tests\n\nPlease see the guidance on how to\n[run tests for a module, or individual tests](http://spark.apache.org/developer-tools.html#individual-tests).\n\n## A Note About Hadoop Versions\n\nSpark uses the Hadoop core library to talk to HDFS and other Hadoop-supported\nstorage systems. Because the protocols have changed in different versions of\nHadoop, you must build Spark against the same version that your cluster runs.\n\nPlease refer to the build documentation at\n[\"Specifying the Hadoop Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)\nfor detailed guidance on building for a particular distribution of Hadoop, including\nbuilding for particular Hive and Hive Thriftserver distributions.\n\n## Configuration\n\nPlease refer to the [Configuration Guide](http://spark.apache.org/docs/latest/configuration.html)\nin the online documentation for an overview on how to configure Spark.\n\n## Contributing\n\nPlease review the [Contribution to Spark guide](http://spark.apache.org/contributing.html)\nfor information on how to get started contributing to the project.\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=194"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893980_1658044206","id":"20190424-180439_1276087743","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:31:07+0000","dateFinished":"2019-05-21T09:31:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38292"},{"text":"%pyspark\nwords = textRDD.flatMap(lambda text: text.split(\" \")).filter(lambda line: not line == '').map(lambda word: (word, 1))   # flat each word into a single line, skip empty lines and map each word into a tuple (to be able to group and count words)   \ngroupWords = words.groupByKey().map(lambda words: (words[0], len(words[1]))).sortBy(lambda words: words[1], ascending=False)   # group RDD by each unique word, count appearance of each word and sort RDD descending (1st action) \n\nfilterWords = groupWords.filter(lambda word: word[0].startswith('a')).count()   # 2nd action\n\nfor element in groupWords.take(10):   # 3rd action\n    print(element)","user":"anonymous","dateUpdated":"2019-05-21T09:43:13+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(u'the', 24)\n(u'to', 17)\n(u'Spark', 16)\n(u'for', 12)\n(u'##', 9)\n(u'and', 9)\n(u'a', 8)\n(u'run', 7)\n(u'on', 7)\n(u'can', 7)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=216","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=217","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=218","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=219"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893980_-785387402","id":"20190424-180445_429138024","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:43:13+0000","dateFinished":"2019-05-21T09:43:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38293"},{"text":"%md\n##### Caching\n\n*   Caching should be used, in order to reuse intermediate transformation results (if enough memory available).\n\n*   In order to cache data the `.cache()` (or the synonym `.persist()`) method can be called on any DataFrame, Dataset or RDD.\n\n*   Caching can be configured with storage level parameters.\n\n*   The default storage level for DataFrames and Datasets is `MEMORY_AND_DISK`. For RDDs the default is `MEMORY_ONLY`.\n\n*   In addition views can also be cached using `CACHE TABLE`: `spark.sql(\"CACHE TABLE viewName\")`. \n\nStorage levels provided by Spark:\n\n* `MEMORY_ONLY`: If the data fits it will be stored in memory.\n\n* `DISK_ONLY`: All partitions will be stored on disk.\n\n* `MEMORY_AND_DISK`: All partitions which do not fit in memory are stored on disk. So called 'spilling'.\n\n\nFurthermore Spark provides special storage levels to serialize data in memory (onyl available in Scala):\n\n* `MEMORY_ONLY_SER`\n\n* `MEMORY_AND_DISK_SER`\n\nThese specialized serialization storage levels are more space efficient but take more time to be read by CPU.\n\nYou can also replicate partitions with the following storage levels:\n\n* `DISK_ONLY_2`\n\n* `MEMORY_AND_DISK_2`\n\n* `MEMORY_ONLY_2`\n\n* `MEMORY_AND_DISK_SER_2`\n\n* `MEMORY_ONLY_SER_2`\n\nFor views there are no storage levels available.\n\nYou can view more about storage levels [here](https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/which_storage_level_to_choose.html).","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>Caching</h5>\n<ul>\n  <li>\n  <p>Caching should be used, in order to reuse intermediate transformation results (if enough memory available).</p></li>\n  <li>\n  <p>In order to cache data the <code>.cache()</code> (or the synonym <code>.persist()</code>) method can be called on any DataFrame, Dataset or RDD.</p></li>\n  <li>\n  <p>Caching can be configured with storage level parameters.</p></li>\n  <li>\n  <p>The default storage level for DataFrames and Datasets is <code>MEMORY_AND_DISK</code>. For RDDs the default is <code>MEMORY_ONLY</code>.</p></li>\n  <li>\n  <p>In addition views can also be cached using <code>CACHE TABLE</code>: <code>spark.sql(&quot;CACHE TABLE viewName&quot;)</code>. </p></li>\n</ul>\n<p>Storage levels provided by Spark:</p>\n<ul>\n  <li>\n  <p><code>MEMORY_ONLY</code>: If the data fits it will be stored in memory.</p></li>\n  <li>\n  <p><code>DISK_ONLY</code>: All partitions will be stored on disk.</p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK</code>: All partitions which do not fit in memory are stored on disk. So called &lsquo;spilling&rsquo;.</p></li>\n</ul>\n<p>Furthermore Spark provides special storage levels to serialize data in memory (onyl available in Scala):</p>\n<ul>\n  <li>\n  <p><code>MEMORY_ONLY_SER</code></p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK_SER</code></p></li>\n</ul>\n<p>These specialized serialization storage levels are more space efficient but take more time to be read by CPU.</p>\n<p>You can also replicate partitions with the following storage levels:</p>\n<ul>\n  <li>\n  <p><code>DISK_ONLY_2</code></p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK_2</code></p></li>\n  <li>\n  <p><code>MEMORY_ONLY_2</code></p></li>\n  <li>\n  <p><code>MEMORY_AND_DISK_SER_2</code></p></li>\n  <li>\n  <p><code>MEMORY_ONLY_SER_2</code></p></li>\n</ul>\n<p>For views there are no storage levels available.</p>\n<p>You can view more about storage levels <a href=\"https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/which_storage_level_to_choose.html\">here</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893980_1974969784","id":"20190424-180452_1678578896","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38294"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T09:45:39+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893981_2083275056","id":"20190424-180503_1852591774","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:45:39+0000","dateFinished":"2019-05-21T09:45:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38295"},{"text":"%spark\nval words2 = textRDD.flatMap(line => line.split(\" \"))    // flat each word into a single line\n                     .filter(line => !line.isEmpty)      // skip empty lines\n                     .map(word => (word, 1))             // map each word into a tuple (to be able to group and count words)\n\nval groupWords2 = words2.groupByKey()                    // group RDD by each unique word\n                      .map(t => (t._1, t._2.size))       // count appearance of each word\n                      .sortBy(t => t._2, false)          // sort RDD descending\n\ngroupWords2.cache()\n\nval filterWords2 = groupWords2.filter(t => t._1.startsWith(\"a\")).count()  // 1st action\n\ngroupWords2.take(10).foreach(println)                                     // 2nd action","user":"anonymous","dateUpdated":"2019-05-21T09:47:06+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(the,24)\n(to,17)\n(Spark,16)\n(for,12)\n(##,9)\n(and,9)\n(a,8)\n(can,7)\n(run,7)\n(on,7)\nwords2: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[672] at map at <console>:33\ngroupWords2: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[679] at sortBy at <console>:37\nfilterWords2: Long = 10\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=220","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=221","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=222"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893981_880330812","id":"20190424-180514_2000812945","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:46:04+0000","dateFinished":"2019-05-21T09:46:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38296"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T09:45:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893981_-806640703","id":"20190424-180525_881229586","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:45:48+0000","dateFinished":"2019-05-21T09:45:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38297"},{"text":"%pyspark\nwords2 = textRDD.flatMap(lambda text: text.split(' ')).filter(lambda line: not line == '').map(lambda word: (word, 1))   # flat each word into a single line, skip empty lines and map each word into a tuple (to be able to group and count words)\n\ngroupWords2 = words2.groupByKey().map(lambda words: (words[0], len(words[1]))).sortBy(lambda words: words[1], ascending=False)   # group RDD by each unique word, count appearance of each word and sort RDD descending\n\ngroupWords2.cache()\n\nfilterWords2 = groupWords2.filter(lambda word: word[0].startswith('a')).count()   # 1st action\n\nfor element in groupWords2.take(10):   # 2nd action\n    print(element)","user":"anonymous","dateUpdated":"2019-05-21T09:49:24+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(u'the', 24)\n(u'to', 17)\n(u'Spark', 16)\n(u'for', 12)\n(u'##', 9)\n(u'and', 9)\n(u'a', 8)\n(u'run', 7)\n(u'on', 7)\n(u'can', 7)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=227","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=228","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=229","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=230"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893981_244308815","id":"20190424-180533_317337455","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:49:25+0000","dateFinished":"2019-05-21T09:49:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38298"},{"text":"%md\n#### Unpersist data\n\nRelease memory on your spark cluster for more important data with `.unpersist()`.","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Unpersist data</h4>\n<p>Release memory on your spark cluster for more important data with <code>.unpersist()</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893982_732870481","id":"20190424-180546_1963921081","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38299"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T09:49:36+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893982_-2130593520","id":"20190424-180555_102621773","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T09:49:36+0000","dateFinished":"2019-05-21T09:49:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38300"},{"text":"%spark\n// Clear the cache to regain memory\ngroupWords2.unpersist()","user":"anonymous","dateUpdated":"2019-05-21T11:16:45+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res37: groupWords2.type = MapPartitionsRDD[679] at sortBy at <console>:37\n"}]},"apps":[],"jobName":"paragraph_1558430893982_-1227807980","id":"20190424-180604_1225885881","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T11:16:45+0000","dateFinished":"2019-05-21T11:16:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38301"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T11:16:57+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893982_731781390","id":"20190424-180614_1259640087","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T11:16:57+0000","dateFinished":"2019-05-21T11:16:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38302"},{"text":"%pyspark\n# Clear the cache to regain memory\ngroupWords2.unpersist()","user":"anonymous","dateUpdated":"2019-05-21T12:54:26+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"PythonRDD[704] at RDD at PythonRDD.scala:53\n"}]},"apps":[],"jobName":"paragraph_1558430893982_587361911","id":"20190424-180624_1766712801","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T11:17:02+0000","dateFinished":"2019-05-21T11:17:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38303"},{"text":"%md\n## 5.1.2 Order of operations\n\n### Rough guidelines to consider for improving Spark performance\n\n*   Spark optimization engine is stronger with SQL Statements\n\n*   `.distinct` called last if necessary, or on fewest number of rows and columns necessary\n\n\n\n### Operations from least to most expensive\n\n*   Generally, you should try to perform your least expensive operations as soon as possible, and your most expensive operations afterwards, if possible. \n\n##### Transformations where no communication is needed.\n*  SELECT (COLUMNS) -> Especially when working with Parquet files\n*  FILTER (ROWS)    -> If you are filtering out a lot of rows, it is wise to cache the resulting filtered data\n*  SAMPLE (ROWS)    -> Take a sample of your input data\n*  MAP              -> Does not reduce the number of rows, but applies a function in parallel to all elements\n\n\n##### Actions where some communication is needed:\n*  REDUCE -> Passes only results from worker nodes to the driver          \n*  TAKE -> Brings some data from worker nodes and sends it to the driver\n*  COUNT -> Passes only resulting counts from worker nodes to the driver          \n*  COLLECT -> Brings all data from worker nodes and sends it to the driver\n\n\n##### Shuffles where a lot of communication is needed\n*  SORT          -> See Window Functions if sorting is only necessary within partitions\n*  JOIN          -> See Broadcast Join below\n*  REPARTITION   -> Useful if you know data will be analyzed by single partitions\n*  DISTINCT      -> Complexity can increase exponentially with the number of columns in the data\n\n#### `.ByKey` Operations can be faster if data is already partitioned by the same fields you are reducing by\n*  SORTBYKEY\n*  REDUCEBYKEY     ","user":"anonymous","dateUpdated":"2019-05-21T13:03:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.2 Order of operations</h2>\n<h3>Rough guidelines to consider for improving Spark performance</h3>\n<ul>\n  <li>\n  <p>Spark optimization engine is stronger with SQL Statements</p></li>\n  <li>\n  <p><code>.distinct</code> called last if necessary, or on fewest number of rows and columns necessary</p></li>\n</ul>\n<h3>Operations from least to most expensive</h3>\n<ul>\n  <li>Generally, you should try to perform your least expensive operations as soon as possible, and your most expensive operations afterwards, if possible.</li>\n</ul>\n<h5>Transformations where no communication is needed.</h5>\n<ul>\n  <li>SELECT (COLUMNS) -&gt; Especially when working with Parquet files</li>\n  <li>FILTER (ROWS) -&gt; If you are filtering out a lot of rows, it is wise to cache the resulting filtered data</li>\n  <li>SAMPLE (ROWS) -&gt; Take a sample of your input data</li>\n  <li>MAP -&gt; Does not reduce the number of rows, but applies a function in parallel to all elements</li>\n</ul>\n<h5>Actions where some communication is needed:</h5>\n<ul>\n  <li>REDUCE -&gt; Passes only results from worker nodes to the driver</li>\n  <li>TAKE -&gt; Brings some data from worker nodes and sends it to the driver</li>\n  <li>COUNT -&gt; Passes only resulting counts from worker nodes to the driver</li>\n  <li>COLLECT -&gt; Brings all data from worker nodes and sends it to the driver</li>\n</ul>\n<h5>Shuffles where a lot of communication is needed</h5>\n<ul>\n  <li>SORT -&gt; See Window Functions if sorting is only necessary within partitions</li>\n  <li>JOIN -&gt; See Broadcast Join below</li>\n  <li>REPARTITION -&gt; Useful if you know data will be analyzed by single partitions</li>\n  <li>DISTINCT -&gt; Complexity can increase exponentially with the number of columns in the data</li>\n</ul>\n<h4><code>.ByKey</code> Operations can be faster if data is already partitioned by the same fields you are reducing by</h4>\n<ul>\n  <li>SORTBYKEY</li>\n  <li>REDUCEBYKEY</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893983_-1689117872","id":"20190424-180630_1079750895","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38304","dateFinished":"2019-05-21T13:03:54+0000","dateStarted":"2019-05-21T13:03:54+0000"},{"text":"%md\nCalling distinct on fewer columns reduces the number of comparisons required","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Calling distinct on fewer columns reduces the number of comparisons required</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893985_-167551276","id":"20190424-180647_2054337143","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38305"},{"text":"%spark\ncase class Song(artist: Option[String], year: Option[Int], loudness: Option[Double])   /* Remember that Datasets are strongly typed. If you´re OK with NULLs in your data and don´t want Spark to crash in this cases you have to use 'Option[]' for\n                                                                                          your case class parameters. */","user":"anonymous","dateUpdated":"2019-05-21T13:04:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class Song\n"}]},"apps":[],"jobName":"paragraph_1558439526394_-1746813266","id":"20190521-115206_817218825","dateCreated":"2019-05-21T11:52:06+0000","dateStarted":"2019-05-21T12:21:08+0000","dateFinished":"2019-05-21T12:21:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38306"},{"text":"%spark\nval millionSongRDD = spark.read\n                          .option(\"inferSchema\", true)\n                          .option(\"delimiter\", \"\\t\")\n                          .csv(\"s3a://cs-spark-basic-training/BigSongs/\")\n                          .select($\"_c2\" as \"artist\", $\"_c15\" as \"year\", $\"_c9\" as \"loudness\")\n                          .as[Song]\n                          .rdd","user":"anonymous","dateUpdated":"2019-05-21T12:19:16+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"millionSongRDD: org.apache.spark.rdd.RDD[Song] = MapPartitionsRDD[859] at rdd at <console>:49\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=261","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=262","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=263"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893985_-1897969214","id":"20190424-180655_1165809301","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T12:19:16+0000","dateFinished":"2019-05-21T12:19:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38307"},{"text":"%spark\nmillionSongRDD.distinct.count   // Counting distinct values on 'artist', 'year' and 'loudness'","user":"anonymous","dateUpdated":"2019-05-21T12:58:32+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res51: Long = 999556\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=264"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893986_-997761531","id":"20190424-180703_694555154","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T12:19:20+0000","dateFinished":"2019-05-21T12:20:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38308"},{"text":"%spark\nmillionSongRDD.map(s => (s.artist, s.year)).distinct.count   // Counting distinct values on 'artist' and 'year'","user":"anonymous","dateUpdated":"2019-05-21T12:58:49+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res52: Long = 155798\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=265"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893987_1299361264","id":"20190424-180713_1552790904","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T12:19:42+0000","dateFinished":"2019-05-21T12:20:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38309"},{"text":"%spark\nmillionSongRDD.map(s => (s.artist)).distinct.count   // Counting distinct values on only 'artist'","user":"anonymous","dateUpdated":"2019-05-21T12:59:00+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res53: Long = 72666\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=266"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893987_-420951063","id":"20190424-180720_316245475","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T12:20:07+0000","dateFinished":"2019-05-21T12:20:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38310"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T12:21:37+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893987_1316726400","id":"20190424-180726_303674004","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T12:21:37+0000","dateFinished":"2019-05-21T12:21:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38311"},{"text":"%pyspark\nfrom pyspark.sql.functions import col\n\nmillionSongRDD = spark.read.option(\"inferSchema\", True).option(\"delimiter\", \"\\t\").csv(\"s3a://cs-spark-basic-training/BigSongs/\").select(col(\"_c2\").alias(\"artist\"), col(\"_c15\").alias(\"year\"), col(\"_c9\").alias(\"loudness\")).rdd#.map(tuple)","user":"anonymous","dateUpdated":"2019-05-21T12:38:48+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=295","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=296","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=297"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1558430893988_-889211715","id":"20190424-180738_773171126","dateCreated":"2019-05-21T09:28:13+0000","dateStarted":"2019-05-21T12:38:48+0000","dateFinished":"2019-05-21T12:38:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38312"},{"text":"%pyspark\nmillionSongRDD.distinct().count()   # Counting distinct values on 'artist', 'year' and 'loudness'","user":"anonymous","dateUpdated":"2019-05-21T12:59:11+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"998202\n"}]},"apps":[],"jobName":"paragraph_1558430893988_1044927357","id":"20190424-180746_1954462912","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38313","dateFinished":"2019-05-21T12:38:15+0000","dateStarted":"2019-05-21T12:37:49+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=294"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\nmillionSongRDD.map(lambda song: (song[\"artist\"], song[\"year\"])).distinct().count()   # Counting distinct values on 'artist' and 'year'","user":"anonymous","dateUpdated":"2019-05-21T12:59:32+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"155798\n"}]},"apps":[],"jobName":"paragraph_1558430893988_-689649032","id":"20190424-180758_479087572","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38314","dateFinished":"2019-05-21T12:39:31+0000","dateStarted":"2019-05-21T12:39:20+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=298"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\nmillionSongRDD.map(lambda song: song[\"artist\"]).distinct().count()   # Counting distinct values on 'artist'","user":"anonymous","dateUpdated":"2019-05-21T12:59:55+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"72666\n"}]},"apps":[],"jobName":"paragraph_1558430893988_909780013","id":"20190424-180806_849998208","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38315","dateFinished":"2019-05-21T12:40:28+0000","dateStarted":"2019-05-21T12:40:19+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=300"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 5.1.3 Broadcast Joins\nUsing the broadcast functionality available in `.SparkContext` can greatly reduce the size of each serialized task, and the cost of launching a job over a cluster. If your tasks use any large object from the driver program inside of them (e.g. a static lookup table), consider turning it into a broadcast variable. \n\nThis should be done for smaller dataframes used in joins or for dictionaries and map lookups.\n","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.3 Broadcast Joins</h2>\n<p>Using the broadcast functionality available in <code>.SparkContext</code> can greatly reduce the size of each serialized task, and the cost of launching a job over a cluster. If your tasks use any large object from the driver program inside of them (e.g. a static lookup table), consider turning it into a broadcast variable. </p>\n<p>This should be done for smaller dataframes used in joins or for dictionaries and map lookups.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893989_1732075762","id":"20190424-180813_1103906047","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38316"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T12:40:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893989_-623014625","id":"20190424-180821_982166438","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38317","dateFinished":"2019-05-21T12:40:45+0000","dateStarted":"2019-05-21T12:40:45+0000"},{"text":"%spark\nval millionSongs = spark.read\n                        .option(\"inferSchema\", true)\n                        .option(\"delimiter\", \"\\t\")\n                        .csv(\"s3a://cs-spark-basic-training/BigSongs/\")\n                        .select($\"_c0\" as \"artist_id\",\n                                $\"_c1\" as \"analysis_sample_rate\",\n                                $\"_c2\" as \"artist_name\",\n                                $\"_c3\" as \"artist_familarity\",\n                                $\"_c4\" as \"artist_hotness\",\n                                $\"_c5\" as \"end_of_fade_in\",\n                                $\"_c6\" as \"key\",\n                                $\"_c7\" as \"key_confidence\",\n                                $\"_c8\" as \"duration\",\n                                $\"_c9\" as \"loudness\",\n                                $\"_c10\" as \"mode\",\n                                $\"_c11\" as \"mode_confidence\",\n                                $\"_c12\" as \"tempo\",\n                                $\"_c13\" as \"time_signature\",\n                                $\"_c14\" as \"time_signature_confidence\",\n                                $\"_c15\" as \"year\")","user":"anonymous","dateUpdated":"2019-05-21T12:41:31+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"millionSongs: org.apache.spark.sql.DataFrame = [artist_id: string, analysis_sample_rate: int ... 14 more fields]\n"}]},"apps":[],"jobName":"paragraph_1558430893989_1365076874","id":"20190424-180952_1756968848","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38318","dateFinished":"2019-05-21T12:41:53+0000","dateStarted":"2019-05-21T12:41:31+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=301","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=302","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=303"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T12:42:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893989_-380137825","id":"20190424-181003_555034064","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38319","dateFinished":"2019-05-21T12:42:03+0000","dateStarted":"2019-05-21T12:42:03+0000"},{"text":"%pyspark\nfrom pyspark.sql.functions import col\n\nmillionSongs = spark.read.option(\"inferSchema\", True).option(\"delimiter\", \"\\t\").csv(\"s3a://cs-spark-basic-training/BigSongs/\").select(col(\"_c0\").alias(\"artist_id\"), col(\"_c1\").alias(\"analysis_sample_rate\"), col(\"_c2\").alias(\"artist_name\"), col(\"_c3\").alias(\"artist_familarity\"), col(\"_c4\").alias(\"artist_hotness\"), col(\"_c5\").alias(\"end_of_fade_in\"),col(\"_c6\").alias(\"key\"), col(\"_c7\").alias(\"key_confidence\"), col(\"_c8\").alias(\"duration\"), col(\"_c9\").alias(\"loudness\"), col(\"_c10\").alias(\"mode\"), col(\"_c11\").alias(\"mode_confidence\"), col(\"_c12\").alias(\"tempo\"), col(\"_c13\").alias(\"time_signature\"), col(\"_c14\").alias(\"time_signature_confidence\"), col(\"_c15\").alias(\"year\"))","user":"anonymous","dateUpdated":"2019-05-21T12:48:19+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1558430893990_-312464863","id":"20190424-181017_832045933","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38320","dateFinished":"2019-05-21T12:48:24+0000","dateStarted":"2019-05-21T12:48:19+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=310","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=311","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=312"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Regular join without broadcasting","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Regular join without broadcasting</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893990_1877815902","id":"20190424-181023_1802490440","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38321"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T12:47:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893990_848471130","id":"20190424-181032_304961585","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38322","dateFinished":"2019-05-21T12:47:51+0000","dateStarted":"2019-05-21T12:47:51+0000"},{"text":"%spark\nval lookupTable = millionSongs.select(\"artist_name\", \"artist_id\").distinct()\n\nval joinedTable1 = millionSongs.join(lookupTable,\n                                    millionSongs(\"artist_name\") === lookupTable(\"artist_name\"),\n                                    \"leftouter\")\n\njoinedTable1.count()","user":"anonymous","dateUpdated":"2019-05-21T12:49:15+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lookupTable: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [artist_name: string, artist_id: string]\njoinedTable1: org.apache.spark.sql.DataFrame = [artist_id: string, analysis_sample_rate: int ... 16 more fields]\nres54: Long = 1199289\n"}]},"apps":[],"jobName":"paragraph_1558430893990_1475854821","id":"20190424-181046_898012742","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38323","dateFinished":"2019-05-21T12:48:52+0000","dateStarted":"2019-05-21T12:48:31+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=313"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T12:48:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893996_18917281","id":"20190424-181055_299171026","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38324","dateFinished":"2019-05-21T12:48:49+0000","dateStarted":"2019-05-21T12:48:49+0000"},{"text":"%pyspark\nlookupTable = millionSongs[['artist_name', 'artist_id']].distinct()\n\njoinedTable1 = millionSongs.join(lookupTable, millionSongs['artist_name'] == lookupTable['artist_name'], how = \"leftouter\")\n\njoinedTable1.count()","user":"anonymous","dateUpdated":"2019-05-21T12:48:56+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1199289\n"}]},"apps":[],"jobName":"paragraph_1558430893998_661036975","id":"20190424-181105_1068204527","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38325","dateFinished":"2019-05-21T12:49:11+0000","dateStarted":"2019-05-21T12:48:56+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=314"],"interpreterSettingId":"spark"}}},{"text":"%md\n### Use broadcast for smaller dataframes in joins","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Use broadcast for smaller dataframes in joins</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893998_-732089311","id":"20190424-181112_962119685","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38326"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T12:49:25+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893998_-3828904","id":"20190424-181118_775504325","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38327","dateFinished":"2019-05-21T12:49:25+0000","dateStarted":"2019-05-21T12:49:25+0000"},{"text":"%spark\nval lookupTable2 = millionSongs.select(\"artist_name\", \"artist_id\").distinct()\n\nimport org.apache.spark.sql.functions.broadcast  \n\n// Broadcast will fully copy the smaller table to each worker node before joining\nval joinedTable2 = millionSongs.join(broadcast(lookupTable2),\n                                     millionSongs(\"artist_name\") === lookupTable2(\"artist_name\"),\n                                     \"leftouter\")\n\njoinedTable2.count()","user":"anonymous","dateUpdated":"2019-05-21T12:49:39+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lookupTable2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [artist_name: string, artist_id: string]\nimport org.apache.spark.sql.functions.broadcast\njoinedTable2: org.apache.spark.sql.DataFrame = [artist_id: string, analysis_sample_rate: int ... 16 more fields]\nres55: Long = 1199289\n"}]},"apps":[],"jobName":"paragraph_1558430893999_-1991004075","id":"20190424-181130_93049248","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38328","dateFinished":"2019-05-21T12:49:45+0000","dateStarted":"2019-05-21T12:49:39+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=315","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=316"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T12:49:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893999_34424904","id":"20190424-181141_1221205570","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38329","dateFinished":"2019-05-21T12:49:48+0000","dateStarted":"2019-05-21T12:49:48+0000"},{"text":"%pyspark\nlookupTable2 = millionSongs[['artist_name', 'artist_id']].distinct()\n\nfrom pyspark.sql.functions import broadcast  \n\n# Broadcast will fully copy the smaller table to each worker node before joining\njoinedTable2 = millionSongs.join(broadcast(lookupTable2), millionSongs['artist_name'] == lookupTable2['artist_name'], how = 'leftouter')\n\njoinedTable2.count()","user":"anonymous","dateUpdated":"2019-05-21T12:49:58+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1199289\n"}]},"apps":[],"jobName":"paragraph_1558430893999_274678388","id":"20190424-181150_1897833219","dateCreated":"2019-05-21T09:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38330","dateFinished":"2019-05-21T12:50:04+0000","dateStarted":"2019-05-21T12:49:58+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=317","http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=318"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 5.1.4 Prefer DataFrames/Datasets to RDDs","user":"anonymous","dateUpdated":"2019-05-21T09:28:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.4 Prefer DataFrames/Datasets to RDDs</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430893999_1893265194","id":"20190424-181156_1134628556","dateCreated":"2019-05-21T09:28:13+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38331"},{"text":"%md\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/CatalystOptimizer.png'>","user":"anonymous","dateUpdated":"2019-05-21T09:28:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://s3.eu-central-1.amazonaws.com/cs-spark-training/CatalystOptimizer.png'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894000_-1831549195","id":"20190424-181203_819940109","dateCreated":"2019-05-21T09:28:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38332"},{"text":"%md\n***Catalyst Optimzer for DataFrames/Datasets***\n\n* Determines and optimize partitions and stages of each job in case of DataFrames/Datasets\n\n* Jobs are executed due to catalyst execution plans\n\n* Catalyst execution plans consist out of:\n  - Parsed logical plan\n  - Analyzed logical plan\n  - Optimized plan\n  - Physical plan\n  - Code generation\n\n* Investigate catalyst execution plan by checking the SQL tab in the Spark web UI or by calling `explain(true)` at the end of query\n\n* Benefits:\n  - Minimizes data transfer between workers and shuffle operations\n  - Pipelines maximum number of operations into one stage\n  - Code generation for every stage at run time (spark.sql.codegen.wholeStage)\n  - If beneficial, jobs can be expanded into multiple jobs \n\n\n* RDDs have to be optimized manually (see also 5.1.5. Partitioning)\n\n* RDDs execution plans can be investigated by checking the Jobs and/or Stages tab in the Spark web UI or by calling `toDebugString`\n\nFurther readings: [Deep Dive into Spark SQL’s Catalyst Optimize](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)","user":"anonymous","dateUpdated":"2019-05-21T09:28:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Catalyst Optimzer for DataFrames/Datasets</em></strong></p>\n<ul>\n  <li>\n  <p>Determines and optimize partitions and stages of each job in case of DataFrames/Datasets</p></li>\n  <li>\n  <p>Jobs are executed due to catalyst execution plans</p></li>\n  <li>\n  <p>Catalyst execution plans consist out of:</p></li>\n  <li>Parsed logical plan</li>\n  <li>Analyzed logical plan</li>\n  <li>Optimized plan</li>\n  <li>Physical plan</li>\n  <li>Code generation</li>\n  <li>\n  <p>Investigate catalyst execution plan by checking the SQL tab in the Spark web UI or by calling <code>explain(true)</code> at the end of query</p></li>\n  <li>\n  <p>Benefits:</p></li>\n  <li>Minimizes data transfer between workers and shuffle operations</li>\n  <li>Pipelines maximum number of operations into one stage</li>\n  <li>Code generation for every stage at run time (spark.sql.codegen.wholeStage)</li>\n  <li>If beneficial, jobs can be expanded into multiple jobs</li>\n  <li>\n  <p>RDDs have to be optimized manually (see also 5.1.5. Partitioning)</p></li>\n  <li>\n  <p>RDDs execution plans can be investigated by checking the Jobs and/or Stages tab in the Spark web UI or by calling <code>toDebugString</code></p></li>\n</ul>\n<p>Further readings: <a href=\"https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html\">Deep Dive into Spark SQL’s Catalyst Optimize</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894002_-432005248","id":"20190424-181209_65266865","dateCreated":"2019-05-21T09:28:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38333"},{"text":"%md\n***Exemplary investigation of catalyst execution plan***","user":"anonymous","dateUpdated":"2019-05-21T09:28:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>Exemplary investigation of catalyst execution plan</em></strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894003_1214327355","id":"20190424-181217_856614330","dateCreated":"2019-05-21T09:28:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38334"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T12:51:20+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1558443073928_730748601","id":"20190521-125113_190836246","dateCreated":"2019-05-21T12:51:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44506","dateFinished":"2019-05-21T12:51:20+0000","dateStarted":"2019-05-21T12:51:20+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]}},{"text":"%spark\njoinedTable2.explain(true)","user":"anonymous","dateUpdated":"2019-05-21T12:50:50+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Parsed Logical Plan ==\nJoin LeftOuter, (artist_name#2009 = artist_name#2497)\n:- Project [_c0#1975 AS artist_id#2007, _c1#1976 AS analysis_sample_rate#2008, _c2#1977 AS artist_name#2009, _c3#1978 AS artist_familarity#2010, _c4#1979 AS artist_hotness#2011, _c5#1980 AS end_of_fade_in#2012, _c6#1981 AS key#2013, _c7#1982 AS key_confidence#2014, _c8#1983 AS duration#2015, _c9#1984 AS loudness#2016, _c10#1985 AS mode#2017, _c11#1986 AS mode_confidence#2018, _c12#1987 AS tempo#2019, _c13#1988 AS time_signature#2020, _c14#1989 AS time_signature_confidence#2021, _c15#1990 AS year#2022]\n:  +- Relation[_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] csv\n+- ResolvedHint (broadcast)\n   +- Deduplicate [artist_name#2497, artist_id#2495]\n      +- Project [artist_name#2497, artist_id#2495]\n         +- Project [_c0#1975 AS artist_id#2495, _c1#1976 AS analysis_sample_rate#2496, _c2#1977 AS artist_name#2497, _c3#1978 AS artist_familarity#2498, _c4#1979 AS artist_hotness#2499, _c5#1980 AS end_of_fade_in#2500, _c6#1981 AS key#2501, _c7#1982 AS key_confidence#2502, _c8#1983 AS duration#2503, _c9#1984 AS loudness#2504, _c10#1985 AS mode#2505, _c11#1986 AS mode_confidence#2506, _c12#1987 AS tempo#2507, _c13#1988 AS time_signature#2508, _c14#1989 AS time_signature_confidence#2509, _c15#1990 AS year#2510]\n            +- Relation[_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] csv\n\n== Analyzed Logical Plan ==\nartist_id: string, analysis_sample_rate: int, artist_name: string, artist_familarity: string, artist_hotness: string, end_of_fade_in: double, key: int, key_confidence: double, duration: double, loudness: double, mode: int, mode_confidence: double, tempo: double, time_signature: int, time_signature_confidence: double, year: int, artist_name: string, artist_id: string\nJoin LeftOuter, (artist_name#2009 = artist_name#2497)\n:- Project [_c0#1975 AS artist_id#2007, _c1#1976 AS analysis_sample_rate#2008, _c2#1977 AS artist_name#2009, _c3#1978 AS artist_familarity#2010, _c4#1979 AS artist_hotness#2011, _c5#1980 AS end_of_fade_in#2012, _c6#1981 AS key#2013, _c7#1982 AS key_confidence#2014, _c8#1983 AS duration#2015, _c9#1984 AS loudness#2016, _c10#1985 AS mode#2017, _c11#1986 AS mode_confidence#2018, _c12#1987 AS tempo#2019, _c13#1988 AS time_signature#2020, _c14#1989 AS time_signature_confidence#2021, _c15#1990 AS year#2022]\n:  +- Relation[_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] csv\n+- ResolvedHint (broadcast)\n   +- Deduplicate [artist_name#2497, artist_id#2495]\n      +- Project [artist_name#2497, artist_id#2495]\n         +- Project [_c0#1975 AS artist_id#2495, _c1#1976 AS analysis_sample_rate#2496, _c2#1977 AS artist_name#2497, _c3#1978 AS artist_familarity#2498, _c4#1979 AS artist_hotness#2499, _c5#1980 AS end_of_fade_in#2500, _c6#1981 AS key#2501, _c7#1982 AS key_confidence#2502, _c8#1983 AS duration#2503, _c9#1984 AS loudness#2504, _c10#1985 AS mode#2505, _c11#1986 AS mode_confidence#2506, _c12#1987 AS tempo#2507, _c13#1988 AS time_signature#2508, _c14#1989 AS time_signature_confidence#2509, _c15#1990 AS year#2510]\n            +- Relation[_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] csv\n\n== Optimized Logical Plan ==\nJoin LeftOuter, (artist_name#2009 = artist_name#2497)\n:- Project [_c0#1975 AS artist_id#2007, _c1#1976 AS analysis_sample_rate#2008, _c2#1977 AS artist_name#2009, _c3#1978 AS artist_familarity#2010, _c4#1979 AS artist_hotness#2011, _c5#1980 AS end_of_fade_in#2012, _c6#1981 AS key#2013, _c7#1982 AS key_confidence#2014, _c8#1983 AS duration#2015, _c9#1984 AS loudness#2016, _c10#1985 AS mode#2017, _c11#1986 AS mode_confidence#2018, _c12#1987 AS tempo#2019, _c13#1988 AS time_signature#2020, _c14#1989 AS time_signature_confidence#2021, _c15#1990 AS year#2022]\n:  +- Relation[_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] csv\n+- ResolvedHint (broadcast)\n   +- Aggregate [artist_name#2497, artist_id#2495], [artist_name#2497, artist_id#2495]\n      +- Project [_c2#1977 AS artist_name#2497, _c0#1975 AS artist_id#2495]\n         +- Filter isnotnull(_c2#1977)\n            +- Relation[_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] csv\n\n== Physical Plan ==\n*(3) BroadcastHashJoin [artist_name#2009], [artist_name#2497], LeftOuter, BuildRight\n:- *(3) Project [_c0#1975 AS artist_id#2007, _c1#1976 AS analysis_sample_rate#2008, _c2#1977 AS artist_name#2009, _c3#1978 AS artist_familarity#2010, _c4#1979 AS artist_hotness#2011, _c5#1980 AS end_of_fade_in#2012, _c6#1981 AS key#2013, _c7#1982 AS key_confidence#2014, _c8#1983 AS duration#2015, _c9#1984 AS loudness#2016, _c10#1985 AS mode#2017, _c11#1986 AS mode_confidence#2018, _c12#1987 AS tempo#2019, _c13#1988 AS time_signature#2020, _c14#1989 AS time_signature_confidence#2021, _c15#1990 AS year#2022]\n:  +- *(3) FileScan csv [_c0#1975,_c1#1976,_c2#1977,_c3#1978,_c4#1979,_c5#1980,_c6#1981,_c7#1982,_c8#1983,_c9#1984,_c10#1985,_c11#1986,_c12#1987,_c13#1988,_c14#1989,_c15#1990] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3a://cs-spark-basic-training/BigSongs], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string,_c1:int,_c2:string,_c3:string,_c4:string,_c5:double,_c6:int,_c7:double,_c8:doub...\n+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n   +- *(2) HashAggregate(keys=[artist_name#2497, artist_id#2495], functions=[], output=[artist_name#2497, artist_id#2495])\n      +- Exchange hashpartitioning(artist_name#2497, artist_id#2495, 200)\n         +- *(1) HashAggregate(keys=[artist_name#2497, artist_id#2495], functions=[], output=[artist_name#2497, artist_id#2495])\n            +- *(1) Project [_c2#1977 AS artist_name#2497, _c0#1975 AS artist_id#2495]\n               +- *(1) Filter isnotnull(_c2#1977)\n                  +- *(1) FileScan csv [_c0#1975,_c2#1977] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3a://cs-spark-basic-training/BigSongs], PartitionFilters: [], PushedFilters: [IsNotNull(_c2)], ReadSchema: struct<_c0:string,_c2:string>\n"}]},"apps":[],"jobName":"paragraph_1558430894003_46482189","id":"20190424-181225_820201251","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38335","dateFinished":"2019-05-21T12:50:51+0000","dateStarted":"2019-05-21T12:50:50+0000"},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T12:51:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1558443088353_1196384814","id":"20190521-125128_476143154","dateCreated":"2019-05-21T12:51:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44596","dateFinished":"2019-05-21T12:51:33+0000","dateStarted":"2019-05-21T12:51:33+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]}},{"text":"%pyspark\njoinedTable2.explain(True)","user":"anonymous","dateUpdated":"2019-05-21T13:04:58+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","lineNumbers":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1558443054140_-1010445220","id":"20190521-125054_951274451","dateCreated":"2019-05-21T12:50:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:44418","dateFinished":"2019-05-21T12:51:07+0000","dateStarted":"2019-05-21T12:51:07+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Parsed Logical Plan ==\nJoin LeftOuter, (artist_name#2231 = artist_name#2613)\n:- Project [_c0#2197 AS artist_id#2229, _c1#2198 AS analysis_sample_rate#2230, _c2#2199 AS artist_name#2231, _c3#2200 AS artist_familarity#2232, _c4#2201 AS artist_hotness#2233, _c5#2202 AS end_of_fade_in#2234, _c6#2203 AS key#2235, _c7#2204 AS key_confidence#2236, _c8#2205 AS duration#2237, _c9#2206 AS loudness#2238, _c10#2207 AS mode#2239, _c11#2208 AS mode_confidence#2240, _c12#2209 AS tempo#2241, _c13#2210 AS time_signature#2242, _c14#2211 AS time_signature_confidence#2243, _c15#2212 AS year#2244]\n:  +- Relation[_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] csv\n+- ResolvedHint (broadcast)\n   +- Deduplicate [artist_name#2613, artist_id#2611]\n      +- Project [artist_name#2613, artist_id#2611]\n         +- Project [_c0#2197 AS artist_id#2611, _c1#2198 AS analysis_sample_rate#2612, _c2#2199 AS artist_name#2613, _c3#2200 AS artist_familarity#2614, _c4#2201 AS artist_hotness#2615, _c5#2202 AS end_of_fade_in#2616, _c6#2203 AS key#2617, _c7#2204 AS key_confidence#2618, _c8#2205 AS duration#2619, _c9#2206 AS loudness#2620, _c10#2207 AS mode#2621, _c11#2208 AS mode_confidence#2622, _c12#2209 AS tempo#2623, _c13#2210 AS time_signature#2624, _c14#2211 AS time_signature_confidence#2625, _c15#2212 AS year#2626]\n            +- Relation[_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] csv\n\n== Analyzed Logical Plan ==\nartist_id: string, analysis_sample_rate: int, artist_name: string, artist_familarity: string, artist_hotness: string, end_of_fade_in: double, key: int, key_confidence: double, duration: double, loudness: double, mode: int, mode_confidence: double, tempo: double, time_signature: int, time_signature_confidence: double, year: int, artist_name: string, artist_id: string\nJoin LeftOuter, (artist_name#2231 = artist_name#2613)\n:- Project [_c0#2197 AS artist_id#2229, _c1#2198 AS analysis_sample_rate#2230, _c2#2199 AS artist_name#2231, _c3#2200 AS artist_familarity#2232, _c4#2201 AS artist_hotness#2233, _c5#2202 AS end_of_fade_in#2234, _c6#2203 AS key#2235, _c7#2204 AS key_confidence#2236, _c8#2205 AS duration#2237, _c9#2206 AS loudness#2238, _c10#2207 AS mode#2239, _c11#2208 AS mode_confidence#2240, _c12#2209 AS tempo#2241, _c13#2210 AS time_signature#2242, _c14#2211 AS time_signature_confidence#2243, _c15#2212 AS year#2244]\n:  +- Relation[_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] csv\n+- ResolvedHint (broadcast)\n   +- Deduplicate [artist_name#2613, artist_id#2611]\n      +- Project [artist_name#2613, artist_id#2611]\n         +- Project [_c0#2197 AS artist_id#2611, _c1#2198 AS analysis_sample_rate#2612, _c2#2199 AS artist_name#2613, _c3#2200 AS artist_familarity#2614, _c4#2201 AS artist_hotness#2615, _c5#2202 AS end_of_fade_in#2616, _c6#2203 AS key#2617, _c7#2204 AS key_confidence#2618, _c8#2205 AS duration#2619, _c9#2206 AS loudness#2620, _c10#2207 AS mode#2621, _c11#2208 AS mode_confidence#2622, _c12#2209 AS tempo#2623, _c13#2210 AS time_signature#2624, _c14#2211 AS time_signature_confidence#2625, _c15#2212 AS year#2626]\n            +- Relation[_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] csv\n\n== Optimized Logical Plan ==\nJoin LeftOuter, (artist_name#2231 = artist_name#2613)\n:- Project [_c0#2197 AS artist_id#2229, _c1#2198 AS analysis_sample_rate#2230, _c2#2199 AS artist_name#2231, _c3#2200 AS artist_familarity#2232, _c4#2201 AS artist_hotness#2233, _c5#2202 AS end_of_fade_in#2234, _c6#2203 AS key#2235, _c7#2204 AS key_confidence#2236, _c8#2205 AS duration#2237, _c9#2206 AS loudness#2238, _c10#2207 AS mode#2239, _c11#2208 AS mode_confidence#2240, _c12#2209 AS tempo#2241, _c13#2210 AS time_signature#2242, _c14#2211 AS time_signature_confidence#2243, _c15#2212 AS year#2244]\n:  +- Relation[_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] csv\n+- ResolvedHint (broadcast)\n   +- Aggregate [artist_name#2613, artist_id#2611], [artist_name#2613, artist_id#2611]\n      +- Project [_c2#2199 AS artist_name#2613, _c0#2197 AS artist_id#2611]\n         +- Filter isnotnull(_c2#2199)\n            +- Relation[_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] csv\n\n== Physical Plan ==\n*(3) BroadcastHashJoin [artist_name#2231], [artist_name#2613], LeftOuter, BuildRight\n:- *(3) Project [_c0#2197 AS artist_id#2229, _c1#2198 AS analysis_sample_rate#2230, _c2#2199 AS artist_name#2231, _c3#2200 AS artist_familarity#2232, _c4#2201 AS artist_hotness#2233, _c5#2202 AS end_of_fade_in#2234, _c6#2203 AS key#2235, _c7#2204 AS key_confidence#2236, _c8#2205 AS duration#2237, _c9#2206 AS loudness#2238, _c10#2207 AS mode#2239, _c11#2208 AS mode_confidence#2240, _c12#2209 AS tempo#2241, _c13#2210 AS time_signature#2242, _c14#2211 AS time_signature_confidence#2243, _c15#2212 AS year#2244]\n:  +- *(3) FileScan csv [_c0#2197,_c1#2198,_c2#2199,_c3#2200,_c4#2201,_c5#2202,_c6#2203,_c7#2204,_c8#2205,_c9#2206,_c10#2207,_c11#2208,_c12#2209,_c13#2210,_c14#2211,_c15#2212] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3a://cs-spark-basic-training/BigSongs], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string,_c1:int,_c2:string,_c3:string,_c4:string,_c5:double,_c6:int,_c7:double,_c8:doub...\n+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n   +- *(2) HashAggregate(keys=[artist_name#2613, artist_id#2611], functions=[], output=[artist_name#2613, artist_id#2611])\n      +- Exchange hashpartitioning(artist_name#2613, artist_id#2611, 200)\n         +- *(1) HashAggregate(keys=[artist_name#2613, artist_id#2611], functions=[], output=[artist_name#2613, artist_id#2611])\n            +- *(1) Project [_c2#2199 AS artist_name#2613, _c0#2197 AS artist_id#2611]\n               +- *(1) Filter isnotnull(_c2#2199)\n                  +- *(1) FileScan csv [_c0#2197,_c2#2199] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3a://cs-spark-basic-training/BigSongs], PartitionFilters: [], PushedFilters: [IsNotNull(_c2)], ReadSchema: struct<_c0:string,_c2:string>\n"}]}},{"text":"%md\n## 5.1.5 Partitioning\n\nIf most of your processing will be done on specific subsets of your dataset (i.e. individual artists, genres, etc.) or you want to leverage the performance by utilize parallelism it makes sense to manually repartition your data. This will ensure data locality which means data that needs to be processed together will be located together on the same server.\n\nSpark provides two ways of (re-)partitioning:\n\n* `.coalesce()`: Can *only reduce* the number of partitions. It´s not possible to increase the number of partitions with `coalesce`. Does *not* require to shuffle data and is therefore a efficient way to reduce the number of partitions.\n\n* `.repartition()`: Can *increase and decrease* the number of partitions. `repartition` does require to shuffle data and equaly distributes the data among the partitions.\n\n#### Sparks rule of thumb for `repartition()`:\n*  number of partitions = 2 or 3 X CPUs in cluster X cores per CPU\n\nSee also [*Level of parallelism*](https://spark.apache.org/docs/latest/tuning.html#level-of-parallelism)","user":"anonymous","dateUpdated":"2019-05-21T13:08:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.5 Partitioning</h2>\n<p>If most of your processing will be done on specific subsets of your dataset (i.e. individual artists, genres, etc.) or you want to leverage the performance by utilize parallelism it makes sense to manually repartition your data. This will ensure data locality which means data that needs to be processed together will be located together on the same server.</p>\n<p>Spark provides two ways of (re-)partitioning:</p>\n<ul>\n  <li>\n  <p><code>.coalesce()</code>: Can <em>only reduce</em> the number of partitions. It´s not possible to increase the number of partitions with <code>coalesce</code>. Does <em>not</em> require to shuffle data and is therefore a efficient way to reduce the number of partitions.</p></li>\n  <li>\n  <p><code>.repartition()</code>: Can <em>increase and decrease</em> the number of partitions. <code>repartition</code> does require to shuffle data and equaly distributes the data among the partitions.</p></li>\n</ul>\n<h4>Sparks rule of thumb for <code>repartition()</code>:</h4>\n<ul>\n  <li>number of partitions = 2 or 3 X CPUs in cluster X cores per CPU</li>\n</ul>\n<p>See also <a href=\"https://spark.apache.org/docs/latest/tuning.html#level-of-parallelism\"><em>Level of parallelism</em></a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894003_-757864400","id":"20190424-181233_651047719","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38336","dateFinished":"2019-05-21T13:08:27+0000","dateStarted":"2019-05-21T13:08:27+0000"},{"text":"%md\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>","user":"anonymous","dateUpdated":"2019-05-21T12:51:56+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://hazelcast.org/wp-content/uploads/2016/04/scala-logo.jpg' style='width:100px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894003_621900622","id":"20190424-181244_1708327145","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38337","dateFinished":"2019-05-21T12:51:56+0000","dateStarted":"2019-05-21T12:51:56+0000"},{"text":"%spark\nmillionSongs.groupBy(\"artist_name\").count().count()","user":"anonymous","dateUpdated":"2019-05-21T13:13:18+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res76: Long = 72666\n"}]},"apps":[],"jobName":"paragraph_1558430894004_2082473753","id":"20190424-181253_812535340","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38338","dateFinished":"2019-05-21T13:13:26+0000","dateStarted":"2019-05-21T13:13:18+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=327"],"interpreterSettingId":"spark"}}},{"text":"%spark\nval songs_partitioned = millionSongs.repartition($\"artist_name\")","user":"anonymous","dateUpdated":"2019-05-21T13:06:53+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"songs_partitioned: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [artist_id: string, analysis_sample_rate: int ... 14 more fields]\n"}]},"apps":[],"jobName":"paragraph_1558430894004_1087601230","id":"20190424-181303_1029262996","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38339","dateFinished":"2019-05-21T12:52:15+0000","dateStarted":"2019-05-21T12:52:03+0000"},{"text":"%spark\nsongs_partitioned.groupBy(\"artist_name\").count().count()","user":"anonymous","dateUpdated":"2019-05-21T13:06:58+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res61: Long = 72666\n"}]},"apps":[],"jobName":"paragraph_1558430894004_-1481611722","id":"20190424-181309_2090048473","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38340","dateFinished":"2019-05-21T12:53:07+0000","dateStarted":"2019-05-21T12:52:55+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=321"],"interpreterSettingId":"spark"}}},{"text":"%md\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>","user":"anonymous","dateUpdated":"2019-05-21T13:13:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg' style='width:150px'>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894004_404264849","id":"20190424-181316_521507640","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38341","dateFinished":"2019-05-21T13:13:44+0000","dateStarted":"2019-05-21T13:13:44+0000"},{"text":"%pyspark \nmillionSongs.groupBy(\"artist_name\").count().count()","user":"anonymous","dateUpdated":"2019-05-21T13:13:56+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"72666\n"}]},"apps":[],"jobName":"paragraph_1558430894005_-596810569","id":"20190424-181323_1164057972","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38342","dateFinished":"2019-05-21T13:14:08+0000","dateStarted":"2019-05-21T13:13:56+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=329"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\nsongs_partitioned = millionSongs.repartition(\"artist_name\")","user":"anonymous","dateUpdated":"2019-05-21T13:14:07+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1558430894005_-1669311218","id":"20190424-181334_727863397","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38343","dateFinished":"2019-05-21T13:14:08+0000","dateStarted":"2019-05-21T13:14:07+0000"},{"text":"%pyspark\nsongs_partitioned.groupBy(\"artist_name\").count().count()","user":"anonymous","dateUpdated":"2019-05-21T13:14:19+0000","config":{"lineNumbers":true,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"72666\n"}]},"apps":[],"jobName":"paragraph_1558430894005_1243887445","id":"20190424-181340_2078089042","dateCreated":"2019-05-21T09:28:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38344","dateFinished":"2019-05-21T13:14:25+0000","dateStarted":"2019-05-21T13:14:19+0000","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-46-129.eu-central-1.compute.internal:4040/jobs/job?id=330"],"interpreterSettingId":"spark"}}},{"text":"%md\n## 5.1.6 Avoid overloading of master/driver node\n\n*   Use `.collect` for large datasets carefully. `.collect` brings all of your data to the master node and can easily kill your application.\n\n*   If you want to check whether your dataframe is empty use data.take(1).length == 0 instead.\n\n*   Use `.takeSample` if you want to check out more than a few rows of data.","user":"anonymous","dateUpdated":"2019-05-21T09:28:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5.1.6 Avoid overloading of master/driver node</h2>\n<ul>\n  <li>\n  <p>Use <code>.collect</code> for large datasets carefully. <code>.collect</code> brings all of your data to the master node and can easily kill your application.</p></li>\n  <li>\n  <p>If you want to check whether your dataframe is empty use data.take(1).length == 0 instead.</p></li>\n  <li>\n  <p>Use <code>.takeSample</code> if you want to check out more than a few rows of data.</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1558430894005_303804469","id":"20190424-181347_1027871197","dateCreated":"2019-05-21T09:28:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38345"}],"name":"/5. Performance Tuning/5.1 Performance Tuning","id":"2ECC2ZUBD","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}