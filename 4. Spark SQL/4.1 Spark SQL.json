{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121382954_-1201462477","id":"20190424-175622_731521033","dateCreated":"2019-04-24T17:56:22+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:55932","text":"%md <img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>","dateUpdated":"2019-04-24T17:57:15+0200","dateFinished":"2019-04-24T17:57:15+0200","dateStarted":"2019-04-24T17:57:15+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<img src='https://global-uploads.webflow.com/5ad0acc69f356a98471287a3/5ae073d500595f83d49e713a_logo_Comsysto-Reply_color.svg' style='width:400px'>\n</div>"}]}},{"text":"%md\n# 4.1 Spark SQL","user":"anonymous","dateUpdated":"2019-04-24T17:57:22+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121435847_-1615088436","id":"20190424-175715_2003769450","dateCreated":"2019-04-24T17:57:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56010","dateFinished":"2019-04-24T17:57:22+0200","dateStarted":"2019-04-24T17:57:22+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>4.1 Spark SQL</h1>\n</div>"}]}},{"text":"%md\n***4.1.1 Spark SQL on DataFrames and Datasets***\n\n***4.1.2 Spark SQL on views***\n\n***4.1.3 Joining, aggregating and grouping***","user":"anonymous","dateUpdated":"2019-04-24T17:57:28+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121442702_1760188184","id":"20190424-175722_539396371","dateCreated":"2019-04-24T17:57:22+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56104","dateFinished":"2019-04-24T17:57:28+0200","dateStarted":"2019-04-24T17:57:28+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong><em>4.1.1 Spark SQL on DataFrames and Datasets</em></strong></p>\n<p><strong><em>4.1.2 Spark SQL on views</em></strong></p>\n<p><strong><em>4.1.3 Joining, aggregating and grouping</em></strong></p>\n</div>"}]}},{"text":"%md\n## 4.1.1 Spark SQL on DataFrames and Dataset\n\nSpark provides two ways of SQL queries - SQL queries on DataFrames and Datasets as well as SQL queries on views.\nIn this section you can see an example for an Spark SQL query on DataFrames and Datasets.","user":"anonymous","dateUpdated":"2019-04-24T17:57:37+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121448522_1617776917","id":"20190424-175728_693630565","dateCreated":"2019-04-24T17:57:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56194","dateFinished":"2019-04-24T17:57:37+0200","dateStarted":"2019-04-24T17:57:37+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>4.1.1 Spark SQL on DataFrames and Dataset</h2>\n<p>Spark provides two ways of SQL queries - SQL queries on DataFrames and Datasets as well as SQL queries on views.<br/>In this section you can see an example for an Spark SQL query on DataFrames and Datasets.</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T17:57:46+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121457159_-1794197238","id":"20190424-175737_23632375","dateCreated":"2019-04-24T17:57:37+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56284","dateFinished":"2019-04-24T17:57:46+0200","dateStarted":"2019-04-24T17:57:46+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Spark SQL query on a DataFrame\nval songDF = spark.read.load(\"dbfs:/cs-spark-training/Songs/\")\nsongDF.show()\n\nsongDF.select($\"artist\", $\"loudness\").where(\"artist like '%Boy%'\").orderBy($\"loudness\").groupBy($\"artist\").count().show()","user":"anonymous","dateUpdated":"2019-04-24T17:57:58+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121466183_-1830828927","id":"20190424-175746_698853042","dateCreated":"2019-04-24T17:57:46+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56374","dateFinished":"2019-04-24T17:57:58+0200","dateStarted":"2019-04-24T17:57:58+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.io.IOException: No FileSystem for scheme: dbfs\n  at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n  at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:616)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 51 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121472126_1862596059","id":"20190424-175752_1740785109","dateCreated":"2019-04-24T17:57:52+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56464","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T17:58:10+0200","dateFinished":"2019-04-24T17:58:10+0200","dateStarted":"2019-04-24T17:58:10+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nsongDF = spark.read.load(\"dbfs:/cs-spark-training/Songs/\")\nsongDF.show()\n\n# plenty of ways to do the following query\nsongDF.select(\"artist\", \"loudness\").filter(songDF.artist.like('%Boy%')).orderBy(songDF.loudness).groupBy(songDF.artist).count().show()","user":"anonymous","dateUpdated":"2019-04-24T17:58:14+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121490361_-2054867065","id":"20190424-175810_1004543255","dateCreated":"2019-04-24T17:58:10+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56599","dateFinished":"2019-04-24T17:58:14+0200","dateStarted":"2019-04-24T17:58:14+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'spark' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'spark' is not defined\n\n"}]}},{"text":"%md\n## 4.1.2 Spark SQL on views\n\nIt´s also possible to use Spark SQL on views. Therefore one has to create a view of the DataFrame or the Dataset.\n\nPossibilities of view creation:\n\n* `.createTempView(\"usersViewName\")` -> Creates a view called *usersViewName* if there is not already a view with the same name\n\n* `.createOrReplaceTempView(\"usersViewName\")` -> Creates a view called *usersViewName* or replaces it if there is already a view with the same name\n\n* `.createGlobalTempView(\"usersViewName\")` -> Creates a global view called *usersViewName* which can be queried across multiple SparkSessions","user":"anonymous","dateUpdated":"2019-04-24T17:58:23+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121494935_399926078","id":"20190424-175814_1913043897","dateCreated":"2019-04-24T17:58:14+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56688","dateFinished":"2019-04-24T17:58:23+0200","dateStarted":"2019-04-24T17:58:23+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>4.1.2 Spark SQL on views</h2>\n<p>It´s also possible to use Spark SQL on views. Therefore one has to create a view of the DataFrame or the Dataset.</p>\n<p>Possibilities of view creation:</p>\n<ul>\n  <li>\n  <p><code>.createTempView(&quot;usersViewName&quot;)</code> -&gt; Creates a view called <em>usersViewName</em> if there is not already a view with the same name</p></li>\n  <li>\n  <p><code>.createOrReplaceTempView(&quot;usersViewName&quot;)</code> -&gt; Creates a view called <em>usersViewName</em> or replaces it if there is already a view with the same name</p></li>\n  <li>\n  <p><code>.createGlobalTempView(&quot;usersViewName&quot;)</code> -&gt; Creates a global view called <em>usersViewName</em> which can be queried across multiple SparkSessions</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T17:58:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121503511_-1119420325","id":"20190424-175823_459966105","dateCreated":"2019-04-24T17:58:23+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56777","dateFinished":"2019-04-24T17:58:35+0200","dateStarted":"2019-04-24T17:58:35+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Create view called 'songDF'\nsongDF.createOrReplaceTempView(\"viewDF\")\n\n//Query view\nspark.sql(\"select artist, loudness, count(artist) from viewDF where artist like '%Boy%' group by artist, loudness order by artist asc\").show(false)","user":"anonymous","dateUpdated":"2019-04-24T17:58:48+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121515919_238524016","id":"20190424-175835_1045987213","dateCreated":"2019-04-24T17:58:35+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56867","dateFinished":"2019-04-24T17:58:48+0200","dateStarted":"2019-04-24T17:58:48+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:30: error: not found: value songDF\n       songDF.createOrReplaceTempView(\"viewDF\")\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121520663_-77437984","id":"20190424-175840_55818327","dateCreated":"2019-04-24T17:58:40+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:56957","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T17:58:58+0200","dateFinished":"2019-04-24T17:58:58+0200","dateStarted":"2019-04-24T17:58:58+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\n# Create view called 'songDF'\nsongDF.createOrReplaceTempView('viewDF')\n\n# Query view\nspark.sql('''select artist, loudness, count(artist) from viewDF where artist like '%Boy%' group by artist, loudness order by artist asc''').show()","user":"anonymous","dateUpdated":"2019-04-24T17:59:05+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121538983_1458261272","id":"20190424-175858_419355055","dateCreated":"2019-04-24T17:58:58+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57078","dateFinished":"2019-04-24T17:59:05+0200","dateStarted":"2019-04-24T17:59:05+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\n"}]}},{"text":"%md\nIn browser applications like notebooks you can also use a SQL interpreter (in case of databricks `%sql`) instead of using `spark.sql()` in combination with the Spark interpreter.\nThe Spark interpreter is the default one.","user":"anonymous","dateUpdated":"2019-04-24T17:59:22+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121545775_-1078098679","id":"20190424-175905_1287959029","dateCreated":"2019-04-24T17:59:05+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57167","dateFinished":"2019-04-24T17:59:22+0200","dateStarted":"2019-04-24T17:59:22+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In browser applications like notebooks you can also use a SQL interpreter (in case of databricks <code>%sql</code>) instead of using <code>spark.sql()</code> in combination with the Spark interpreter.<br/>The Spark interpreter is the default one.</p>\n</div>"}]}},{"text":"%sql\nSelect artist, loudness, count(artist) from viewDF where artist like '%Boy%' group by artist, loudness order by artist asc","user":"anonymous","dateUpdated":"2019-04-24T17:59:30+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121554296_367123279","id":"20190424-175914_1058535062","dateCreated":"2019-04-24T17:59:14+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57256","dateFinished":"2019-04-24T17:59:30+0200","dateStarted":"2019-04-24T17:59:30+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: viewDF; line 1 pos 44\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n## 4.1.3 Joining, aggregating and grouping\n\nJoining, aggregating and grouping are working the same way as we´ve already seen in section [1.2.5 Use DataFrame API](https://dbc.comsysto.com/#notebook/85989/command/88775)","user":"anonymous","dateUpdated":"2019-04-24T18:00:03+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121570191_1229519606","id":"20190424-175930_1067581782","dateCreated":"2019-04-24T17:59:30+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57368","dateFinished":"2019-04-24T18:00:03+0200","dateStarted":"2019-04-24T18:00:03+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>4.1.3 Joining, aggregating and grouping</h2>\n<p>Joining, aggregating and grouping are working the same way as we´ve already seen in section <a href=\"https://dbc.comsysto.com/#notebook/85989/command/88775\">1.2.5 Use DataFrame API</a></p>\n</div>"}]}},{"text":"%md\n### Joining\n\n***Available join types:***\n\n * inner (default)\n \n * outer\n \n * left_outer\n \n * right_outer\n \n * leftsemi\n \n * crossJoin","user":"anonymous","dateUpdated":"2019-04-24T18:00:11+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121600488_-1999514276","id":"20190424-180000_338659907","dateCreated":"2019-04-24T18:00:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57466","dateFinished":"2019-04-24T18:00:11+0200","dateStarted":"2019-04-24T18:00:11+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Joining</h3>\n<p><strong><em>Available join types:</em></strong></p>\n<ul>\n  <li>\n  <p>inner (default)</p></li>\n  <li>\n  <p>outer</p></li>\n  <li>\n  <p>left_outer</p></li>\n  <li>\n  <p>right_outer</p></li>\n  <li>\n  <p>leftsemi</p></li>\n  <li>\n  <p>crossJoin</p></li>\n</ul>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:00:19+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121611607_1669508896","id":"20190424-180011_1789377781","dateCreated":"2019-04-24T18:00:11+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57579","dateFinished":"2019-04-24T18:00:19+0200","dateStarted":"2019-04-24T18:00:19+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\n//Create second DataFrame out of in-memory data\nval listenersDF = spark.createDataFrame(Seq((\"Muse\", 4571),(\"Frank Sinatra\", 1658),(\"Beastie Boys\", 2483)))\n                        .withColumnRenamed(\"_1\", \"band\")\n                        .withColumnRenamed(\"_2\", \"listeners\")\n\nlistenersDF.show()\n\nlistenersDF.createOrReplaceTempView(\"listenersDF\")","user":"anonymous","dateUpdated":"2019-04-24T18:00:31+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121619432_1774873393","id":"20190424-180019_1149594813","dateCreated":"2019-04-24T18:00:19+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57669","dateFinished":"2019-04-24T18:00:31+0200","dateStarted":"2019-04-24T18:00:31+0200","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+---------+\n|         band|listeners|\n+-------------+---------+\n|         Muse|     4571|\n|Frank Sinatra|     1658|\n| Beastie Boys|     2483|\n+-------------+---------+\n\nlistenersDF: org.apache.spark.sql.DataFrame = [band: string, listeners: int]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121624720_-2037190289","id":"20190424-180024_17228047","dateCreated":"2019-04-24T18:00:24+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57759","text":"%md\n<b><font color='blue'size=5>Python</font>","dateUpdated":"2019-04-24T18:00:41+0200","dateFinished":"2019-04-24T18:00:41+0200","dateStarted":"2019-04-24T18:00:41+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nmyData = [(\"Muse\", 4571),(\"Frank Sinatra\", 1658),(\"Beastie Boys\", 2483)]\nlistenersDF = spark.createDataFrame(myData, ['band', 'listeners'])\n\nlistenersDF.show()\nlistenersDF.createOrReplaceTempView('listenersDF')","user":"anonymous","dateUpdated":"2019-04-24T18:00:47+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121641912_2126087312","id":"20190424-180041_1285319072","dateCreated":"2019-04-24T18:00:41+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57894","dateFinished":"2019-04-24T18:00:47+0200","dateStarted":"2019-04-24T18:00:47+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'spark' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 307, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 2, in <module>\nNameError: name 'spark' is not defined\n\n"}]}},{"text":"%md\nJoining by using SQL on DataFrames and Datasets","user":"anonymous","dateUpdated":"2019-04-24T18:00:54+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121647728_615938983","id":"20190424-180047_564853536","dateCreated":"2019-04-24T18:00:47+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:57983","dateFinished":"2019-04-24T18:00:54+0200","dateStarted":"2019-04-24T18:00:54+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Joining by using SQL on DataFrames and Datasets</p>\n</div>"}]}},{"text":"%md\n<b><font color='vermilion'size=5>Scala</font>","user":"anonymous","dateUpdated":"2019-04-24T18:01:01+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121654880_746572586","id":"20190424-180054_645671290","dateCreated":"2019-04-24T18:00:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58072","dateFinished":"2019-04-24T18:01:01+0200","dateStarted":"2019-04-24T18:01:01+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='vermilion'size=5>Scala</font></p>\n</div>"}]}},{"text":"%spark\nsongDF.join(listenersDF, songDF(\"artist\")===listenersDF(\"band\")).show()","user":"anonymous","dateUpdated":"2019-04-24T18:01:18+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121661944_1288587085","id":"20190424-180101_511101527","dateCreated":"2019-04-24T18:01:01+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58162","dateFinished":"2019-04-24T18:01:18+0200","dateStarted":"2019-04-24T18:01:18+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:32: error: not found: value songDF\n       songDF.join(listenersDF, songDF(\"artist\")===listenersDF(\"band\")).show()\n       ^\n<console>:32: error: not found: value songDF\n       songDF.join(listenersDF, songDF(\"artist\")===listenersDF(\"band\")).show()\n                                ^\n"}]}},{"text":"%md\n<b><font color='blue'size=5>Python</font>","user":"anonymous","dateUpdated":"2019-04-24T18:01:36+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121678592_170234768","id":"20190424-180118_499596349","dateCreated":"2019-04-24T18:01:18+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58251","dateFinished":"2019-04-24T18:01:36+0200","dateStarted":"2019-04-24T18:01:36+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b><font color='blue'size=5>Python</font></p>\n</div>"}]}},{"text":"%python\nsongDF.join(listenersDF, songDF.artist == listenersDF.band).show()","user":"anonymous","dateUpdated":"2019-04-24T18:01:44+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121696783_1155469233","id":"20190424-180136_2091734001","dateCreated":"2019-04-24T18:01:36+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58340","dateFinished":"2019-04-24T18:01:44+0200","dateStarted":"2019-04-24T18:01:44+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 319, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-9202459694796226681.py\", line 312, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'songDF' is not defined\n\n"}]}},{"text":"%md\nJoining by using SQL on views","user":"anonymous","dateUpdated":"2019-04-24T18:01:51+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121704728_1057001481","id":"20190424-180144_813333021","dateCreated":"2019-04-24T18:01:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58429","dateFinished":"2019-04-24T18:01:51+0200","dateStarted":"2019-04-24T18:01:51+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Joining by using SQL on views</p>\n</div>"}]}},{"text":"%spark\nspark.sql(\"select viewDF.artist, viewDF.loudness, listenersDF.band, listenersDF.listeners from viewDF join listenersDF on viewDF.artist = listenersDF.band\").show()","user":"anonymous","dateUpdated":"2019-04-24T18:02:09+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121711704_-222286198","id":"20190424-180151_160958143","dateCreated":"2019-04-24T18:01:51+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58518","dateFinished":"2019-04-24T18:02:09+0200","dateStarted":"2019-04-24T18:02:09+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.sql.AnalysisException: Table or view not found: viewDF; line 1 pos 84\n  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:649)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:601)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:631)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:624)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:61)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:624)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:570)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)\n  at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n  at scala.collection.immutable.List.foldLeft(List.scala:84)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:69)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:67)\n  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:50)\n  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:67)\n  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)\n  ... 51 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121718418_540059243","id":"20190424-180158_1985401616","dateCreated":"2019-04-24T18:01:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58608","text":"%md\nJoining by using SQL interpreter in browser applications","dateUpdated":"2019-04-24T18:02:21+0200","dateFinished":"2019-04-24T18:02:21+0200","dateStarted":"2019-04-24T18:02:21+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Joining by using SQL interpreter in browser applications</p>\n</div>"}]}},{"text":"%sql\nSelect * from viewDF join listenersDF on viewDF.artist = listenersDF.band ","user":"anonymous","dateUpdated":"2019-04-24T18:02:35+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121740993_1647949879","id":"20190424-180220_2093044228","dateCreated":"2019-04-24T18:02:20+0200","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58754","dateFinished":"2019-04-24T18:02:35+0200","dateStarted":"2019-04-24T18:02:35+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: viewDF; line 1 pos 14\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]}},{"text":"%md\n### Aggregating and grouping\n\n* DataFrames can be grouped (`groupBy`, `groupByKey`) in a SQL-like fashion. Grouping functions can be found in the [Dataset API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset).\n\n* DataFrames can be aggregated as well. Aggregation functions can be found in the [built-in DataFrame functions](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$).\n\n* Examples for aggregation functions:\n - count\n - sum\n - first\n - max\n - avg","user":"anonymous","dateUpdated":"2019-04-24T18:02:43+0200","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556121749183_2129892524","id":"20190424-180229_1548912125","dateCreated":"2019-04-24T18:02:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:58844","dateFinished":"2019-04-24T18:02:43+0200","dateStarted":"2019-04-24T18:02:43+0200","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Aggregating and grouping</h3>\n<ul>\n  <li>\n  <p>DataFrames can be grouped (<code>groupBy</code>, <code>groupByKey</code>) in a SQL-like fashion. Grouping functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\">Dataset API</a>.</p></li>\n  <li>\n  <p>DataFrames can be aggregated as well. Aggregation functions can be found in the <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\">built-in DataFrame functions</a>.</p></li>\n  <li>\n  <p>Examples for aggregation functions:</p></li>\n  <li>count</li>\n  <li>sum</li>\n  <li>first</li>\n  <li>max</li>\n  <li>avg</li>\n</ul>\n</div>"}]}}],"name":"/4. Spark SQL/4.1 Spark SQL","id":"2EASBV4HN","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}